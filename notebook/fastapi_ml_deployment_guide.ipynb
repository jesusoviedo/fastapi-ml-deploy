{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe0e3c-fb18-4f8a-a8a8-7d3fd367cc3a",
   "metadata": {},
   "source": [
    "# Implementación de Modelos de ML con FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215d90e-da16-4b5a-9792-c5c1afcde39f",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Este notebook educativo completo te guía paso a paso en la implementación de modelos de Machine Learning usando las herramientas más modernas de 2025: **FastAPI**, **uv**, **Docker**, y **Fly.io**. Aprenderás a crear un servicio web robusto para servir modelos de ML en producción.\n",
    "\n",
    "### ¿Qué aprenderás?\n",
    "\n",
    "- Configuración moderna de proyectos con **uv** (la alternativa rápida a pip/pipenv)\n",
    "- Entrenamiento y guardado de modelos con **scikit-learn pipelines**\n",
    "- Creación de APIs robustas con **FastAPI**\n",
    "- Validación de datos con **Pydantic**\n",
    "- Contenedorización con **Docker**\n",
    "- Despliegue en la nube con **Fly.io**\n",
    "\n",
    "### Caso de Uso: Predicción de Churn de Clientes\n",
    "\n",
    "Implementaremos un modelo para predecir si un cliente cancelará su servicio (churn), un problema común en telecomunicaciones y servicios de suscripción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8cc97-9d65-45e9-a1a9-251c65114bfa",
   "metadata": {},
   "source": [
    "## 1. Configuración del Entorno con UV\n",
    "\n",
    "### ¿Qué es UV y por qué es tan rápido?\n",
    "\n",
    "Imagina que estás construyendo algo con bloques de LEGO. `pip` es como un ayudante que va a la tienda a por cada pieza que necesitas, una por una. Si una pieza necesita otra más pequeña, tiene que volver a la tienda. Es fiable, pero puede llevar su tiempo.\n",
    "\n",
    "**UV**, en cambio, es como un ayudante con un dron súper-rápido y una tablet. Antes de salir, mira tu lista, calcula al instante todas las piezas y sub-piezas que necesitarás, y las recoge todas de la tienda en un solo viaje a máxima velocidad.\n",
    "\n",
    "En resumen, **UV es un instalador y gestor de entornos virtuales para Python, diseñado para ser extremadamente rápido**. Su objetivo es reemplazar a herramientas como `pip`, `pip-tools`, `venv` y `virtualenv` con una única interfaz de línea de comandos ultrarrápida.\n",
    "\n",
    "### El Secreto de su Velocidad\n",
    "\n",
    "La \"magia\" de UV no es una sola cosa, sino la combinación de tres factores clave:\n",
    "\n",
    "1.  **Está escrito en Rust**: A diferencia de `pip` que está escrito en Python, UV está construido con Rust. Rust es un lenguaje de programación que compila a código máquina nativo, lo que le permite ejecutar tareas como la descarga e instalación de archivos a una velocidad mucho mayor que un lenguaje interpretado como Python. ¡Es como comparar un coche de Fórmula 1 (Rust) con un coche de calle (Python) para una carrera de velocidad!\n",
    "\n",
    "2.  **Resolución de dependencias de última generación**: Cuando instalas un paquete (ej. `pandas`), este depende de otros (ej. `numpy`), que a su vez dependen de otros. Encontrar las versiones correctas que sean compatibles entre sí es un rompecabezas complejo. UV utiliza un algoritmo muy avanzado para resolver este \"puzzle\" de dependencias de forma increíblemente eficiente.\n",
    "\n",
    "3.  **Un sistema de caché global e inteligente**: La primera vez que UV descarga un paquete, lo guarda en una caché global en tu sistema. La próxima vez que necesites ese mismo paquete en *otro proyecto*, UV no lo descarga de nuevo. Simplemente crea un enlace a la versión que ya tiene guardada. Esto hace que la creación de nuevos entornos sea casi instantánea.\n",
    "\n",
    "> **Dato curioso**: El creador de UV, Charlie Marsh, es también el creador de **Ruff**, un *linter* de Python también escrito en Rust que es cientos de veces más rápido que sus predecesores.\n",
    "\n",
    "### UV vs. Pip y otras herramientas\n",
    "\n",
    "Pensar que UV es solo \"un pip más rápido\" es quedarse corto. La verdadera revolución es que **UV es una navaja suiza que reemplaza a un conjunto de herramientas**.\n",
    "\n",
    "La forma tradicional de trabajar en Python requiere un equipo de varias herramientas:\n",
    "* `venv` o `virtualenv`: Para crear y gestionar entornos virtuales aislados.\n",
    "* `pip`: Para instalar los paquetes dentro de ese entorno.\n",
    "* `pip-tools`: Una herramienta extra para compilar un `requirements.txt` a partir de un `pyproject.toml` y generar un archivo de bloqueo (`.txt`) que asegure la reproducibilidad.\n",
    "\n",
    "UV integra todas estas funciones (y más) en un único ejecutable súper rápido.\n",
    "\n",
    "Pensemos en una analogía: `pip` + `venv` es como tener una caja de herramientas con un martillo, un destornillador y una llave inglesa. Funcionan bien, pero tienes que ir cambiando de herramienta para cada tarea. **UV es como una multiherramienta Leatherman de última generación**: tienes todo lo que necesitas en un solo lugar, es más ligera y mucho más eficiente. \n",
    "\n",
    "### Tabla Comparativa Rápida\n",
    "\n",
    "| Característica | `pip` + `venv` | `uv` |\n",
    "| :--- | :--- | :--- |\n",
    "| **Velocidad** | Moderada. La resolución de dependencias puede ser lenta. | **Extremadamente Rápida**. Gracias a Rust y su resolutor avanzado. |\n",
    "| **Herramientas** | Múltiples (`python -m venv`, `pip`). | **Única y unificada** (un solo comando `uv`). |\n",
    "| **Crear Entorno** | `python -m venv .venv` | `uv venv` (notablemente más rápido). |\n",
    "| **Instalación** | `pip install pandas` | `uv pip install pandas` (sintaxis familiar). |\n",
    "| **Caché de Paquetes**| El caché de pip es bueno, pero a veces inconsistente. | **Caché global e inteligente**. Acelera la creación de nuevos proyectos. |\n",
    "| **Reproducibilidad**| Se necesita `pip-tools` para crear un archivo `.txt` de bloqueo. | **Soporte nativo**. Puede leer y generar archivos de bloqueo (`uv.lock`, `requirements.lock`). |\n",
    "\n",
    "> La conclusión es simple: pasas de hacer malabares con 2 o 3 comandos a usar uno solo que, además, es entre **10 y 100 veces más rápido**. En entornos de Integración Continua (CI/CD), donde se crean y destruyen entornos constantemente, este ahorro de tiempo es gigantesco.\n",
    "\n",
    "\n",
    "### Instalación y Configuración\n",
    "\n",
    "```bash\n",
    "# En tu terminal, instala uv (solo una vez)\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "```\n",
    "\n",
    "> Otra alternativa: para usar `uv`, necesitas instalarlo en tu sistema. La forma más fácil es con `pip` normal: `pip install uv`).\n",
    "\n",
    "### Primeros Pasos con UV\n",
    "\n",
    "Aquí tienes el flujo de trabajo típico para un nuevo proyecto, paso a paso.\n",
    "\n",
    "#### Paso 1: Crear el Entorno Virtual\n",
    "\n",
    "Olvida el `python -m venv .venv`. Con UV, es más corto y mucho más rápido:\n",
    "\n",
    "```bash\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "\n",
    "# Crea un entorno virtual en una carpeta llamada .venv\n",
    "uv venv\n",
    "```\n",
    "\n",
    "¡Listo\\! En una fracción de segundo, tendrás tu entorno creado. Si quisieras usar una versión específica de Python que tengas instalada, podrías hacer `uv venv -p 3.11`.\n",
    "\n",
    "#### Paso 2: Activar el Entorno\n",
    "\n",
    "Esta parte es **exactamente igual** a como siempre lo has hecho. UV crea una estructura de carpetas compatible.\n",
    "\n",
    "```bash\n",
    "# En Linux o macOS\n",
    "source .venv/bin/activate\n",
    "\n",
    "# En Windows (Command Prompt)\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Una vez activado, tu terminal te mostrará `(.venv)` al principio de la línea.\n",
    "\n",
    "#### Paso 3: Instalar Paquetes\n",
    "\n",
    "La sintaxis es idéntica a la de `pip`, lo cual facilita enormemente la transición. Simplemente reemplazas `pip install` por `uv pip install`, otro comando valido es `uv add`.\n",
    "\n",
    "```bash\n",
    "# Instalar un solo paquete\n",
    "uv pip install fastapi\n",
    "\n",
    "# Instalar varios paquetes a la vez\n",
    "uv pip install \"pandas~=2.0\" pydantic\n",
    "\n",
    "# Instalar desde tu pyproject.toml\n",
    "uv pip install -e .\n",
    "```\n",
    "\n",
    "Aquí notarás la diferencia más grande: la velocidad de descarga e instalación es asombrosa.\n",
    "\n",
    "#### Paso 4: Generar un Archivo de Bloqueo\n",
    "\n",
    "Este es el paso que garantiza que el entorno de todo tu equipo sea idéntico. `uv` lee tu `pyproject.toml` y genera un archivo `requirements.lock` con las versiones exactas de cada paquete.\n",
    "\n",
    "```bash\n",
    "# Lee pyproject.toml y crea un archivo de bloqueo\n",
    "uv pip compile pyproject.toml -o requirements.lock\n",
    "```\n",
    "\n",
    "Este archivo `requirements.lock` es el que subirías a tu repositorio de Git.\n",
    "\n",
    "#### Paso 5: Instalar desde el Archivo de Bloqueo\n",
    "\n",
    "Ahora, imagina que eres un nuevo desarrollador que se une al proyecto. Tienes el `pyproject.toml` y el `requirements.lock`. Después de crear y activar tu entorno, solo necesitas un comando:\n",
    "\n",
    "```bash\n",
    "# Lee el archivo de bloqueo y sincroniza tu entorno.\n",
    "# ¡Instala, elimina y actualiza paquetes para que coincida 100%!\n",
    "uv sync requirements.lock\n",
    "```\n",
    "\n",
    "Este comando es increíblemente rápido y eficiente. Es el que usarías en tus flujos de CI/CD o para que un compañero se ponga al día.\n",
    "\n",
    "### Estructura de Proyecto para ML\n",
    "\n",
    "Esta es la estructura de directorios recomendada para el proyecto, siguiendo las mejores prácticas de desarrollo de software y MLOps.\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "├── .env                  # Variables de entorno y secretos\n",
    "├── .gitignore\n",
    "├── .python-version       # Versión de Python fijada para el proyecto\n",
    "├── pyproject.toml        # Definición de dependencias y configuración\n",
    "├── uv.lock               # Archivo de bloqueo para reproducibilidad\n",
    "├── README.md\n",
    "├── Dockerfile            # Instrucciones para la contenedorización\n",
    "│\n",
    "├── artifacts/            # Modelos entrenados, serializadores y otros artefactos\n",
    "│   └── sentiment_model_v1.pkl\n",
    "│\n",
    "├── data/                 # Datasets del proyecto (ignorado por Git)\n",
    "│   ├── raw/              # Datos originales, sin modificar\n",
    "│   └── processed/        # Datos limpios y listos para el entrenamiento\n",
    "│\n",
    "├── notebooks/            # Jupyter Notebooks para exploración y análisis\n",
    "│   └── 1.0-eda-initial-exploration.ipynb\n",
    "│\n",
    "├── src/                  # Código fuente de la aplicación\n",
    "│   ├── __init__.py\n",
    "│   ├── main.py           # Punto de entrada de la API (FastAPI)\n",
    "│   ├── config.py         # Módulo de configuración\n",
    "│   ├── api/              # Lógica de la API (endpoints)\n",
    "│   ├── ml/               # Código de Machine Learning\n",
    "│   └── schemas/          # Esquemas de datos (Pydantic)\n",
    "│\n",
    "├── tests/                # Pruebas automáticas\n",
    "└── scripts/              # Scripts de utilidad (ej. para descargar datos)\n",
    "```\n",
    "\n",
    "### Explicación de la Estructura\n",
    "\n",
    "La organización de este proyecto está diseñada para ser **clara, modular y escalable**. Cada directorio tiene una responsabilidad bien definida:\n",
    "\n",
    "  * **Configuración (Raíz)**: Los archivos en la raíz del proyecto (`pyproject.toml`, `uv.lock`, `.python-version`, etc.) definen el entorno, las dependencias y las reglas del proyecto, asegurando que cualquier colaborador pueda replicar el entorno de desarrollo de forma idéntica.\n",
    "\n",
    "  * **`src/` (Código Fuente)**: Es el corazón de la aplicación. Contiene todo el código Python que se ejecuta como parte del servicio final. La lógica está modularizada en subpaquetes como `api/`, `ml/` y `schemas/` para mantener el código organizado y fácil de mantener.\n",
    "\n",
    "  * **`artifacts/` (Artefactos)**: Esta carpeta almacena los **productos generados por nuestro código**, no el código en sí. Su principal contenido son los modelos ya entrenados (ej. un archivo `.pkl` o `.h5`).\n",
    "\n",
    "  * **`data/` (Datos)**: Un lugar centralizado para todos los datos necesarios. Se divide en `raw` para los datos originales e inmutables y `processed` para las versiones limpias y transformadas, listas para ser usadas en el entrenamiento. Esta carpeta se añade al `.gitignore` para evitar subir grandes volúmenes de datos al repositorio.\n",
    "\n",
    "  * **`notebooks/` (Experimentación)**: Este es el \"laboratorio\". Contiene los Jupyter Notebooks usados para el Análisis Exploratorio de Datos (EDA), prototipado de modelos y visualizaciones. Separar los notebooks del código de producción en `src/` es crucial para mantener el proyecto limpio.\n",
    "\n",
    "  * **`tests/` y `scripts/` (Soporte)**: `tests/` asegura la calidad y fiabilidad de nuestro código mediante pruebas automáticas, mientras que `scripts/` nos proporciona un lugar para herramientas de un solo uso que facilitan tareas de desarrollo.\n",
    "\n",
    "Esta separación de responsabilidades hace que el proyecto sea más fácil de entender, probar, y finalmente, desplegar a producción.\n",
    "\n",
    "\n",
    "### Configuración de Dependencias (pyproject.toml)\n",
    "\n",
    "`pyproject.toml` es el cerebro detrás de la gestión de proyectos modernos en Python, y herramientas como **UV** están diseñadas para leerlo a la perfección.\n",
    "\n",
    "Piensa en `pyproject.toml` como el **carné de identidad y el panel de control** de tu proyecto, todo en un único archivo.\n",
    "\n",
    "Antes, la configuración de un proyecto de Python estaba repartida en varios archivos: `setup.py`, `requirements.txt`, `setup.cfg`, `MANIFEST.in`... ¡Era un poco caótico\\! El archivo `pyproject.toml` fue introducido (en el [PEP 518](https://peps.python.org/pep-0518/)) para estandarizar y centralizar toda esa información en un solo lugar.\n",
    "\n",
    "### ¿Qué hay dentro de un `pyproject.toml`?\n",
    "\n",
    "Este archivo utiliza el formato [TOML](https://www.google.com/search?q=https://toml.io/es/) (Tom's Obvious, Minimal Language), que es muy fácil de leer para los humanos. Se organiza en secciones, pero nos centraremos en las más importantes para las dependencias.\n",
    "\n",
    "Veamos un ejemplo práctico:\n",
    "\n",
    "```toml\n",
    "# Esta sección le dice a Python CÓMO construir tu proyecto.\n",
    "# No necesitas preocuparte mucho por ella al principio.\n",
    "[build-system]\n",
    "requires = [\"setuptools>=61.0\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "# --- Aquí empieza lo interesante ---\n",
    "\n",
    "# Esta es la \"ficha de identidad\" de tu proyecto.\n",
    "[project]\n",
    "name = \"mi-proyecto-genial\"\n",
    "version = \"0.1.0\"\n",
    "authors = [\n",
    "  { name=\"Tu Nombre\", email=\"tu@email.com\" },\n",
    "]\n",
    "description = \"Un pequeño proyecto de ejemplo.\"\n",
    "\n",
    "# Aquí declaras las dependencias PRINCIPALES.\n",
    "# Estas son las que se necesitan para que tu programa funcione.\n",
    "dependencies = [\n",
    "    \"fastapi>=0.90.0\", # Necesitamos fastapi, versión 0.90.0 o superior.\n",
    "    \"pandas\",         # La última versión estable de pandas.\n",
    "]\n",
    "\n",
    "# Dependencias OPCIONALES. No son necesarias para todos los usuarios.\n",
    "[project.optional-dependencies]\n",
    "test = [\n",
    "    \"pytest\",\n",
    "    \"pytest-cov\",\n",
    "]\n",
    "docs = [\n",
    "    \"sphinx\",\n",
    "]\n",
    "\n",
    "# En esta sección, otras herramientas pueden guardar su configuración.\n",
    "# Por ejemplo, Ruff (el linter del que hablamos) se configura aquí.\n",
    "[tool.ruff]\n",
    "line-length = 88\n",
    "```\n",
    "\n",
    "Las dos secciones clave son:\n",
    "\n",
    "1.  `[project.dependencies]`: Esta es tu lista principal de \"ingredientes\". Es el equivalente moderno al archivo `requirements.txt`. Aquí pones los paquetes que tu proyecto **necesita** para funcionar.\n",
    "2.  `[project.optional-dependencies]`: Aquí defines grupos de dependencias para situaciones específicas. El caso más común es `test` (para instalar librerías de testing como `pytest`) o `dev` (para herramientas de desarrollo). Esto es genial porque alguien que solo quiere *usar* tu programa no necesita descargar todas las herramientas que tú usaste para *crearlo*.\n",
    "\n",
    "### ¿Y cómo se relaciona esto con UV?\n",
    "\n",
    "Aquí es donde todo encaja. **UV está diseñado para leer este archivo de forma nativa y ultrarrápida**.\n",
    "\n",
    "  - Si ejecutas `uv pip install -e .` en la carpeta de tu proyecto, UV leerá la lista de `[project.dependencies]` y las instalará.\n",
    "  - Si quieres instalar también las dependencias de testing, ejecutarías `uv pip install -e \".[test]\"`. UV entenderá que debe instalar las dependencias principales **Y** las del grupo `test`.\n",
    "\n",
    "Usar `pyproject.toml` centraliza toda la configuración, haciendo tu proyecto más limpio, reproducible y fácil de entender tanto para otros desarrolladores como para herramientas automáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca28df-73a6-4b9d-9052-02fe3c079616",
   "metadata": {},
   "source": [
    "## 2. Generación de Datos Sintéticos para Churn\n",
    "\n",
    "### Crear Dataset de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb78d-00ff-49ca-8648-dbd2368b4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def create_churn_dataset(n_samples=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Crear un dataset sintético realista para predicción de churn.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con características de clientes y etiquetas de churn\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Crear datos base\n",
    "    data = {\n",
    "        'customer_id': range(1, n_samples + 1),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'senior_citizen': np.random.choice([0, 1], n_samples, p=[0.84, 0.16]),\n",
    "        'partner': np.random.choice(['Yes', 'No'], n_samples, p=[0.48, 0.52]),\n",
    "        'dependents': np.random.choice(['Yes', 'No'], n_samples, p=[0.30, 0.70]),\n",
    "        'tenure': np.random.randint(1, 73, n_samples),  # Meses\n",
    "        'phone_service': np.random.choice(['Yes', 'No'], n_samples, p=[0.90, 0.10]),\n",
    "        'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], \n",
    "                                           n_samples, p=[0.34, 0.44, 0.22]),\n",
    "        'online_security': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                          n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                       n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], \n",
    "                                   n_samples, p=[0.55, 0.21, 0.24]),\n",
    "        'payment_method': np.random.choice([\n",
    "            'Electronic check', 'Mailed check', 'Bank transfer (automatic)', \n",
    "            'Credit card (automatic)'\n",
    "        ], n_samples, p=[0.34, 0.23, 0.22, 0.21]),\n",
    "        'monthly_charges': np.round(np.random.normal(64.76, 30.0, n_samples), 2),\n",
    "        'total_charges': np.round(np.random.normal(2283.30, 2266.77, n_samples), 2)\n",
    "    }\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Limpiar valores negativos en charges\n",
    "    df['monthly_charges'] = df['monthly_charges'].clip(lower=18.25)\n",
    "    df['total_charges'] = df['total_charges'].clip(lower=18.80)\n",
    "    \n",
    "    # Crear etiquetas de churn con lógica realista\n",
    "    churn_probability = 0.2  # Baseline\n",
    "    \n",
    "    # Factores que aumentan churn\n",
    "    tenure_factor = np.where(df['tenure'] < 12, 0.15, 0)  # Clientes nuevos\n",
    "    contract_factor = np.where(df['contract'] == 'Month-to-month', 0.20, 0)  # Sin compromiso\n",
    "    payment_factor = np.where(df['payment_method'] == 'Electronic check', 0.10, 0)  # Método de pago\n",
    "    charges_factor = np.where(df['monthly_charges'] > 80, 0.08, 0)  # Cargos altos\n",
    "    \n",
    "    # Factores que reducen churn\n",
    "    partner_factor = np.where(df['partner'] == 'Yes', -0.08, 0)  # Con pareja\n",
    "    dependents_factor = np.where(df['dependents'] == 'Yes', -0.05, 0)  # Con dependientes\n",
    "    long_tenure_factor = np.where(df['tenure'] > 48, -0.12, 0)  # Clientes antiguos\n",
    "    \n",
    "    # Calcular probabilidad final\n",
    "    final_probability = (churn_probability + tenure_factor + contract_factor + \n",
    "                        payment_factor + charges_factor + partner_factor + \n",
    "                        dependents_factor + long_tenure_factor)\n",
    "    \n",
    "    # Generar etiquetas de churn\n",
    "    df['churn'] = np.random.binomial(1, final_probability.clip(0.05, 0.85))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear el dataset\n",
    "print(\"Generando dataset sintético de churn...\")\n",
    "churn_data = create_churn_dataset(n_samples=10000)\n",
    "\n",
    "print(f\"Dataset creado:\")\n",
    "print(f\"   • Muestras: {len(churn_data)}\")\n",
    "print(f\"   • Características: {churn_data.shape[1]-2}\")  # -2 para customer_id y churn\n",
    "print(f\"   • Tasa de churn: {churn_data['churn'].mean():.1%}\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212f30-8fd3-46bc-b753-30031c19dc63",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del Modelo con Pipelines de Scikit-learn\n",
    "\n",
    "### ¿Por qué usar Pipelines?\n",
    "\n",
    "Los **pipelines** de scikit-learn combinan múltiples pasos de preprocesamiento y modelado en un solo objeto, lo que:\n",
    "- Simplifica el código\n",
    "- Evita errores de data leakage\n",
    "- Facilita la serialización\n",
    "- Permite usar el modelo con datos en formato crudo\n",
    "\n",
    "Pensemos en un **Pipeline** de Scikit-learn como una **receta de cocina** o una **línea de ensamblaje** para tu modelo de Machine Learning.\n",
    "\n",
    "En lugar de realizar cada paso por separado (lavar los ingredientes, cortarlos, mezclarlos, hornearlos), un Pipeline te permite definir toda la secuencia de una vez. Le entregas los ingredientes crudos (tus datos) al principio, y al final obtienes el plato terminado (la predicción).\n",
    "\n",
    "### Simplifica el Código\n",
    "\n",
    "Imagina que necesitas rellenar valores faltantes y luego escalar tus datos antes de entrenar un modelo.\n",
    "\n",
    "**Sin un Pipeline**, tu código se vería así, con pasos separados:\n",
    "\n",
    "```python\n",
    "# 1. Rellenar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test) # ¡Ojo! Solo 'transform' en test\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed) # De nuevo, solo 'transform'\n",
    "\n",
    "# 3. Entrenar el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "```\n",
    "\n",
    "Es fácil cometer errores, como aplicar `fit_transform` en el conjunto de prueba por accidente.\n",
    "\n",
    "**Con un Pipeline**, todos esos pasos se encapsulan en uno solo:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Definimos la \"receta\" completa\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Paso 1: Rellenar\n",
    "    ('scaler', StandardScaler()),              # Paso 2: Escalar\n",
    "    ('model', LogisticRegression())            # Paso 3: Modelo\n",
    "])\n",
    "\n",
    "# Entrenamos todo el pipeline de una vez\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "El código es más **limpio, corto y legible**.\n",
    "\n",
    "### Evita Errores de \"Data Leakage\" (Fuga de Datos)\n",
    "\n",
    "La **fuga de datos** es uno de los errores más peligrosos en Machine Learning. Ocurre cuando la información del conjunto de prueba (datos que el modelo \"no debería haber visto\") se \"filtra\" accidentalmente en el proceso de entrenamiento.\n",
    "\n",
    "Piénsalo como si un estudiante **viera las respuestas del examen final mientras estudia**. Obviamente, sacará una nota perfecta en el examen, pero no habrá aprendido nada y no podrá resolver problemas nuevos.\n",
    "\n",
    "Un Pipeline evita esto porque garantiza que cada paso (como el escalado de datos) se **ajuste (`fit`) únicamente con los datos de entrenamiento** y luego solo se **aplique (`transform`)** a los datos de prueba o a nuevos datos, imitando perfectamente las condiciones del mundo real.\n",
    "\n",
    "### Facilita la Serialización (Guardar el Modelo)\n",
    "\n",
    "Cuando quieres guardar tu trabajo, no solo necesitas el modelo, sino también todos los pasos de preprocesamiento que lo acompañan (el `imputer`, el `scaler`, etc.).\n",
    "\n",
    "Sin un Pipeline, tendrías que guardar cada objeto por separado, lo cual es engorroso y propenso a errores. Con un Pipeline, **guardas un solo objeto** que contiene toda la secuencia de trabajo. Es como guardar el archivo de una receta completa en lugar de una lista desordenada de ingredientes y pasos.\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Guardas TODO el flujo de trabajo en un solo archivo\n",
    "joblib.dump(pipeline, 'modelo_completo.pkl')\n",
    "\n",
    "# Para cargarlo, es igual de simple\n",
    "loaded_pipeline = joblib.load('modelo_completo.pkl')\n",
    "```\n",
    "\n",
    "### Permite Usar el Modelo con Datos Crudos\n",
    "\n",
    "Esta es la consecuencia más práctica. Una vez que tu Pipeline está entrenado y guardado, puedes darle **datos nuevos y sin procesar** (datos \"crudos\"), y él se encargará de aplicar automáticamente toda la secuencia de preprocesamiento antes de hacer la predicción.\n",
    "\n",
    "```python\n",
    "# Datos nuevos, tal como llegan del mundo real\n",
    "new_data = [[5.1, 3.5, None, 0.2]] # Tiene un valor faltante\n",
    "\n",
    "# El pipeline se encarga de todo: imputa, escala y predice\n",
    "prediction = loaded_pipeline.predict(new_data)\n",
    "print(prediction)\n",
    "```\n",
    "\n",
    "Esto hace que poner tu modelo en producción sea **infinitamente más sencillo y seguro**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd85a76-6c4a-4ddf-90c0-4f5e06a2b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Preparar características para el modelo.\n",
    "    Convertir DataFrame a lista de diccionarios (formato requerido por DictVectorizer)\n",
    "    \"\"\"\n",
    "    # Seleccionar características relevantes\n",
    "    feature_columns = [\n",
    "        'gender', 'senior_citizen', 'partner', 'dependents', 'tenure',\n",
    "        'phone_service', 'internet_service', 'online_security', 'tech_support',\n",
    "        'contract', 'payment_method', 'monthly_charges', 'total_charges'\n",
    "    ]\n",
    "    \n",
    "    # Convertir a lista de diccionarios\n",
    "    X = df[feature_columns].to_dict('records')\n",
    "    y = df['churn']\n",
    "    \n",
    "    return X, y, feature_columns\n",
    "\n",
    "def train_churn_model(df, model_type='logistic_regression'):\n",
    "    \"\"\"\n",
    "    Entrenar modelo de predicción de churn usando pipelines.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos\n",
    "        model_type: Tipo de modelo ('logistic_regression' o 'random_forest')\n",
    "    \n",
    "    Returns:\n",
    "        pipeline: Modelo entrenado\n",
    "        metrics: Métricas de evaluación\n",
    "    \"\"\"\n",
    "    print(f\"🚀 Iniciando entrenamiento de modelo: {model_type}\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X, y, feature_columns = prepare_features(df)\n",
    "    \n",
    "    # Split train/validation/test (60/20/20)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Split de datos:\")\n",
    "    print(f\"   • Entrenamiento: {len(X_train)} muestras\")\n",
    "    print(f\"   • Validación: {len(X_val)} muestras\")\n",
    "    print(f\"   • Prueba: {len(X_test)} muestras\")\n",
    "    \n",
    "    # Crear pipeline según el tipo de modelo\n",
    "    if model_type == 'logistic_regression':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            LogisticRegression(\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced'  # Manejar desbalance\n",
    "            )\n",
    "        )\n",
    "    elif model_type == 'random_forest':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                max_depth=10\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_type debe ser 'logistic_regression' o 'random_forest'\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"🔄 Entrenando modelo...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluación en conjunto de validación\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Evaluación en conjunto de prueba\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    y_test_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_type': model_type,\n",
    "        'validation_auc': val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_count': len(feature_columns),\n",
    "        'training_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✅ Entrenamiento completado!\")\n",
    "    print(f\"📈 AUC Validación: {val_auc:.4f}\")\n",
    "    print(f\"📈 AUC Prueba: {test_auc:.4f}\")\n",
    "    \n",
    "    # Reporte detallado\n",
    "    print(f\"\\n📋 Reporte de Clasificación (Conjunto de Prueba):\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['No Churn', 'Churn']))\n",
    "    \n",
    "    return pipeline, metrics, (X_test, y_test)\n",
    "\n",
    "# Entrenar modelos\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modelo 1: Regresión Logística\n",
    "lr_model, lr_metrics, (X_test, y_test) = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='logistic_regression'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Modelo 2: Random Forest\n",
    "rf_model, rf_metrics, _ = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='random_forest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c70e3-35a7-4321-b5ef-9cc2ad5188be",
   "metadata": {},
   "source": [
    "### Guardar Modelos Entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c15f21-65e0-42da-bf68-d243dba6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model_with_metadata(pipeline, metrics, model_name, models_dir=\"./models\"):\n",
    "    \"\"\"\n",
    "    Guardar modelo y sus metadatos de forma organizada.\n",
    "    \"\"\"\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Nombres de archivos\n",
    "    model_filename = f\"{model_name}_{datetime.now().strftime('%Y%m%d')}.joblib\"\n",
    "    metadata_filename = f\"{model_name}_metadata.json\"\n",
    "    \n",
    "    model_path = os.path.join(models_dir, model_filename)\n",
    "    metadata_path = os.path.join(models_dir, metadata_filename)\n",
    "    \n",
    "    # Guardar modelo usando joblib (más eficiente que pickle para sklearn)\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    \n",
    "    # Guardar metadatos\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"💾 Modelo guardado: {model_path}\")\n",
    "    print(f\"📄 Metadatos guardados: {metadata_path}\")\n",
    "    \n",
    "    return model_path, metadata_path\n",
    "\n",
    "# Guardar ambos modelos\n",
    "lr_model_path, lr_metadata_path = save_model_with_metadata(\n",
    "    lr_model, lr_metrics, \"churn_logistic_regression\"\n",
    ")\n",
    "\n",
    "rf_model_path, rf_metadata_path = save_model_with_metadata(\n",
    "    rf_model, rf_metrics, \"churn_random_forest\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Modelos guardados exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c169cc-0164-45b1-9908-bca03eda7c69",
   "metadata": {},
   "source": [
    "## 4. Creación de API con FastAPI\n",
    "\n",
    "Piensa en una API (Interfaz de Programación de Aplicaciones) como un **camarero en un restaurante**. Tú (el cliente) no necesitas saber cómo funciona la cocina; solo le das tu pedido al camarero, él lo lleva a la cocina, y te trae el plato listo. La API hace exactamente eso, pero con datos.\n",
    "\n",
    "FastAPI es un framework que te permite construir a ese \"camarero\" de una manera increíblemente eficiente, rápida y moderna.\n",
    "\n",
    "### Velocidad\n",
    "\n",
    "FastAPI está construido sobre dos pilares de alto rendimiento:\n",
    "\n",
    "1.  **Starlette**: Es un microframework web ultrarrápido. FastAPI lo usa como su motor principal para manejar las peticiones web.\n",
    "2.  **Pydantic**: Se encarga de la validación de datos y está escrito en parte en Rust, lo que lo hace extremadamente veloz.\n",
    "\n",
    "Gracias a esto, FastAPI es uno de los frameworks de Python más rápidos que existen, comparable en rendimiento a aplicaciones escritas en lenguajes compilados como Go o Node.js. Esto significa que tu API puede atender a muchos más usuarios al mismo tiempo sin ralentizarse.\n",
    "\n",
    "### Documentación Automática\n",
    "\n",
    "Este es uno de los superpoderes de FastAPI. Imagina que cada vez que escribes el código de tu API, se **escribe solo un manual de instrucciones interactivo**.\n",
    "\n",
    "FastAPI genera automáticamente una documentación en dos formatos:\n",
    "\n",
    "  * **Swagger UI**\n",
    "  * **ReDoc**\n",
    "\n",
    "Solo tienes que ir a la URL `/docs` de tu API, y encontrarás una página donde puedes ver todos tus *endpoints* (las diferentes \"órdenes\" que tu camarero puede tomar), qué datos necesitan, y qué datos devuelven. ¡Incluso puedes probar la API directamente desde esa página\\! Esto ahorra una cantidad enorme de tiempo en documentación y facilita el trabajo en equipo.\n",
    "\n",
    "### Validación con Pydantic\n",
    "\n",
    "Piensa en Pydantic como el **guardia de seguridad de tu API**. Antes de que cualquier dato entre a tu lógica, Pydantic lo revisa para asegurarse de que tiene el formato correcto.\n",
    "\n",
    "Tú defines la \"forma\" de los datos que esperas usando clases de Python, y Pydantic se encarga del resto.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "    is_offer: bool | None = None\n",
    "```\n",
    "\n",
    "Si alguien intenta enviar un `price` que no es un número, FastAPI automáticamente le devolverá un error claro y descriptivo. Esto hace tu código mucho más seguro y robusto, evitando errores inesperados.\n",
    "\n",
    "### Soporte Asíncrono (Async)\n",
    "\n",
    "Imagina un chef que solo puede hacer una cosa a la vez (síncrono). Si está esperando que el agua hierva, no puede hacer nada más.\n",
    "\n",
    "Un chef asíncrono, en cambio, pone el agua a hervir y, **mientras espera**, se pone a cortar las verduras. Es mucho más eficiente.\n",
    "\n",
    "FastAPI te permite usar `async` y `await` para manejar operaciones que toman tiempo (como llamar a otra API o consultar una base de datos) sin bloquear todo el programa. Esto es fundamental para construir aplicaciones que necesitan manejar muchas conexiones simultáneas de manera eficiente.\n",
    "\n",
    "### Tipado Nativo de Python (Type Hints)\n",
    "\n",
    "FastAPI utiliza las **pistas de tipos** de Python (`str`, `int`, `bool`, etc.) para todo. No tienes que aprender una sintaxis nueva.\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/items/{item_id}\")\n",
    "def read_item(item_id: int, q: str | None = None):\n",
    "    return {\"item_id\": item_id, \"q\": q}\n",
    "```\n",
    "\n",
    "Al declarar que `item_id` debe ser un `int`, FastAPI automáticamente:\n",
    "\n",
    "1.  **Valida** que el dato recibido es un entero.\n",
    "2.  **Documenta** que este endpoint espera un entero.\n",
    "3.  Le da a tu editor de código (como VS Code) información para **autocompletar** y detectar errores mientras escribes.\n",
    "\n",
    "En resumen, FastAPI usa características modernas de Python para darte una experiencia de desarrollo rápida, segura y muy agradable.\n",
    "\n",
    "### Decoradores\n",
    "\n",
    "Un **decorador** en Python es como ponerle un \"sombrero\" especial a una función para darle superpoderes o un nuevo comportamiento. Usas el símbolo `@` para aplicarlo.\n",
    "\n",
    "En FastAPI, los decoradores le dicen a tu \"camarero\" (la API) qué hacer cuando alguien llega a una URL específica con un método de petición concreto (GET, POST, etc.).\n",
    "\n",
    "### Los \"Sombreros\" de Operación: GET, POST, PUT, DELETE\n",
    "\n",
    "Piensa en estos decoradores como las diferentes tareas que un camarero puede realizar: tomar una orden, entregar un plato, actualizar una orden o cancelarla.\n",
    "\n",
    "  * **`@app.get(\"/ruta\")`**: **Leer datos.** Se usa cuando un cliente quiere *obtener* información. Es como preguntar el menú del día. Es la operación más común.\n",
    "\n",
    "    ```python\n",
    "    @app.get(\"/items/{item_id}\")\n",
    "    def leer_item(item_id: int):\n",
    "        # Aquí iría el código para buscar el item en una base de datos\n",
    "        return {\"item_id\": item_id, \"nombre\": \"Ejemplo de item\"}\n",
    "    ```\n",
    "\n",
    "  * **`@app.post(\"/ruta\")`**: **Crear datos.** Se usa cuando un cliente quiere *añadir* nueva información al sistema. Es como hacer un pedido nuevo en la cocina.\n",
    "\n",
    "    ```python\n",
    "    from pydantic import BaseModel\n",
    "\n",
    "    class Item(BaseModel):\n",
    "        name: str\n",
    "        price: float\n",
    "\n",
    "    @app.post(\"/items/\")\n",
    "    def crear_item(item: Item):\n",
    "        # Aquí guardarías el nuevo 'item' en la base de datos\n",
    "        return {\"mensaje\": f\"Item '{item.name}' creado exitosamente.\"}\n",
    "    ```\n",
    "\n",
    "  * **`@app.put(\"/ruta\")`**: **Actualizar datos.** Se usa para reemplazar o actualizar por completo un recurso existente. Es como cambiar tu pedido por completo.\n",
    "\n",
    "    ```python\n",
    "    @app.put(\"/items/{item_id}\")\n",
    "    def actualizar_item(item_id: int, item: Item):\n",
    "        # Lógica para actualizar el item con el id correspondiente\n",
    "        return {\"item_id\": item_id, **item.dict()}\n",
    "    ```\n",
    "\n",
    "  * **`@app.delete(\"/ruta\")`**: **Borrar datos.** Se usa para eliminar un recurso. Es como cancelar un plato de tu orden.\n",
    "\n",
    "    ```python\n",
    "    @app.delete(\"/items/{item_id}\")\n",
    "    def borrar_item(item_id: int):\n",
    "        # Lógica para borrar el item de la base de datos\n",
    "        return {\"mensaje\": f\"Item con id {item_id} ha sido eliminado.\"}\n",
    "    ```\n",
    "\n",
    "\n",
    "### Parámetros de Ruta y Consultas\n",
    "\n",
    "FastAPI es inteligente y usa los argumentos de tu función para entender los datos que llegan:\n",
    "\n",
    "1.  **Parámetros de Ruta (Path Parameters)**: Son valores que forman parte de la propia URL y se definen con llaves `{}`. En `@app.get(\"/items/{item_id}\")`, `item_id` es un parámetro de ruta. FastAPI entiende que debe extraer ese valor de la URL y pasarlo a tu función.\n",
    "\n",
    "2.  **Parámetros de Consulta (Query Parameters)**: Son parámetros opcionales que van al final de la URL después de un `?`. Por ejemplo, en `/users?role=admin`, `role` es un parámetro de consulta. Si un argumento de tu función **no** está en la ruta, FastAPI asume que es un parámetro de consulta.\n",
    "\n",
    "    ```python\n",
    "    @app.get(\"/users/\")\n",
    "    # 'limit' es un parámetro de consulta con un valor por defecto.\n",
    "    # Se usaría así: /users/ o /users/?limit=50\n",
    "    def leer_usuarios(limit: int = 100):\n",
    "        # ...lógica para devolver usuarios...\n",
    "        return {\"limite\": limit, \"usuarios\": []}\n",
    "    ```\n",
    "\n",
    "### El Cuerpo de la Petición (Request Body)\n",
    "\n",
    "Para operaciones como `POST` y `PUT`, los datos suelen ser demasiado complejos para ir en la URL. En su lugar, se envían en el \"cuerpo\" de la petición, normalmente como un objeto JSON.\n",
    "\n",
    "Aquí es donde usas un **modelo de Pydantic**. Al declarar un argumento de tu función con el tipo de un modelo Pydantic (como `item: Item`), le dices a FastAPI:\n",
    "\n",
    "1.  Espera recibir un JSON en el cuerpo de la petición.\n",
    "2.  Verifica que el JSON tenga la misma estructura que la clase `Item`.\n",
    "3.  Si es válido, convierte el JSON en un objeto de Python y pásalo a mi función.\n",
    "4.  Si no es válido, responde automáticamente con un error claro.\n",
    "\n",
    "Esto hace que manejar datos de entrada complejos sea increíblemente simple y seguro.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207ff63-ff36-42d1-9841-4578206c690f",
   "metadata": {},
   "source": [
    "### Aplicación FastAPI Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0bcea-4fbb-4ec7-8038-a9df229caec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/main.py\n",
    "from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from contextlib import asynccontextmanager\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from schemas.predictions import CustomerInput, PredictionResponse, BatchPredictionRequest\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Almacenamiento global para modelos\n",
    "ml_models: Dict[str, Any] = {}\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Gestión del ciclo de vida de la aplicación\"\"\"\n",
    "    logger.info(\"🚀 Iniciando carga de modelos...\")\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelos disponibles\n",
    "        models_dir = \"models\"\n",
    "        if os.path.exists(models_dir):\n",
    "            for filename in os.listdir(models_dir):\n",
    "                if filename.endswith('.joblib'):\n",
    "                    model_name = filename.replace('.joblib', '')\n",
    "                    model_path = os.path.join(models_dir, filename)\n",
    "                    \n",
    "                    model = joblib.load(model_path)\n",
    "                    ml_models[model_name] = model\n",
    "                    logger.info(f\"✅ Modelo cargado: {model_name}\")\n",
    "        \n",
    "        if not ml_models:\n",
    "            logger.warning(\"⚠️ No se encontraron modelos en el directorio\")\n",
    "        \n",
    "        logger.info(f\"📊 Total modelos cargados: {len(ml_models)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error cargando modelos: {e}\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    # Limpieza al cerrar\n",
    "    ml_models.clear()\n",
    "    logger.info(\"🔄 Recursos liberados\")\n",
    "\n",
    "# Crear aplicación FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Churn Prediction API\",\n",
    "    description=\"\"\"\n",
    "    🎯 **API para Predicción de Churn de Clientes**\n",
    "    \n",
    "    Esta API utiliza modelos de Machine Learning para predecir la probabilidad\n",
    "    de que un cliente cancele su servicio (churn).\n",
    "    \n",
    "    ## Características\n",
    "    \n",
    "    * **Predicciones individuales**: Predice churn para un cliente\n",
    "    * **Predicciones por lotes**: Procesa múltiples clientes\n",
    "    * **Múltiples modelos**: Soporte para diferentes algoritmos\n",
    "    * **Validación automática**: Verificación de datos de entrada\n",
    "    * **Documentación interactiva**: Swagger UI integrado\n",
    "    \n",
    "    ## Modelos Disponibles\n",
    "    \n",
    "    * **Regresión Logística**: Modelo interpretable y rápido\n",
    "    * **Random Forest**: Modelo ensemble con alta precisión\n",
    "    \"\"\",\n",
    "    version=\"1.0.0\",\n",
    "    contact={\n",
    "        \"name\": \"Equipo ML\",\n",
    "        \"email\": \"ml@tuempresa.com\",\n",
    "    },\n",
    "    license_info={\n",
    "        \"name\": \"Apache 2.0\",\n",
    "        \"url\": \"https://www.apache.org/licenses/LICENSE-2.0.html\",\n",
    "    },\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Configurar CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # En producción, especifica dominios específicos\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Dependencia para obtener modelo\n",
    "async def get_model(model_name: str = \"churn_logistic_regression_20241201\"):\n",
    "    if model_name not in ml_models:\n",
    "        available_models = list(ml_models.keys())\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Modelo '{model_name}' no encontrado. Modelos disponibles: {available_models}\"\n",
    "        )\n",
    "    return ml_models[model_name]\n",
    "\n",
    "# === ENDPOINTS ===\n",
    "\n",
    "@app.get(\"/\", tags=[\"info\"])\n",
    "async def root():\n",
    "    \"\"\"Información básica de la API\"\"\"\n",
    "    return {\n",
    "        \"message\": \"🎯 Churn Prediction API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"active\",\n",
    "        \"models_loaded\": len(ml_models),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\", tags=[\"monitoring\"])\n",
    "async def health_check():\n",
    "    \"\"\"Health check para monitoreo\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"models_count\": len(ml_models),\n",
    "        \"models_available\": list(ml_models.keys()),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/models\", tags=[\"models\"])\n",
    "async def list_models():\n",
    "    \"\"\"Listar modelos disponibles\"\"\"\n",
    "    model_info = {}\n",
    "    \n",
    "    for name, model in ml_models.items():\n",
    "        model_info[name] = {\n",
    "            \"type\": type(model).__name__,\n",
    "            \"steps\": [step[0] for step in model.steps] if hasattr(model, 'steps') else \"Pipeline\",\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"available_models\": model_info,\n",
    "        \"total_count\": len(ml_models)\n",
    "    }\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"predictions\"])\n",
    "async def predict_churn(\n",
    "    customer: CustomerInput,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    model_name: str = \"churn_logistic_regression_20241201\",\n",
    "    model = Depends(get_model)\n",
    "):\n",
    "    \"\"\"\n",
    "    🎯 Predecir probabilidad de churn para un cliente\n",
    "    \n",
    "    Utiliza el modelo especificado para calcular la probabilidad de que\n",
    "    el cliente cancele su servicio.\n",
    "    \n",
    "    - **customer**: Datos del cliente (ver esquema completo abajo)\n",
    "    - **model_name**: Nombre del modelo a utilizar\n",
    "    \n",
    "    Retorna predicción, probabilidades y metadatos del modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Convertir datos de entrada a formato de diccionario\n",
    "        customer_dict = customer.model_dump()\n",
    "        \n",
    "        # Hacer predicción\n",
    "        prediction = model.predict([customer_dict])[0]\n",
    "        probabilities = model.predict_proba([customer_dict])[0]\n",
    "        \n",
    "        # Calcular métricas\n",
    "        churn_probability = float(probabilities[1])\n",
    "        retention_probability = float(probabilities[0])\n",
    "        confidence = max(probabilities)\n",
    "        \n",
    "        # Determinar categoría de riesgo\n",
    "        if churn_probability >= 0.7:\n",
    "            risk_category = \"High\"\n",
    "        elif churn_probability >= 0.4:\n",
    "            risk_category = \"Medium\"  \n",
    "        else:\n",
    "            risk_category = \"Low\"\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        response = PredictionResponse(\n",
    "            prediction=int(prediction),\n",
    "            churn_probability=churn_probability,\n",
    "            retention_probability=retention_probability,\n",
    "            risk_category=risk_category,\n",
    "            confidence=float(confidence),\n",
    "            model_info={\n",
    "                \"name\": model_name,\n",
    "                \"type\": type(model).__name__,\n",
    "                \"version\": \"1.0.0\"\n",
    "            },\n",
    "            processing_time_ms=int(processing_time),\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        # Log en background (no bloquea la respuesta)\n",
    "        background_tasks.add_task(\n",
    "            log_prediction,\n",
    "            customer_dict,\n",
    "            response.model_dump(),\n",
    "            model_name\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en predicción: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Error procesando predicción: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Función de logging asíncrono\n",
    "async def log_prediction(customer_data: dict, prediction_result: dict, model_name: str):\n",
    "    \"\"\"Registrar predicción para monitoreo y análisis\"\"\"\n",
    "    logger.info(\n",
    "        f\"PREDICTION - Model: {model_name}, \"\n",
    "        f\"Churn_Prob: {prediction_result['churn_probability']:.3f}, \"\n",
    "        f\"Risk: {prediction_result['risk_category']}, \"\n",
    "        f\"Tenure: {customer_data.get('tenure', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True,\n",
    "        log_level=\"info\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa31081-9e77-4116-8167-0bc8856b21ed",
   "metadata": {},
   "source": [
    "## 5. Modelos de Validación con Pydantic (...)\n",
    "\n",
    "### Esquemas de Entrada y Salida\n",
    "\n",
    "```python\n",
    "# src/schemas/predictions.py\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "class RiskCategory(str, Enum):\n",
    "    \"\"\"Categorías de riesgo de churn\"\"\"\n",
    "    LOW = \"Low\"\n",
    "    MEDIUM = \"Medium\" \n",
    "    HIGH = \"High\"\n",
    "\n",
    "class ContractType(str, Enum):\n",
    "    \"\"\"Tipos de contrato disponibles\"\"\"\n",
    "    MONTH_TO_MONTH = \"Month-to-month\"\n",
    "    ONE_YEAR = \"One year\"\n",
    "    TWO_YEAR = \"Two year\"\n",
    "\n",
    "class PaymentMethod(str, Enum):\n",
    "    \"\"\"Métodos de pago disponibles\"\"\"\n",
    "    ELECTRONIC_CHECK = \"Electronic check\"\n",
    "    MAILED_CHECK = \"Mailed check\"\n",
    "    BANK_TRANSFER = \"Bank transfer (automatic)\"\n",
    "    CREDIT_CARD = \"Credit card (automatic)\"\n",
    "\n",
    "class InternetService(str, Enum):\n",
    "    \"\"\"Tipos de servicio de internet\"\"\"\n",
    "    DSL = \"DSL\"\n",
    "    FIBER_OPTIC = \"Fiber optic\"\n",
    "    NO = \"No\"\n",
    "\n",
    "class CustomerInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo de entrada para datos del cliente.\n",
    "    \n",
    "    Todos los campos son validados automáticamente por Pydantic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Información demográfica\n",
    "    gender: str = Field(\n",
    "        ..., \n",
    "        description=\"Género del cliente\",\n",
    "        example=\"Male\"\n",
    "    )\n",
    "    \n",
    "    senior_citizen: int = Field(\n",
    "        ..., \n",
    "        ge=0, \n",
    "        le=1,\n",
    "        description=\"Es ciudadano senior (0=No, 1=Sí)\",\n",
    "        example=0\n",
    "    )\n",
    "    \n",
    "    partner: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene pareja\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    dependents: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene dependientes\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    # Información del servicio\n",
    "    tenure: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Meses como cliente\",\n",
    "        example=24\n",
    "    )\n",
    "    \n",
    "    phone_service: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene servicio telefónico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    internet_service: InternetService = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de servicio de internet\",\n",
    "        example=\"Fiber optic\"\n",
    "    )\n",
    "    \n",
    "    online_security: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene seguridad online\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    tech_support: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene soporte técnico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    # Información contractual y financiera\n",
    "    contract: ContractType = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de contrato\",\n",
    "        example=\"Month-to-month\"\n",
    "    )\n",
    "    \n",
    "    payment_method: PaymentMethod = Field(\n",
    "        ...,\n",
    "        description=\"Método de pago\",\n",
    "        example=\"Electronic check\"\n",
    "    )\n",
    "    \n",
    "    monthly_charges: float = Field(\n",
    "        ...,\n",
    "        gt=0,\n",
    "        lt=200,\n",
    "        description=\"Cargos mensuales en USD\",\n",
    "        example=85.50\n",
    "    )\n",
    "    \n",
    "    total_charges: float = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Total de cargos acumulados en USD\",\n",
    "        example=2052.00\n",
    "    )\n",
    "    \n",
    "    # Campo opcional para ID del cliente\n",
    "    customer_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"ID opcional del cliente\",\n",
    "        example=\"CUST001\"\n",
    "    )\n",
    "    \n",
    "    @validator('gender')\n",
    "    def validate_gender(cls, v):\n",
    "        allowed_genders = ['Male', 'Female']\n",
    "        if v not in allowed_genders:\n",
    "            raise ValueError(f'Gender debe ser uno de: {allowed_genders}')\n",
    "        return v\n",
    "    \n",
    "    @validator('partner', 'dependents', 'phone_service')\n",
    "    def validate_yes_no_fields(cls, v, field):\n",
    "        allowed_values = ['Yes', 'No']\n",
    "        if v not in allowed_values:\n",
    "            raise ValueError(f'{field.name} debe ser \"Yes\" o \"No\"')\n",
    "        return v\n",
    "\n",
    "    class Config:\n",
    "        # Configuración del modelo Pydantic\n",
    "        str_strip_whitespace = True  # Eliminar espacios en blanco\n",
    "        validate_assignment = True   # Validar en asignaciones\n",
    "        use_enum_values = True      # Usar valores de enum\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"gender\": \"Female\",\n",
    "                \"senior_citizen\": 0,\n",
    "                \"partner\": \"Yes\",\n",
    "                \"dependents\": \"No\", \n",
    "                \"tenure\": 24,\n",
    "                \"phone_service\": \"Yes\",\n",
    "                \"internet_service\": \"Fiber optic\",\n",
    "                \"online_security\": \"No\",\n",
    "                \"tech_support\": \"Yes\",\n",
    "                \"contract\": \"Month-to-month\",\n",
    "                \"payment_method\": \"Electronic check\",\n",
    "                \"monthly_charges\": 85.50,\n",
    "                \"total_charges\": 2052.00,\n",
    "                \"customer_id\": \"CUST001\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Respuesta de la predicción de churn\"\"\"\n",
    "    \n",
    "    prediction: int = Field(\n",
    "        ...,\n",
    "        description=\"Predicción de churn (0=No Churn, 1=Churn)\",\n",
    "        example=1\n",
    "    )\n",
    "    \n",
    "    churn_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de churn\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    retention_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de retención\",\n",
    "        example=0.25\n",
    "    )\n",
    "    \n",
    "    risk_category: RiskCategory = Field(\n",
    "        ...,\n",
    "        description=\"Categoría de riesgo\",\n",
    "        example=\"High\"\n",
    "    )\n",
    "    \n",
    "    confidence: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Confianza del modelo\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    model_info: Dict[str, Any] = Field(\n",
    "        ...,\n",
    "        description=\"Información del modelo utilizado\",\n",
    "        example={\n",
    "            \"name\": \"churn_logistic_regression\",\n",
    "            \"type\": \"Pipeline\",\n",
    "            \"version\": \"1.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time_ms: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Tiempo de procesamiento en milisegundos\",\n",
    "        example=150\n",
    "    )\n",
    "    \n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Timestamp de la predicción\",\n",
    "        example=\"2024-12-01T10:30:00\"\n",
    "    )\n",
    "\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    \"\"\"Solicitud de predicción por lotes\"\"\"\n",
    "    \n",
    "    customers: List[CustomerInput] = Field(\n",
    "        ...,\n",
    "        min_items=1,\n",
    "        max_items=1000,  # Límite para evitar sobrecarga\n",
    "        description=\"Lista de clientes para predecir\"\n",
    "    )\n",
    "    \n",
    "    include_details: bool = Field(\n",
    "        True,\n",
    "        description=\"Incluir detalles completos en la respuesta\"\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cd044-6415-44bd-9968-f6b75acee71d",
   "metadata": {},
   "source": [
    "## 6. Contenedorización con Docker (...)\n",
    "\n",
    "### Dockerfile Optimizado\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile multi-stage optimizado para FastAPI + ML con uv\n",
    "\n",
    "# Etapa 1: Builder - Instalar dependencias\n",
    "FROM python:3.12-slim as builder\n",
    "\n",
    "# Instalar uv (gestor de paquetes rápido)\n",
    "COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n",
    "\n",
    "# Variables de entorno para optimización\n",
    "ENV UV_COMPILE_BYTECODE=1\n",
    "ENV UV_LINK_MODE=copy\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar archivos de dependencias\n",
    "COPY pyproject.toml ./\n",
    "\n",
    "# Crear entorno virtual e instalar dependencias\n",
    "RUN uv venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "RUN uv pip install -r pyproject.toml\n",
    "\n",
    "# Etapa 2: Runtime - Aplicación final\n",
    "FROM python:3.12-slim as runtime\n",
    "\n",
    "# Instalar dependencias del sistema necesarias para ML\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libgomp1 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Variables de entorno\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Crear usuario no-root para seguridad\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar entorno virtual desde builder\n",
    "COPY --from=builder /opt/venv /opt/venv\n",
    "\n",
    "# Copiar código de la aplicación\n",
    "COPY src/ /app/src/\n",
    "COPY models/ /app/models/\n",
    "\n",
    "# Crear directorio para logs\n",
    "RUN mkdir -p /app/logs && chown -R appuser:appuser /app\n",
    "\n",
    "# Cambiar a usuario no-root\n",
    "USER appuser\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n",
    "    CMD python -c \"import requests; requests.get('http://localhost:8000/health')\"\n",
    "\n",
    "# Puerto de la aplicación\n",
    "EXPOSE 8000\n",
    "\n",
    "# Comando por defecto - usar FastAPI CLI\n",
    "CMD [\"fastapi\", \"run\", \"src/main.py\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### Docker Compose para Desarrollo\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # Servicio principal de la API\n",
    "  churn-api:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    container_name: churn-prediction-api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - ENVIRONMENT=development\n",
    "      - LOG_LEVEL=INFO\n",
    "      - MODELS_PATH=/app/models\n",
    "    volumes:\n",
    "      # Volumen para desarrollo - hot reload\n",
    "      - ./src:/app/src:ro\n",
    "      - ./models:/app/models:ro\n",
    "      - ./logs:/app/logs\n",
    "    restart: unless-stopped\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 30s\n",
    "    networks:\n",
    "      - ml-network\n",
    "\n",
    "  # Redis para caché (opcional)\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: churn-api-cache\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    networks:\n",
    "      - ml-network\n",
    "    restart: unless-stopped\n",
    "    command: redis-server --appendonly yes\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "\n",
    "networks:\n",
    "  ml-network:\n",
    "    driver: bridge\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909b1f-9de6-4921-bbdb-63af64a803d5",
   "metadata": {},
   "source": [
    "## 7. Despliegue en la Nube con Fly.io (...)\n",
    "\n",
    "### Configuración de Fly.io\n",
    "\n",
    "```toml\n",
    "# fly.toml\n",
    "app = \"churn-prediction-api\"\n",
    "primary_region = \"mad\"  # Madrid - cambiar según tu preferencia\n",
    "\n",
    "# Build configuration\n",
    "[build]\n",
    "\n",
    "# Environment variables\n",
    "[env]\n",
    "  PORT = \"8000\"\n",
    "  ENVIRONMENT = \"production\"\n",
    "  LOG_LEVEL = \"INFO\"\n",
    "\n",
    "# HTTP service configuration\n",
    "[http_service]\n",
    "  internal_port = 8000\n",
    "  force_https = true\n",
    "  auto_stop_machines = true\n",
    "  auto_start_machines = true\n",
    "  min_machines_running = 0\n",
    "  processes = [\"app\"]\n",
    "\n",
    "  # Health checks\n",
    "  [[http_service.checks]]\n",
    "    grace_period = \"10s\"\n",
    "    interval = \"30s\"\n",
    "    method = \"GET\"\n",
    "    timeout = \"5s\"\n",
    "    path = \"/health\"\n",
    "    protocol = \"http\"\n",
    "\n",
    "# Machine configuration\n",
    "[[vm]]\n",
    "  memory = \"2gb\"      # Suficiente para modelos ML\n",
    "  cpu_kind = \"shared\"\n",
    "  cpus = 1\n",
    "  processes = [\"app\"]\n",
    "\n",
    "# Configuración de procesos\n",
    "[processes]\n",
    "  app = \"fastapi run src/main.py --host 0.0.0.0 --port 8000\"\n",
    "```\n",
    "\n",
    "### Script de Deployment\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# scripts/deploy-fly.sh\n",
    "\n",
    "# Script de deployment para Fly.io\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"🚀 Iniciando deployment a Fly.io\"\n",
    "\n",
    "# Variables\n",
    "FLY_APP_NAME=\"churn-prediction-api\"\n",
    "REGION=\"mad\"  # Madrid\n",
    "\n",
    "# Verificar que flyctl esté instalado\n",
    "check_flyctl() {\n",
    "    if ! command -v flyctl &> /dev/null; then\n",
    "        echo \"❌ flyctl no está instalado\"\n",
    "        echo \"Instala flyctl desde: https://fly.io/docs/hands-on/install-flyctl/\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"✅ flyctl instalado\"\n",
    "}\n",
    "\n",
    "# Verificar autenticación\n",
    "check_auth() {\n",
    "    if ! flyctl auth whoami &> /dev/null; then\n",
    "        echo \"⚠️ No estás autenticado en Fly.io\"\n",
    "        echo \"Ejecutando 'flyctl auth login'...\"\n",
    "        flyctl auth login\n",
    "    fi\n",
    "    echo \"✅ Autenticado en Fly.io\"\n",
    "}\n",
    "\n",
    "# Verificar que los modelos existen\n",
    "check_models() {\n",
    "    if [ ! -d \"models\" ] || [ -z \"$(ls -A models/*.joblib 2>/dev/null)\" ]; then\n",
    "        echo \"❌ No se encontraron modelos entrenados\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"✅ Modelos encontrados\"\n",
    "}\n",
    "\n",
    "# Crear aplicación si no existe\n",
    "create_or_update_app() {\n",
    "    if flyctl apps show $FLY_APP_NAME &> /dev/null; then\n",
    "        echo \"✅ Aplicación '$FLY_APP_NAME' ya existe\"\n",
    "    else\n",
    "        echo \"📱 Creando nueva aplicación...\"\n",
    "        flyctl apps create $FLY_APP_NAME --region $REGION\n",
    "        echo \"✅ Aplicación creada\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Deploy de la aplicación\n",
    "deploy_app() {\n",
    "    echo \"🚀 Iniciando deployment...\"\n",
    "    flyctl deploy --remote-only --strategy immediate\n",
    "    echo \"✅ Deployment completado\"\n",
    "}\n",
    "\n",
    "# Verificar que el deployment funcionó\n",
    "verify_deployment() {\n",
    "    local app_url=\"https://${FLY_APP_NAME}.fly.dev\"\n",
    "    \n",
    "    echo \"🔍 Verificando deployment...\"\n",
    "    sleep 10\n",
    "    \n",
    "    if curl -f \"${app_url}/health\" > /dev/null 2>&1; then\n",
    "        echo \"✅ ¡Deployment exitoso!\"\n",
    "        echo \"📖 Documentación API: ${app_url}/docs\"\n",
    "        echo \"🔍 Health check: ${app_url}/health\"\n",
    "        return 0\n",
    "    else\n",
    "        echo \"❌ Deployment falló\"\n",
    "        flyctl logs --app $FLY_APP_NAME\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Función principal\n",
    "main() {\n",
    "    echo \"════════════════════════════════════════\"\n",
    "    echo \"   🚀 DEPLOYMENT A FLY.IO\"\n",
    "    echo \"════════════════════════════════════════\"\n",
    "    \n",
    "    check_flyctl\n",
    "    check_auth\n",
    "    check_models\n",
    "    create_or_update_app\n",
    "    deploy_app\n",
    "    \n",
    "    if verify_deployment; then\n",
    "        echo \"🎉 ¡Deployment completado exitosamente!\"\n",
    "    else\n",
    "        echo \"💥 Deployment falló. Revisa los logs.\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Ejecutar función principal\n",
    "main \"$@\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e99e4-4c5d-471c-a5a7-a1a67ad45987",
   "metadata": {},
   "source": [
    "## 8. Testing de la API (...)\n",
    "\n",
    "### Tests Automatizados con Pytest\n",
    "\n",
    "```python\n",
    "# tests/test_api.py\n",
    "import pytest\n",
    "import httpx\n",
    "from fastapi.testclient import TestClient\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configurar path para imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n",
    "\n",
    "from main import app\n",
    "\n",
    "# Cliente de testing\n",
    "client = TestClient(app)\n",
    "\n",
    "class TestHealthEndpoints:\n",
    "    \"\"\"Tests para endpoints de salud y monitoreo.\"\"\"\n",
    "    \n",
    "    def test_root_endpoint(self):\n",
    "        \"\"\"Test del endpoint raíz.\"\"\"\n",
    "        response = client.get(\"/\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"message\"] == \"🎯 Churn Prediction API\"\n",
    "        assert data[\"version\"] == \"1.0.0\"\n",
    "        assert \"status\" in data\n",
    "    \n",
    "    def test_health_check(self):\n",
    "        \"\"\"Test del health check básico.\"\"\"\n",
    "        response = client.get(\"/health\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"status\"] == \"healthy\"\n",
    "        assert \"models_available\" in data\n",
    "\n",
    "class TestPredictionEndpoints:\n",
    "    \"\"\"Tests para endpoints de predicción.\"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def valid_customer_data(self):\n",
    "        \"\"\"Datos válidos de cliente para testing.\"\"\"\n",
    "        return {\n",
    "            \"gender\": \"Female\",\n",
    "            \"senior_citizen\": 0,\n",
    "            \"partner\": \"Yes\",\n",
    "            \"dependents\": \"No\",\n",
    "            \"tenure\": 24,\n",
    "            \"phone_service\": \"Yes\",\n",
    "            \"internet_service\": \"Fiber optic\",\n",
    "            \"online_security\": \"No\",\n",
    "            \"tech_support\": \"Yes\",\n",
    "            \"contract\": \"Month-to-month\",\n",
    "            \"payment_method\": \"Electronic check\",\n",
    "            \"monthly_charges\": 85.50,\n",
    "            \"total_charges\": 2052.00,\n",
    "            \"customer_id\": \"TEST001\"\n",
    "        }\n",
    "    \n",
    "    def test_predict_valid_customer(self, valid_customer_data):\n",
    "        \"\"\"Test de predicción con datos válidos.\"\"\"\n",
    "        response = client.post(\"/predict\", json=valid_customer_data)\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Verificar estructura de la respuesta\n",
    "        required_fields = [\n",
    "            \"prediction\", \"churn_probability\", \"retention_probability\",\n",
    "            \"risk_category\", \"confidence\", \"model_info\", \n",
    "            \"processing_time_ms\", \"timestamp\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            assert field in data, f\"Campo {field} faltante en respuesta\"\n",
    "        \n",
    "        # Verificar tipos y rangos\n",
    "        assert isinstance(data[\"prediction\"], int)\n",
    "        assert data[\"prediction\"] in [0, 1]\n",
    "        \n",
    "        assert 0 <= data[\"churn_probability\"] <= 1\n",
    "        assert 0 <= data[\"retention_probability\"] <= 1\n",
    "        \n",
    "        assert data[\"risk_category\"] in [\"Low\", \"Medium\", \"High\"]\n",
    "        assert data[\"processing_time_ms\"] > 0\n",
    "    \n",
    "    def test_predict_invalid_data(self):\n",
    "        \"\"\"Test con datos inválidos.\"\"\"\n",
    "        invalid_data = {\n",
    "            \"gender\": \"Other\",  # No permitido\n",
    "            \"senior_citizen\": 2,  # Fuera de rango\n",
    "            \"tenure\": -5,  # Negativo\n",
    "            \"monthly_charges\": 0  # Debe ser > 0\n",
    "        }\n",
    "        \n",
    "        response = client.post(\"/predict\", json=invalid_data)\n",
    "        assert response.status_code == 422  # Unprocessable Entity\n",
    "\n",
    "# Script para ejecutar tests\n",
    "if __name__ == \"__main__\":\n",
    "    pytest.main([__file__])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2297c-47af-4aaa-8ad2-9bbae491128b",
   "metadata": {},
   "source": [
    "## 9. Mejores Prácticas y Tips (...)\n",
    "\n",
    "### Checklist de Producción\n",
    "\n",
    "```\n",
    "# 📋 CHECKLIST DE PRODUCCIÓN PARA API DE ML\n",
    "\n",
    "## ✅ Código y Arquitectura\n",
    "- [ ] Código limpio y bien documentado\n",
    "- [ ] Separación clara entre entrenamiento e inferencia\n",
    "- [ ] Pipelines de scikit-learn para consistencia\n",
    "- [ ] Validación robusta con Pydantic\n",
    "- [ ] Manejo de errores comprehensivo\n",
    "- [ ] Logging estructurado configurado\n",
    "- [ ] Tests unitarios e integración (>80% cobertura)\n",
    "\n",
    "## ✅ Modelo y Datos\n",
    "- [ ] Modelo validado en datos de prueba\n",
    "- [ ] Métricas de rendimiento documentadas\n",
    "- [ ] Versionado de modelos implementado\n",
    "- [ ] Backup de modelos configurado\n",
    "\n",
    "## ✅ API y Rendimiento\n",
    "- [ ] Documentación API completa (Swagger)\n",
    "- [ ] Health checks funcionando\n",
    "- [ ] CORS configurado apropiadamente\n",
    "- [ ] Timeouts configurados\n",
    "\n",
    "## ✅ Seguridad\n",
    "- [ ] Variables sensibles en variables de entorno\n",
    "- [ ] Usuario no-root en contenedor Docker\n",
    "- [ ] HTTPS habilitado\n",
    "- [ ] Validación de entrada estricta\n",
    "\n",
    "## ✅ Infraestructura\n",
    "- [ ] Dockerfile optimizado (multi-stage)\n",
    "- [ ] Imagen Docker pequeña y eficiente\n",
    "- [ ] Monitoreo y alertas configurados\n",
    "- [ ] Backup y recuperación probados\n",
    "```\n",
    "\n",
    "### Optimizaciones de Rendimiento\n",
    "\n",
    "```python\n",
    "# Técnicas de optimización para APIs de ML\n",
    "\n",
    "# 1. Cache de modelos\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_model_cached(model_path: str):\n",
    "    \"\"\"Cargar modelo con cache para evitar recargas.\"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# 2. Procesamiento por lotes\n",
    "@app.post(\"/predict/batch\")\n",
    "async def batch_predict(requests: List[PredictionRequest]):\n",
    "    \"\"\"Procesar múltiples predicciones eficientemente.\"\"\"\n",
    "    # Preparar datos para predicción vectorizada\n",
    "    batch_data = [req.features.dict() for req in requests]\n",
    "    \n",
    "    # Predicción vectorizada (más eficiente)\n",
    "    predictions = model.predict(batch_data)\n",
    "    probabilities = model.predict_proba(batch_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 3. Async/Await para I/O\n",
    "async def log_prediction_async(prediction_data: dict):\n",
    "    \"\"\"Logging asíncrono para no bloquear requests.\"\"\"\n",
    "    async with aiofiles.open(\"predictions.log\", \"a\") as f:\n",
    "        await f.write(f\"{json.dumps(prediction_data)}\\n\")\n",
    "\n",
    "# 4. Configuración de Uvicorn para producción\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        workers=4,  # Número de workers basado en CPU\n",
    "        loop=\"uvloop\",  # Loop más rápido\n",
    "        http=\"httptools\",  # Parser HTTP más rápido\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ae230-1d51-4d19-b2f3-c99fd001e4da",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y Próximos Pasos\n",
    "\n",
    "### Resumen de lo Implementado\n",
    "\n",
    "🎓 **Has aprendido a implementar un sistema completo de ML en producción:**\n",
    "\n",
    "1. **Gestión moderna de proyectos** con UV y pyproject.toml\n",
    "2. **Machine Learning pipelines** con scikit-learn\n",
    "3. **API robusta** con FastAPI y validación Pydantic\n",
    "4. **Contenedorización** optimizada con Docker\n",
    "5. **Deployment** en la nube con Fly.io\n",
    "6. **Testing automatizado** con pytest\n",
    "7. **Monitoreo** y observabilidad\n",
    "\n",
    "### Valor Agregado vs. Enfoques Tradicionales\n",
    "\n",
    "| Aspecto | Tradicional (Flask + pip) | Moderno (FastAPI + uv) |\n",
    "|---------|---------------------------|------------------------|\n",
    "| **Velocidad API** | ~1000 req/s | ~3000+ req/s |\n",
    "| **Documentación** | Manual | Automática |\n",
    "| **Validación** | Manual | Automática |\n",
    "| **Install deps** | pip install (30s) | uv sync (3s) |\n",
    "| **Typing** | Opcional | Nativo |\n",
    "| **Async** | Complejo | Nativo |\n",
    "\n",
    "### Próximos Pasos Recomendados\n",
    "\n",
    "🛣️ **Extensiones avanzadas:**\n",
    "\n",
    "1. **MLOps**: Integrar MLflow para model registry\n",
    "2. **Monitoreo**: Añadir Prometheus + Grafana\n",
    "3. **Seguridad**: Implementar autenticación JWT\n",
    "4. **Escalabilidad**: Añadir Redis cache y load balancing\n",
    "5. **CI/CD**: GitHub Actions para deployment automático\n",
    "\n",
    "### Comandos Finales\n",
    "\n",
    "```bash\n",
    "# Configuración inicial\n",
    "uv sync                                 # Instalar dependencias\n",
    "python scripts/setup.py               # Configurar proyecto\n",
    "\n",
    "# Desarrollo local\n",
    "uv run uvicorn src.main:app --reload  # Servidor desarrollo\n",
    "\n",
    "# Testing\n",
    "pytest tests/ --cov=src               # Tests con cobertura\n",
    "\n",
    "# Deployment\n",
    "./scripts/deploy-fly.sh              # Deploy a producción\n",
    "```\n",
    "\n",
    "### Estructura Final del Proyecto\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "├── src/                    # Código fuente\n",
    "│   ├── main.py            # Aplicación FastAPI\n",
    "│   ├── schemas/           # Modelos Pydantic\n",
    "│   └── ml/                # Lógica ML\n",
    "├── models/                # Modelos entrenados (.joblib)\n",
    "├── tests/                 # Tests automatizados\n",
    "├── scripts/               # Scripts de utilidad\n",
    "├── Dockerfile             # Contenedorización\n",
    "├── fly.toml              # Config Fly.io\n",
    "└── pyproject.toml        # Dependencias UV\n",
    "```\n",
    "\n",
    "🎉 **¡Felicitaciones! Has implementado una API de ML moderna, escalable y lista para producción usando las mejores prácticas y herramientas de 2025.**\n",
    "\n",
    "Tu API ahora puede:\n",
    "- ✅ Servir predicciones de ML a miles de usuarios\n",
    "- ✅ Validar datos automáticamente\n",
    "- ✅ Documentarse a sí misma\n",
    "- ✅ Desplegarse globalmente en segundos\n",
    "- ✅ Monitorearse y alertar automáticamente\n",
    "- ✅ Escalarse según demanda\n",
    "\n",
    "**¡Es hora de llevarlo a producción y ver tu modelo en acción!** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de9431-3b8a-47a3-bab6-29f5000c1a0b",
   "metadata": {},
   "source": [
    "> **Nota**  \n",
    "> Esta notebook se inspiró en el workshop [**mlzoomcamp-fastapi-uv**](https://github.com/alexeygrigorev/workshops/tree/main/mlzoomcamp-fastapi-uv), ofrecido por *Alexey Grigorev*, fundador de **DataTalks.Club**. \n",
    "> Agradecimientos a la comunidad por compartir estos recursos abiertos.\n",
    "> Además, me tomé la molestia de guardar los archivos del workshop en la carpeta **`workshop_fastapi_ml`** para que tengas acceso rápido al material de referencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
