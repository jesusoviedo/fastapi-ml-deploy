{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe0e3c-fb18-4f8a-a8a8-7d3fd367cc3a",
   "metadata": {},
   "source": [
    "# Implementaci√≥n de Modelos de ML con FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215d90e-da16-4b5a-9792-c5c1afcde39f",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "Este notebook educativo completo te gu√≠a paso a paso en la implementaci√≥n de modelos de Machine Learning usando las herramientas m√°s modernas de 2025: **FastAPI**, **uv**, **Docker**, y **Fly.io**. Aprender√°s a crear un servicio web robusto para servir modelos de ML en producci√≥n.\n",
    "\n",
    "### ¬øQu√© aprender√°s?\n",
    "\n",
    "- Configuraci√≥n moderna de proyectos con **uv** (la alternativa r√°pida a pip/pipenv)\n",
    "- Entrenamiento y guardado de modelos con **scikit-learn pipelines**\n",
    "- Creaci√≥n de APIs robustas con **FastAPI**\n",
    "- Validaci√≥n de datos con **Pydantic**\n",
    "- Contenedorizaci√≥n con **Docker**\n",
    "- Despliegue en la nube con **Fly.io**\n",
    "\n",
    "### Caso de Uso: Predicci√≥n de Churn de Clientes\n",
    "\n",
    "Implementaremos un modelo para predecir si un cliente cancelar√° su servicio (churn), un problema com√∫n en telecomunicaciones y servicios de suscripci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8cc97-9d65-45e9-a1a9-251c65114bfa",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno con UV\n",
    "\n",
    "### ¬øQu√© es UV y por qu√© es tan r√°pido?\n",
    "\n",
    "Imagina que est√°s construyendo algo con bloques de LEGO. `pip` es como un ayudante que va a la tienda a por cada pieza que necesitas, una por una. Si una pieza necesita otra m√°s peque√±a, tiene que volver a la tienda. Es fiable, pero puede llevar su tiempo.\n",
    "\n",
    "**UV**, en cambio, es como un ayudante con un dron s√∫per-r√°pido y una tablet. Antes de salir, mira tu lista, calcula al instante todas las piezas y sub-piezas que necesitar√°s, y las recoge todas de la tienda en un solo viaje a m√°xima velocidad.\n",
    "\n",
    "En resumen, **UV es un instalador y gestor de entornos virtuales para Python, dise√±ado para ser extremadamente r√°pido**. Su objetivo es reemplazar a herramientas como `pip`, `pip-tools`, `venv` y `virtualenv` con una √∫nica interfaz de l√≠nea de comandos ultrarr√°pida.\n",
    "\n",
    "### El Secreto de su Velocidad\n",
    "\n",
    "La \"magia\" de UV no es una sola cosa, sino la combinaci√≥n de tres factores clave:\n",
    "\n",
    "1.  **Est√° escrito en Rust**: A diferencia de `pip` que est√° escrito en Python, UV est√° construido con Rust. Rust es un lenguaje de programaci√≥n que compila a c√≥digo m√°quina nativo, lo que le permite ejecutar tareas como la descarga e instalaci√≥n de archivos a una velocidad mucho mayor que un lenguaje interpretado como Python. ¬°Es como comparar un coche de F√≥rmula 1 (Rust) con un coche de calle (Python) para una carrera de velocidad!\n",
    "\n",
    "2.  **Resoluci√≥n de dependencias de √∫ltima generaci√≥n**: Cuando instalas un paquete (ej. `pandas`), este depende de otros (ej. `numpy`), que a su vez dependen de otros. Encontrar las versiones correctas que sean compatibles entre s√≠ es un rompecabezas complejo. UV utiliza un algoritmo muy avanzado para resolver este \"puzzle\" de dependencias de forma incre√≠blemente eficiente.\n",
    "\n",
    "3.  **Un sistema de cach√© global e inteligente**: La primera vez que UV descarga un paquete, lo guarda en una cach√© global en tu sistema. La pr√≥xima vez que necesites ese mismo paquete en *otro proyecto*, UV no lo descarga de nuevo. Simplemente crea un enlace a la versi√≥n que ya tiene guardada. Esto hace que la creaci√≥n de nuevos entornos sea casi instant√°nea.\n",
    "\n",
    "> **Dato curioso**: El creador de UV, Charlie Marsh, es tambi√©n el creador de **Ruff**, un *linter* de Python tambi√©n escrito en Rust que es cientos de veces m√°s r√°pido que sus predecesores.\n",
    "\n",
    "### UV vs. Pip y otras herramientas\n",
    "\n",
    "Pensar que UV es solo \"un pip m√°s r√°pido\" es quedarse corto. La verdadera revoluci√≥n es que **UV es una navaja suiza que reemplaza a un conjunto de herramientas**.\n",
    "\n",
    "La forma tradicional de trabajar en Python requiere un equipo de varias herramientas:\n",
    "* `venv` o `virtualenv`: Para crear y gestionar entornos virtuales aislados.\n",
    "* `pip`: Para instalar los paquetes dentro de ese entorno.\n",
    "* `pip-tools`: Una herramienta extra para compilar un `requirements.txt` a partir de un `pyproject.toml` y generar un archivo de bloqueo (`.txt`) que asegure la reproducibilidad.\n",
    "\n",
    "UV integra todas estas funciones (y m√°s) en un √∫nico ejecutable s√∫per r√°pido.\n",
    "\n",
    "Pensemos en una analog√≠a: `pip` + `venv` es como tener una caja de herramientas con un martillo, un destornillador y una llave inglesa. Funcionan bien, pero tienes que ir cambiando de herramienta para cada tarea. **UV es como una multiherramienta Leatherman de √∫ltima generaci√≥n**: tienes todo lo que necesitas en un solo lugar, es m√°s ligera y mucho m√°s eficiente. \n",
    "\n",
    "### Tabla Comparativa R√°pida\n",
    "\n",
    "| Caracter√≠stica | `pip` + `venv` | `uv` |\n",
    "| :--- | :--- | :--- |\n",
    "| **Velocidad** | Moderada. La resoluci√≥n de dependencias puede ser lenta. | **Extremadamente R√°pida**. Gracias a Rust y su resolutor avanzado. |\n",
    "| **Herramientas** | M√∫ltiples (`python -m venv`, `pip`). | **√önica y unificada** (un solo comando `uv`). |\n",
    "| **Crear Entorno** | `python -m venv .venv` | `uv venv` (notablemente m√°s r√°pido). |\n",
    "| **Instalaci√≥n** | `pip install pandas` | `uv pip install pandas` (sintaxis familiar). |\n",
    "| **Cach√© de Paquetes**| El cach√© de pip es bueno, pero a veces inconsistente. | **Cach√© global e inteligente**. Acelera la creaci√≥n de nuevos proyectos. |\n",
    "| **Reproducibilidad**| Se necesita `pip-tools` para crear un archivo `.txt` de bloqueo. | **Soporte nativo**. Puede leer y generar archivos de bloqueo (`uv.lock`, `requirements.lock`). |\n",
    "\n",
    "> La conclusi√≥n es simple: pasas de hacer malabares con 2 o 3 comandos a usar uno solo que, adem√°s, es entre **10 y 100 veces m√°s r√°pido**. En entornos de Integraci√≥n Continua (CI/CD), donde se crean y destruyen entornos constantemente, este ahorro de tiempo es gigantesco.\n",
    "\n",
    "\n",
    "### Instalaci√≥n y Configuraci√≥n\n",
    "\n",
    "```bash\n",
    "# En tu terminal, instala uv (solo una vez)\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "```\n",
    "\n",
    "> Otra alternativa: para usar `uv`, necesitas instalarlo en tu sistema. La forma m√°s f√°cil es con `pip` normal: `pip install uv`).\n",
    "\n",
    "### Primeros Pasos con UV\n",
    "\n",
    "Aqu√≠ tienes el flujo de trabajo t√≠pico para un nuevo proyecto, paso a paso.\n",
    "\n",
    "#### Paso 1: Crear el Entorno Virtual\n",
    "\n",
    "Olvida el `python -m venv .venv`. Con UV, es m√°s corto y mucho m√°s r√°pido:\n",
    "\n",
    "```bash\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "\n",
    "# Crea un entorno virtual en una carpeta llamada .venv\n",
    "uv venv\n",
    "```\n",
    "\n",
    "¬°Listo\\! En una fracci√≥n de segundo, tendr√°s tu entorno creado. Si quisieras usar una versi√≥n espec√≠fica de Python que tengas instalada, podr√≠as hacer `uv venv -p 3.11`.\n",
    "\n",
    "#### Paso 2: Activar el Entorno\n",
    "\n",
    "Esta parte es **exactamente igual** a como siempre lo has hecho. UV crea una estructura de carpetas compatible.\n",
    "\n",
    "```bash\n",
    "# En Linux o macOS\n",
    "source .venv/bin/activate\n",
    "\n",
    "# En Windows (Command Prompt)\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Una vez activado, tu terminal te mostrar√° `(.venv)` al principio de la l√≠nea.\n",
    "\n",
    "#### Paso 3: Instalar Paquetes\n",
    "\n",
    "La sintaxis es id√©ntica a la de `pip`, lo cual facilita enormemente la transici√≥n. Simplemente reemplazas `pip install` por `uv pip install`, otro comando valido es `uv add`.\n",
    "\n",
    "```bash\n",
    "# Instalar un solo paquete\n",
    "uv pip install fastapi\n",
    "\n",
    "# Instalar varios paquetes a la vez\n",
    "uv pip install \"pandas~=2.0\" pydantic\n",
    "\n",
    "# Instalar desde tu pyproject.toml\n",
    "uv pip install -e .\n",
    "```\n",
    "\n",
    "Aqu√≠ notar√°s la diferencia m√°s grande: la velocidad de descarga e instalaci√≥n es asombrosa.\n",
    "\n",
    "#### Paso 4: Generar un Archivo de Bloqueo\n",
    "\n",
    "Este es el paso que garantiza que el entorno de todo tu equipo sea id√©ntico. `uv` lee tu `pyproject.toml` y genera un archivo `requirements.lock` con las versiones exactas de cada paquete.\n",
    "\n",
    "```bash\n",
    "# Lee pyproject.toml y crea un archivo de bloqueo\n",
    "uv pip compile pyproject.toml -o requirements.lock\n",
    "```\n",
    "\n",
    "Este archivo `requirements.lock` es el que subir√≠as a tu repositorio de Git.\n",
    "\n",
    "#### Paso 5: Instalar desde el Archivo de Bloqueo\n",
    "\n",
    "Ahora, imagina que eres un nuevo desarrollador que se une al proyecto. Tienes el `pyproject.toml` y el `requirements.lock`. Despu√©s de crear y activar tu entorno, solo necesitas un comando:\n",
    "\n",
    "```bash\n",
    "# Lee el archivo de bloqueo y sincroniza tu entorno.\n",
    "# ¬°Instala, elimina y actualiza paquetes para que coincida 100%!\n",
    "uv sync requirements.lock\n",
    "```\n",
    "\n",
    "Este comando es incre√≠blemente r√°pido y eficiente. Es el que usar√≠as en tus flujos de CI/CD o para que un compa√±ero se ponga al d√≠a.\n",
    "\n",
    "### Estructura de Proyecto para ML\n",
    "\n",
    "Esta es la estructura de directorios recomendada para el proyecto, siguiendo las mejores pr√°cticas de desarrollo de software y MLOps.\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "‚îú‚îÄ‚îÄ .env                  # Variables de entorno y secretos\n",
    "‚îú‚îÄ‚îÄ .gitignore\n",
    "‚îú‚îÄ‚îÄ .python-version       # Versi√≥n de Python fijada para el proyecto\n",
    "‚îú‚îÄ‚îÄ pyproject.toml        # Definici√≥n de dependencias y configuraci√≥n\n",
    "‚îú‚îÄ‚îÄ uv.lock               # Archivo de bloqueo para reproducibilidad\n",
    "‚îú‚îÄ‚îÄ README.md\n",
    "‚îú‚îÄ‚îÄ Dockerfile            # Instrucciones para la contenedorizaci√≥n\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ artifacts/            # Modelos entrenados, serializadores y otros artefactos\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ sentiment_model_v1.pkl\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ data/                 # Datasets del proyecto (ignorado por Git)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Datos originales, sin modificar\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Datos limpios y listos para el entrenamiento\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ notebooks/            # Jupyter Notebooks para exploraci√≥n y an√°lisis\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 1.0-eda-initial-exploration.ipynb\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ src/                  # C√≥digo fuente de la aplicaci√≥n\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Punto de entrada de la API (FastAPI)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ config.py         # M√≥dulo de configuraci√≥n\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ api/              # L√≥gica de la API (endpoints)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ml/               # C√≥digo de Machine Learning\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ schemas/          # Esquemas de datos (Pydantic)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ tests/                # Pruebas autom√°ticas\n",
    "‚îî‚îÄ‚îÄ scripts/              # Scripts de utilidad (ej. para descargar datos)\n",
    "```\n",
    "\n",
    "### Explicaci√≥n de la Estructura\n",
    "\n",
    "La organizaci√≥n de este proyecto est√° dise√±ada para ser **clara, modular y escalable**. Cada directorio tiene una responsabilidad bien definida:\n",
    "\n",
    "  * **Configuraci√≥n (Ra√≠z)**: Los archivos en la ra√≠z del proyecto (`pyproject.toml`, `uv.lock`, `.python-version`, etc.) definen el entorno, las dependencias y las reglas del proyecto, asegurando que cualquier colaborador pueda replicar el entorno de desarrollo de forma id√©ntica.\n",
    "\n",
    "  * **`src/` (C√≥digo Fuente)**: Es el coraz√≥n de la aplicaci√≥n. Contiene todo el c√≥digo Python que se ejecuta como parte del servicio final. La l√≥gica est√° modularizada en subpaquetes como `api/`, `ml/` y `schemas/` para mantener el c√≥digo organizado y f√°cil de mantener.\n",
    "\n",
    "  * **`artifacts/` (Artefactos)**: Esta carpeta almacena los **productos generados por nuestro c√≥digo**, no el c√≥digo en s√≠. Su principal contenido son los modelos ya entrenados (ej. un archivo `.pkl` o `.h5`).\n",
    "\n",
    "  * **`data/` (Datos)**: Un lugar centralizado para todos los datos necesarios. Se divide en `raw` para los datos originales e inmutables y `processed` para las versiones limpias y transformadas, listas para ser usadas en el entrenamiento. Esta carpeta se a√±ade al `.gitignore` para evitar subir grandes vol√∫menes de datos al repositorio.\n",
    "\n",
    "  * **`notebooks/` (Experimentaci√≥n)**: Este es el \"laboratorio\". Contiene los Jupyter Notebooks usados para el An√°lisis Exploratorio de Datos (EDA), prototipado de modelos y visualizaciones. Separar los notebooks del c√≥digo de producci√≥n en `src/` es crucial para mantener el proyecto limpio.\n",
    "\n",
    "  * **`tests/` y `scripts/` (Soporte)**: `tests/` asegura la calidad y fiabilidad de nuestro c√≥digo mediante pruebas autom√°ticas, mientras que `scripts/` nos proporciona un lugar para herramientas de un solo uso que facilitan tareas de desarrollo.\n",
    "\n",
    "Esta separaci√≥n de responsabilidades hace que el proyecto sea m√°s f√°cil de entender, probar, y finalmente, desplegar a producci√≥n.\n",
    "\n",
    "\n",
    "### Configuraci√≥n de Dependencias (pyproject.toml)\n",
    "\n",
    "`pyproject.toml` es el cerebro detr√°s de la gesti√≥n de proyectos modernos en Python, y herramientas como **UV** est√°n dise√±adas para leerlo a la perfecci√≥n.\n",
    "\n",
    "Piensa en `pyproject.toml` como el **carn√© de identidad y el panel de control** de tu proyecto, todo en un √∫nico archivo.\n",
    "\n",
    "Antes, la configuraci√≥n de un proyecto de Python estaba repartida en varios archivos: `setup.py`, `requirements.txt`, `setup.cfg`, `MANIFEST.in`... ¬°Era un poco ca√≥tico\\! El archivo `pyproject.toml` fue introducido (en el [PEP 518](https://peps.python.org/pep-0518/)) para estandarizar y centralizar toda esa informaci√≥n en un solo lugar.\n",
    "\n",
    "### ¬øQu√© hay dentro de un `pyproject.toml`?\n",
    "\n",
    "Este archivo utiliza el formato [TOML](https://www.google.com/search?q=https://toml.io/es/) (Tom's Obvious, Minimal Language), que es muy f√°cil de leer para los humanos. Se organiza en secciones, pero nos centraremos en las m√°s importantes para las dependencias.\n",
    "\n",
    "Veamos un ejemplo pr√°ctico:\n",
    "\n",
    "```toml\n",
    "# Esta secci√≥n le dice a Python C√ìMO construir tu proyecto.\n",
    "# No necesitas preocuparte mucho por ella al principio.\n",
    "[build-system]\n",
    "requires = [\"setuptools>=61.0\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "# --- Aqu√≠ empieza lo interesante ---\n",
    "\n",
    "# Esta es la \"ficha de identidad\" de tu proyecto.\n",
    "[project]\n",
    "name = \"mi-proyecto-genial\"\n",
    "version = \"0.1.0\"\n",
    "authors = [\n",
    "  { name=\"Tu Nombre\", email=\"tu@email.com\" },\n",
    "]\n",
    "description = \"Un peque√±o proyecto de ejemplo.\"\n",
    "\n",
    "# Aqu√≠ declaras las dependencias PRINCIPALES.\n",
    "# Estas son las que se necesitan para que tu programa funcione.\n",
    "dependencies = [\n",
    "    \"fastapi>=0.90.0\", # Necesitamos fastapi, versi√≥n 0.90.0 o superior.\n",
    "    \"pandas\",         # La √∫ltima versi√≥n estable de pandas.\n",
    "]\n",
    "\n",
    "# Dependencias OPCIONALES. No son necesarias para todos los usuarios.\n",
    "[project.optional-dependencies]\n",
    "test = [\n",
    "    \"pytest\",\n",
    "    \"pytest-cov\",\n",
    "]\n",
    "docs = [\n",
    "    \"sphinx\",\n",
    "]\n",
    "\n",
    "# En esta secci√≥n, otras herramientas pueden guardar su configuraci√≥n.\n",
    "# Por ejemplo, Ruff (el linter del que hablamos) se configura aqu√≠.\n",
    "[tool.ruff]\n",
    "line-length = 88\n",
    "```\n",
    "\n",
    "Las dos secciones clave son:\n",
    "\n",
    "1.  `[project.dependencies]`: Esta es tu lista principal de \"ingredientes\". Es el equivalente moderno al archivo `requirements.txt`. Aqu√≠ pones los paquetes que tu proyecto **necesita** para funcionar.\n",
    "2.  `[project.optional-dependencies]`: Aqu√≠ defines grupos de dependencias para situaciones espec√≠ficas. El caso m√°s com√∫n es `test` (para instalar librer√≠as de testing como `pytest`) o `dev` (para herramientas de desarrollo). Esto es genial porque alguien que solo quiere *usar* tu programa no necesita descargar todas las herramientas que t√∫ usaste para *crearlo*.\n",
    "\n",
    "### ¬øY c√≥mo se relaciona esto con UV?\n",
    "\n",
    "Aqu√≠ es donde todo encaja. **UV est√° dise√±ado para leer este archivo de forma nativa y ultrarr√°pida**.\n",
    "\n",
    "  - Si ejecutas `uv pip install -e .` en la carpeta de tu proyecto, UV leer√° la lista de `[project.dependencies]` y las instalar√°.\n",
    "  - Si quieres instalar tambi√©n las dependencias de testing, ejecutar√≠as `uv pip install -e \".[test]\"`. UV entender√° que debe instalar las dependencias principales **Y** las del grupo `test`.\n",
    "\n",
    "Usar `pyproject.toml` centraliza toda la configuraci√≥n, haciendo tu proyecto m√°s limpio, reproducible y f√°cil de entender tanto para otros desarrolladores como para herramientas autom√°ticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca28df-73a6-4b9d-9052-02fe3c079616",
   "metadata": {},
   "source": [
    "## 2. Generaci√≥n de Datos Sint√©ticos para Churn\n",
    "\n",
    "### Crear Dataset de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb78d-00ff-49ca-8648-dbd2368b4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def create_churn_dataset(n_samples=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Crear un dataset sint√©tico realista para predicci√≥n de churn.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con caracter√≠sticas de clientes y etiquetas de churn\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Crear datos base\n",
    "    data = {\n",
    "        'customer_id': range(1, n_samples + 1),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'senior_citizen': np.random.choice([0, 1], n_samples, p=[0.84, 0.16]),\n",
    "        'partner': np.random.choice(['Yes', 'No'], n_samples, p=[0.48, 0.52]),\n",
    "        'dependents': np.random.choice(['Yes', 'No'], n_samples, p=[0.30, 0.70]),\n",
    "        'tenure': np.random.randint(1, 73, n_samples),  # Meses\n",
    "        'phone_service': np.random.choice(['Yes', 'No'], n_samples, p=[0.90, 0.10]),\n",
    "        'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], \n",
    "                                           n_samples, p=[0.34, 0.44, 0.22]),\n",
    "        'online_security': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                          n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                       n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], \n",
    "                                   n_samples, p=[0.55, 0.21, 0.24]),\n",
    "        'payment_method': np.random.choice([\n",
    "            'Electronic check', 'Mailed check', 'Bank transfer (automatic)', \n",
    "            'Credit card (automatic)'\n",
    "        ], n_samples, p=[0.34, 0.23, 0.22, 0.21]),\n",
    "        'monthly_charges': np.round(np.random.normal(64.76, 30.0, n_samples), 2),\n",
    "        'total_charges': np.round(np.random.normal(2283.30, 2266.77, n_samples), 2)\n",
    "    }\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Limpiar valores negativos en charges\n",
    "    df['monthly_charges'] = df['monthly_charges'].clip(lower=18.25)\n",
    "    df['total_charges'] = df['total_charges'].clip(lower=18.80)\n",
    "    \n",
    "    # Crear etiquetas de churn con l√≥gica realista\n",
    "    churn_probability = 0.2  # Baseline\n",
    "    \n",
    "    # Factores que aumentan churn\n",
    "    tenure_factor = np.where(df['tenure'] < 12, 0.15, 0)  # Clientes nuevos\n",
    "    contract_factor = np.where(df['contract'] == 'Month-to-month', 0.20, 0)  # Sin compromiso\n",
    "    payment_factor = np.where(df['payment_method'] == 'Electronic check', 0.10, 0)  # M√©todo de pago\n",
    "    charges_factor = np.where(df['monthly_charges'] > 80, 0.08, 0)  # Cargos altos\n",
    "    \n",
    "    # Factores que reducen churn\n",
    "    partner_factor = np.where(df['partner'] == 'Yes', -0.08, 0)  # Con pareja\n",
    "    dependents_factor = np.where(df['dependents'] == 'Yes', -0.05, 0)  # Con dependientes\n",
    "    long_tenure_factor = np.where(df['tenure'] > 48, -0.12, 0)  # Clientes antiguos\n",
    "    \n",
    "    # Calcular probabilidad final\n",
    "    final_probability = (churn_probability + tenure_factor + contract_factor + \n",
    "                        payment_factor + charges_factor + partner_factor + \n",
    "                        dependents_factor + long_tenure_factor)\n",
    "    \n",
    "    # Generar etiquetas de churn\n",
    "    df['churn'] = np.random.binomial(1, final_probability.clip(0.05, 0.85))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear el dataset\n",
    "print(\"Generando dataset sint√©tico de churn...\")\n",
    "churn_data = create_churn_dataset(n_samples=10000)\n",
    "\n",
    "print(f\"Dataset creado:\")\n",
    "print(f\"   ‚Ä¢ Muestras: {len(churn_data)}\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {churn_data.shape[1]-2}\")  # -2 para customer_id y churn\n",
    "print(f\"   ‚Ä¢ Tasa de churn: {churn_data['churn'].mean():.1%}\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212f30-8fd3-46bc-b753-30031c19dc63",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del Modelo con Pipelines de Scikit-learn\n",
    "\n",
    "### ¬øPor qu√© usar Pipelines?\n",
    "\n",
    "Los **pipelines** de scikit-learn combinan m√∫ltiples pasos de preprocesamiento y modelado en un solo objeto, lo que:\n",
    "- Simplifica el c√≥digo\n",
    "- Evita errores de data leakage\n",
    "- Facilita la serializaci√≥n\n",
    "- Permite usar el modelo con datos en formato crudo\n",
    "\n",
    "Pensemos en un **Pipeline** de Scikit-learn como una **receta de cocina** o una **l√≠nea de ensamblaje** para tu modelo de Machine Learning.\n",
    "\n",
    "En lugar de realizar cada paso por separado (lavar los ingredientes, cortarlos, mezclarlos, hornearlos), un Pipeline te permite definir toda la secuencia de una vez. Le entregas los ingredientes crudos (tus datos) al principio, y al final obtienes el plato terminado (la predicci√≥n).\n",
    "\n",
    "### Simplifica el C√≥digo\n",
    "\n",
    "Imagina que necesitas rellenar valores faltantes y luego escalar tus datos antes de entrenar un modelo.\n",
    "\n",
    "**Sin un Pipeline**, tu c√≥digo se ver√≠a as√≠, con pasos separados:\n",
    "\n",
    "```python\n",
    "# 1. Rellenar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test) # ¬°Ojo! Solo 'transform' en test\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed) # De nuevo, solo 'transform'\n",
    "\n",
    "# 3. Entrenar el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "```\n",
    "\n",
    "Es f√°cil cometer errores, como aplicar `fit_transform` en el conjunto de prueba por accidente.\n",
    "\n",
    "**Con un Pipeline**, todos esos pasos se encapsulan en uno solo:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Definimos la \"receta\" completa\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Paso 1: Rellenar\n",
    "    ('scaler', StandardScaler()),              # Paso 2: Escalar\n",
    "    ('model', LogisticRegression())            # Paso 3: Modelo\n",
    "])\n",
    "\n",
    "# Entrenamos todo el pipeline de una vez\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "El c√≥digo es m√°s **limpio, corto y legible**.\n",
    "\n",
    "### Evita Errores de \"Data Leakage\" (Fuga de Datos)\n",
    "\n",
    "La **fuga de datos** es uno de los errores m√°s peligrosos en Machine Learning. Ocurre cuando la informaci√≥n del conjunto de prueba (datos que el modelo \"no deber√≠a haber visto\") se \"filtra\" accidentalmente en el proceso de entrenamiento.\n",
    "\n",
    "Pi√©nsalo como si un estudiante **viera las respuestas del examen final mientras estudia**. Obviamente, sacar√° una nota perfecta en el examen, pero no habr√° aprendido nada y no podr√° resolver problemas nuevos.\n",
    "\n",
    "Un Pipeline evita esto porque garantiza que cada paso (como el escalado de datos) se **ajuste (`fit`) √∫nicamente con los datos de entrenamiento** y luego solo se **aplique (`transform`)** a los datos de prueba o a nuevos datos, imitando perfectamente las condiciones del mundo real.\n",
    "\n",
    "### Facilita la Serializaci√≥n (Guardar el Modelo)\n",
    "\n",
    "Cuando quieres guardar tu trabajo, no solo necesitas el modelo, sino tambi√©n todos los pasos de preprocesamiento que lo acompa√±an (el `imputer`, el `scaler`, etc.).\n",
    "\n",
    "Sin un Pipeline, tendr√≠as que guardar cada objeto por separado, lo cual es engorroso y propenso a errores. Con un Pipeline, **guardas un solo objeto** que contiene toda la secuencia de trabajo. Es como guardar el archivo de una receta completa en lugar de una lista desordenada de ingredientes y pasos.\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Guardas TODO el flujo de trabajo en un solo archivo\n",
    "joblib.dump(pipeline, 'modelo_completo.pkl')\n",
    "\n",
    "# Para cargarlo, es igual de simple\n",
    "loaded_pipeline = joblib.load('modelo_completo.pkl')\n",
    "```\n",
    "\n",
    "### Permite Usar el Modelo con Datos Crudos\n",
    "\n",
    "Esta es la consecuencia m√°s pr√°ctica. Una vez que tu Pipeline est√° entrenado y guardado, puedes darle **datos nuevos y sin procesar** (datos \"crudos\"), y √©l se encargar√° de aplicar autom√°ticamente toda la secuencia de preprocesamiento antes de hacer la predicci√≥n.\n",
    "\n",
    "```python\n",
    "# Datos nuevos, tal como llegan del mundo real\n",
    "new_data = [[5.1, 3.5, None, 0.2]] # Tiene un valor faltante\n",
    "\n",
    "# El pipeline se encarga de todo: imputa, escala y predice\n",
    "prediction = loaded_pipeline.predict(new_data)\n",
    "print(prediction)\n",
    "```\n",
    "\n",
    "Esto hace que poner tu modelo en producci√≥n sea **infinitamente m√°s sencillo y seguro**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd85a76-6c4a-4ddf-90c0-4f5e06a2b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Preparar caracter√≠sticas para el modelo.\n",
    "    Convertir DataFrame a lista de diccionarios (formato requerido por DictVectorizer)\n",
    "    \"\"\"\n",
    "    # Seleccionar caracter√≠sticas relevantes\n",
    "    feature_columns = [\n",
    "        'gender', 'senior_citizen', 'partner', 'dependents', 'tenure',\n",
    "        'phone_service', 'internet_service', 'online_security', 'tech_support',\n",
    "        'contract', 'payment_method', 'monthly_charges', 'total_charges'\n",
    "    ]\n",
    "    \n",
    "    # Convertir a lista de diccionarios\n",
    "    X = df[feature_columns].to_dict('records')\n",
    "    y = df['churn']\n",
    "    \n",
    "    return X, y, feature_columns\n",
    "\n",
    "def train_churn_model(df, model_type='logistic_regression'):\n",
    "    \"\"\"\n",
    "    Entrenar modelo de predicci√≥n de churn usando pipelines.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos\n",
    "        model_type: Tipo de modelo ('logistic_regression' o 'random_forest')\n",
    "    \n",
    "    Returns:\n",
    "        pipeline: Modelo entrenado\n",
    "        metrics: M√©tricas de evaluaci√≥n\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Iniciando entrenamiento de modelo: {model_type}\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X, y, feature_columns = prepare_features(df)\n",
    "    \n",
    "    # Split train/validation/test (60/20/20)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Split de datos:\")\n",
    "    print(f\"   ‚Ä¢ Entrenamiento: {len(X_train)} muestras\")\n",
    "    print(f\"   ‚Ä¢ Validaci√≥n: {len(X_val)} muestras\")\n",
    "    print(f\"   ‚Ä¢ Prueba: {len(X_test)} muestras\")\n",
    "    \n",
    "    # Crear pipeline seg√∫n el tipo de modelo\n",
    "    if model_type == 'logistic_regression':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            LogisticRegression(\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced'  # Manejar desbalance\n",
    "            )\n",
    "        )\n",
    "    elif model_type == 'random_forest':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                max_depth=10\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_type debe ser 'logistic_regression' o 'random_forest'\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"üîÑ Entrenando modelo...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluaci√≥n en conjunto de validaci√≥n\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Evaluaci√≥n en conjunto de prueba\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    y_test_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_type': model_type,\n",
    "        'validation_auc': val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_count': len(feature_columns),\n",
    "        'training_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ Entrenamiento completado!\")\n",
    "    print(f\"üìà AUC Validaci√≥n: {val_auc:.4f}\")\n",
    "    print(f\"üìà AUC Prueba: {test_auc:.4f}\")\n",
    "    \n",
    "    # Reporte detallado\n",
    "    print(f\"\\nüìã Reporte de Clasificaci√≥n (Conjunto de Prueba):\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['No Churn', 'Churn']))\n",
    "    \n",
    "    return pipeline, metrics, (X_test, y_test)\n",
    "\n",
    "# Entrenar modelos\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modelo 1: Regresi√≥n Log√≠stica\n",
    "lr_model, lr_metrics, (X_test, y_test) = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='logistic_regression'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Modelo 2: Random Forest\n",
    "rf_model, rf_metrics, _ = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='random_forest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c70e3-35a7-4321-b5ef-9cc2ad5188be",
   "metadata": {},
   "source": [
    "### Guardar Modelos Entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c15f21-65e0-42da-bf68-d243dba6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model_with_metadata(pipeline, metrics, model_name, models_dir=\"./models\"):\n",
    "    \"\"\"\n",
    "    Guardar modelo y sus metadatos de forma organizada.\n",
    "    \"\"\"\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Nombres de archivos\n",
    "    model_filename = f\"{model_name}_{datetime.now().strftime('%Y%m%d')}.joblib\"\n",
    "    metadata_filename = f\"{model_name}_metadata.json\"\n",
    "    \n",
    "    model_path = os.path.join(models_dir, model_filename)\n",
    "    metadata_path = os.path.join(models_dir, metadata_filename)\n",
    "    \n",
    "    # Guardar modelo usando joblib (m√°s eficiente que pickle para sklearn)\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    \n",
    "    # Guardar metadatos\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üíæ Modelo guardado: {model_path}\")\n",
    "    print(f\"üìÑ Metadatos guardados: {metadata_path}\")\n",
    "    \n",
    "    return model_path, metadata_path\n",
    "\n",
    "# Guardar ambos modelos\n",
    "lr_model_path, lr_metadata_path = save_model_with_metadata(\n",
    "    lr_model, lr_metrics, \"churn_logistic_regression\"\n",
    ")\n",
    "\n",
    "rf_model_path, rf_metadata_path = save_model_with_metadata(\n",
    "    rf_model, rf_metrics, \"churn_random_forest\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Modelos guardados exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c169cc-0164-45b1-9908-bca03eda7c69",
   "metadata": {},
   "source": [
    "## 4. Creaci√≥n de API con FastAPI\n",
    "\n",
    "Piensa en una API (Interfaz de Programaci√≥n de Aplicaciones) como un **camarero en un restaurante**. T√∫ (el cliente) no necesitas saber c√≥mo funciona la cocina; solo le das tu pedido al camarero, √©l lo lleva a la cocina, y te trae el plato listo. La API hace exactamente eso, pero con datos.\n",
    "\n",
    "FastAPI es un framework que te permite construir a ese \"camarero\" de una manera incre√≠blemente eficiente, r√°pida y moderna.\n",
    "\n",
    "### Velocidad\n",
    "\n",
    "FastAPI est√° construido sobre dos pilares de alto rendimiento:\n",
    "\n",
    "1.  **Starlette**: Es un microframework web ultrarr√°pido. FastAPI lo usa como su motor principal para manejar las peticiones web.\n",
    "2.  **Pydantic**: Se encarga de la validaci√≥n de datos y est√° escrito en parte en Rust, lo que lo hace extremadamente veloz.\n",
    "\n",
    "Gracias a esto, FastAPI es uno de los frameworks de Python m√°s r√°pidos que existen, comparable en rendimiento a aplicaciones escritas en lenguajes compilados como Go o Node.js. Esto significa que tu API puede atender a muchos m√°s usuarios al mismo tiempo sin ralentizarse.\n",
    "\n",
    "### Documentaci√≥n Autom√°tica\n",
    "\n",
    "Este es uno de los superpoderes de FastAPI. Imagina que cada vez que escribes el c√≥digo de tu API, se **escribe solo un manual de instrucciones interactivo**.\n",
    "\n",
    "FastAPI genera autom√°ticamente una documentaci√≥n en dos formatos:\n",
    "\n",
    "  * **Swagger UI**\n",
    "  * **ReDoc**\n",
    "\n",
    "Solo tienes que ir a la URL `/docs` de tu API, y encontrar√°s una p√°gina donde puedes ver todos tus *endpoints* (las diferentes \"√≥rdenes\" que tu camarero puede tomar), qu√© datos necesitan, y qu√© datos devuelven. ¬°Incluso puedes probar la API directamente desde esa p√°gina\\! Esto ahorra una cantidad enorme de tiempo en documentaci√≥n y facilita el trabajo en equipo.\n",
    "\n",
    "### Validaci√≥n con Pydantic\n",
    "\n",
    "Piensa en Pydantic como el **guardia de seguridad de tu API**. Antes de que cualquier dato entre a tu l√≥gica, Pydantic lo revisa para asegurarse de que tiene el formato correcto.\n",
    "\n",
    "T√∫ defines la \"forma\" de los datos que esperas usando clases de Python, y Pydantic se encarga del resto.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "    is_offer: bool | None = None\n",
    "```\n",
    "\n",
    "Si alguien intenta enviar un `price` que no es un n√∫mero, FastAPI autom√°ticamente le devolver√° un error claro y descriptivo. Esto hace tu c√≥digo mucho m√°s seguro y robusto, evitando errores inesperados.\n",
    "\n",
    "### Soporte As√≠ncrono (Async)\n",
    "\n",
    "Imagina un chef que solo puede hacer una cosa a la vez (s√≠ncrono). Si est√° esperando que el agua hierva, no puede hacer nada m√°s.\n",
    "\n",
    "Un chef as√≠ncrono, en cambio, pone el agua a hervir y, **mientras espera**, se pone a cortar las verduras. Es mucho m√°s eficiente.\n",
    "\n",
    "FastAPI te permite usar `async` y `await` para manejar operaciones que toman tiempo (como llamar a otra API o consultar una base de datos) sin bloquear todo el programa. Esto es fundamental para construir aplicaciones que necesitan manejar muchas conexiones simult√°neas de manera eficiente.\n",
    "\n",
    "### Tipado Nativo de Python (Type Hints)\n",
    "\n",
    "FastAPI utiliza las **pistas de tipos** de Python (`str`, `int`, `bool`, etc.) para todo. No tienes que aprender una sintaxis nueva.\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/items/{item_id}\")\n",
    "def read_item(item_id: int, q: str | None = None):\n",
    "    return {\"item_id\": item_id, \"q\": q}\n",
    "```\n",
    "\n",
    "Al declarar que `item_id` debe ser un `int`, FastAPI autom√°ticamente:\n",
    "\n",
    "1.  **Valida** que el dato recibido es un entero.\n",
    "2.  **Documenta** que este endpoint espera un entero.\n",
    "3.  Le da a tu editor de c√≥digo (como VS Code) informaci√≥n para **autocompletar** y detectar errores mientras escribes.\n",
    "\n",
    "En resumen, FastAPI usa caracter√≠sticas modernas de Python para darte una experiencia de desarrollo r√°pida, segura y muy agradable.\n",
    "\n",
    "### Decoradores\n",
    "\n",
    "Un **decorador** en Python es como ponerle un \"sombrero\" especial a una funci√≥n para darle superpoderes o un nuevo comportamiento. Usas el s√≠mbolo `@` para aplicarlo.\n",
    "\n",
    "En FastAPI, los decoradores le dicen a tu \"camarero\" (la API) qu√© hacer cuando alguien llega a una URL espec√≠fica con un m√©todo de petici√≥n concreto (GET, POST, etc.).\n",
    "\n",
    "### Los \"Sombreros\" de Operaci√≥n: GET, POST, PUT, DELETE\n",
    "\n",
    "Piensa en estos decoradores como las diferentes tareas que un camarero puede realizar: tomar una orden, entregar un plato, actualizar una orden o cancelarla.\n",
    "\n",
    "  * **`@app.get(\"/ruta\")`**: **Leer datos.** Se usa cuando un cliente quiere *obtener* informaci√≥n. Es como preguntar el men√∫ del d√≠a. Es la operaci√≥n m√°s com√∫n.\n",
    "\n",
    "    ```python\n",
    "    @app.get(\"/items/{item_id}\")\n",
    "    def leer_item(item_id: int):\n",
    "        # Aqu√≠ ir√≠a el c√≥digo para buscar el item en una base de datos\n",
    "        return {\"item_id\": item_id, \"nombre\": \"Ejemplo de item\"}\n",
    "    ```\n",
    "\n",
    "  * **`@app.post(\"/ruta\")`**: **Crear datos.** Se usa cuando un cliente quiere *a√±adir* nueva informaci√≥n al sistema. Es como hacer un pedido nuevo en la cocina.\n",
    "\n",
    "    ```python\n",
    "    from pydantic import BaseModel\n",
    "\n",
    "    class Item(BaseModel):\n",
    "        name: str\n",
    "        price: float\n",
    "\n",
    "    @app.post(\"/items/\")\n",
    "    def crear_item(item: Item):\n",
    "        # Aqu√≠ guardar√≠as el nuevo 'item' en la base de datos\n",
    "        return {\"mensaje\": f\"Item '{item.name}' creado exitosamente.\"}\n",
    "    ```\n",
    "\n",
    "  * **`@app.put(\"/ruta\")`**: **Actualizar datos.** Se usa para reemplazar o actualizar por completo un recurso existente. Es como cambiar tu pedido por completo.\n",
    "\n",
    "    ```python\n",
    "    @app.put(\"/items/{item_id}\")\n",
    "    def actualizar_item(item_id: int, item: Item):\n",
    "        # L√≥gica para actualizar el item con el id correspondiente\n",
    "        return {\"item_id\": item_id, **item.dict()}\n",
    "    ```\n",
    "\n",
    "  * **`@app.delete(\"/ruta\")`**: **Borrar datos.** Se usa para eliminar un recurso. Es como cancelar un plato de tu orden.\n",
    "\n",
    "    ```python\n",
    "    @app.delete(\"/items/{item_id}\")\n",
    "    def borrar_item(item_id: int):\n",
    "        # L√≥gica para borrar el item de la base de datos\n",
    "        return {\"mensaje\": f\"Item con id {item_id} ha sido eliminado.\"}\n",
    "    ```\n",
    "\n",
    "\n",
    "### Par√°metros de Ruta y Consultas\n",
    "\n",
    "FastAPI es inteligente y usa los argumentos de tu funci√≥n para entender los datos que llegan:\n",
    "\n",
    "1.  **Par√°metros de Ruta (Path Parameters)**: Son valores que forman parte de la propia URL y se definen con llaves `{}`. En `@app.get(\"/items/{item_id}\")`, `item_id` es un par√°metro de ruta. FastAPI entiende que debe extraer ese valor de la URL y pasarlo a tu funci√≥n.\n",
    "\n",
    "2.  **Par√°metros de Consulta (Query Parameters)**: Son par√°metros opcionales que van al final de la URL despu√©s de un `?`. Por ejemplo, en `/users?role=admin`, `role` es un par√°metro de consulta. Si un argumento de tu funci√≥n **no** est√° en la ruta, FastAPI asume que es un par√°metro de consulta.\n",
    "\n",
    "    ```python\n",
    "    @app.get(\"/users/\")\n",
    "    # 'limit' es un par√°metro de consulta con un valor por defecto.\n",
    "    # Se usar√≠a as√≠: /users/ o /users/?limit=50\n",
    "    def leer_usuarios(limit: int = 100):\n",
    "        # ...l√≥gica para devolver usuarios...\n",
    "        return {\"limite\": limit, \"usuarios\": []}\n",
    "    ```\n",
    "\n",
    "### El Cuerpo de la Petici√≥n (Request Body)\n",
    "\n",
    "Para operaciones como `POST` y `PUT`, los datos suelen ser demasiado complejos para ir en la URL. En su lugar, se env√≠an en el \"cuerpo\" de la petici√≥n, normalmente como un objeto JSON.\n",
    "\n",
    "Aqu√≠ es donde usas un **modelo de Pydantic**. Al declarar un argumento de tu funci√≥n con el tipo de un modelo Pydantic (como `item: Item`), le dices a FastAPI:\n",
    "\n",
    "1.  Espera recibir un JSON en el cuerpo de la petici√≥n.\n",
    "2.  Verifica que el JSON tenga la misma estructura que la clase `Item`.\n",
    "3.  Si es v√°lido, convierte el JSON en un objeto de Python y p√°salo a mi funci√≥n.\n",
    "4.  Si no es v√°lido, responde autom√°ticamente con un error claro.\n",
    "\n",
    "Esto hace que manejar datos de entrada complejos sea incre√≠blemente simple y seguro.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207ff63-ff36-42d1-9841-4578206c690f",
   "metadata": {},
   "source": [
    "### Aplicaci√≥n FastAPI Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0bcea-4fbb-4ec7-8038-a9df229caec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/main.py\n",
    "from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from contextlib import asynccontextmanager\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from schemas.predictions import CustomerInput, PredictionResponse, BatchPredictionRequest\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Almacenamiento global para modelos\n",
    "ml_models: Dict[str, Any] = {}\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Gesti√≥n del ciclo de vida de la aplicaci√≥n\"\"\"\n",
    "    logger.info(\"üöÄ Iniciando carga de modelos...\")\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelos disponibles\n",
    "        models_dir = \"models\"\n",
    "        if os.path.exists(models_dir):\n",
    "            for filename in os.listdir(models_dir):\n",
    "                if filename.endswith('.joblib'):\n",
    "                    model_name = filename.replace('.joblib', '')\n",
    "                    model_path = os.path.join(models_dir, filename)\n",
    "                    \n",
    "                    model = joblib.load(model_path)\n",
    "                    ml_models[model_name] = model\n",
    "                    logger.info(f\"‚úÖ Modelo cargado: {model_name}\")\n",
    "        \n",
    "        if not ml_models:\n",
    "            logger.warning(\"‚ö†Ô∏è No se encontraron modelos en el directorio\")\n",
    "        \n",
    "        logger.info(f\"üìä Total modelos cargados: {len(ml_models)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error cargando modelos: {e}\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    # Limpieza al cerrar\n",
    "    ml_models.clear()\n",
    "    logger.info(\"üîÑ Recursos liberados\")\n",
    "\n",
    "# Crear aplicaci√≥n FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Churn Prediction API\",\n",
    "    description=\"\"\"\n",
    "    üéØ **API para Predicci√≥n de Churn de Clientes**\n",
    "    \n",
    "    Esta API utiliza modelos de Machine Learning para predecir la probabilidad\n",
    "    de que un cliente cancele su servicio (churn).\n",
    "    \n",
    "    ## Caracter√≠sticas\n",
    "    \n",
    "    * **Predicciones individuales**: Predice churn para un cliente\n",
    "    * **Predicciones por lotes**: Procesa m√∫ltiples clientes\n",
    "    * **M√∫ltiples modelos**: Soporte para diferentes algoritmos\n",
    "    * **Validaci√≥n autom√°tica**: Verificaci√≥n de datos de entrada\n",
    "    * **Documentaci√≥n interactiva**: Swagger UI integrado\n",
    "    \n",
    "    ## Modelos Disponibles\n",
    "    \n",
    "    * **Regresi√≥n Log√≠stica**: Modelo interpretable y r√°pido\n",
    "    * **Random Forest**: Modelo ensemble con alta precisi√≥n\n",
    "    \"\"\",\n",
    "    version=\"1.0.0\",\n",
    "    contact={\n",
    "        \"name\": \"Equipo ML\",\n",
    "        \"email\": \"ml@tuempresa.com\",\n",
    "    },\n",
    "    license_info={\n",
    "        \"name\": \"Apache 2.0\",\n",
    "        \"url\": \"https://www.apache.org/licenses/LICENSE-2.0.html\",\n",
    "    },\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Configurar CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # En producci√≥n, especifica dominios espec√≠ficos\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Dependencia para obtener modelo\n",
    "async def get_model(model_name: str = \"churn_logistic_regression_20241201\"):\n",
    "    if model_name not in ml_models:\n",
    "        available_models = list(ml_models.keys())\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Modelo '{model_name}' no encontrado. Modelos disponibles: {available_models}\"\n",
    "        )\n",
    "    return ml_models[model_name]\n",
    "\n",
    "# === ENDPOINTS ===\n",
    "\n",
    "@app.get(\"/\", tags=[\"info\"])\n",
    "async def root():\n",
    "    \"\"\"Informaci√≥n b√°sica de la API\"\"\"\n",
    "    return {\n",
    "        \"message\": \"üéØ Churn Prediction API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"active\",\n",
    "        \"models_loaded\": len(ml_models),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\", tags=[\"monitoring\"])\n",
    "async def health_check():\n",
    "    \"\"\"Health check para monitoreo\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"models_count\": len(ml_models),\n",
    "        \"models_available\": list(ml_models.keys()),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/models\", tags=[\"models\"])\n",
    "async def list_models():\n",
    "    \"\"\"Listar modelos disponibles\"\"\"\n",
    "    model_info = {}\n",
    "    \n",
    "    for name, model in ml_models.items():\n",
    "        model_info[name] = {\n",
    "            \"type\": type(model).__name__,\n",
    "            \"steps\": [step[0] for step in model.steps] if hasattr(model, 'steps') else \"Pipeline\",\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"available_models\": model_info,\n",
    "        \"total_count\": len(ml_models)\n",
    "    }\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"predictions\"])\n",
    "async def predict_churn(\n",
    "    customer: CustomerInput,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    model_name: str = \"churn_logistic_regression_20241201\",\n",
    "    model = Depends(get_model)\n",
    "):\n",
    "    \"\"\"\n",
    "    üéØ Predecir probabilidad de churn para un cliente\n",
    "    \n",
    "    Utiliza el modelo especificado para calcular la probabilidad de que\n",
    "    el cliente cancele su servicio.\n",
    "    \n",
    "    - **customer**: Datos del cliente (ver esquema completo abajo)\n",
    "    - **model_name**: Nombre del modelo a utilizar\n",
    "    \n",
    "    Retorna predicci√≥n, probabilidades y metadatos del modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Convertir datos de entrada a formato de diccionario\n",
    "        customer_dict = customer.model_dump()\n",
    "        \n",
    "        # Hacer predicci√≥n\n",
    "        prediction = model.predict([customer_dict])[0]\n",
    "        probabilities = model.predict_proba([customer_dict])[0]\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        churn_probability = float(probabilities[1])\n",
    "        retention_probability = float(probabilities[0])\n",
    "        confidence = max(probabilities)\n",
    "        \n",
    "        # Determinar categor√≠a de riesgo\n",
    "        if churn_probability >= 0.7:\n",
    "            risk_category = \"High\"\n",
    "        elif churn_probability >= 0.4:\n",
    "            risk_category = \"Medium\"  \n",
    "        else:\n",
    "            risk_category = \"Low\"\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        response = PredictionResponse(\n",
    "            prediction=int(prediction),\n",
    "            churn_probability=churn_probability,\n",
    "            retention_probability=retention_probability,\n",
    "            risk_category=risk_category,\n",
    "            confidence=float(confidence),\n",
    "            model_info={\n",
    "                \"name\": model_name,\n",
    "                \"type\": type(model).__name__,\n",
    "                \"version\": \"1.0.0\"\n",
    "            },\n",
    "            processing_time_ms=int(processing_time),\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        # Log en background (no bloquea la respuesta)\n",
    "        background_tasks.add_task(\n",
    "            log_prediction,\n",
    "            customer_dict,\n",
    "            response.model_dump(),\n",
    "            model_name\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en predicci√≥n: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Error procesando predicci√≥n: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Funci√≥n de logging as√≠ncrono\n",
    "async def log_prediction(customer_data: dict, prediction_result: dict, model_name: str):\n",
    "    \"\"\"Registrar predicci√≥n para monitoreo y an√°lisis\"\"\"\n",
    "    logger.info(\n",
    "        f\"PREDICTION - Model: {model_name}, \"\n",
    "        f\"Churn_Prob: {prediction_result['churn_probability']:.3f}, \"\n",
    "        f\"Risk: {prediction_result['risk_category']}, \"\n",
    "        f\"Tenure: {customer_data.get('tenure', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True,\n",
    "        log_level=\"info\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa31081-9e77-4116-8167-0bc8856b21ed",
   "metadata": {},
   "source": [
    "## 5. Modelos de Validaci√≥n con Pydantic (...)\n",
    "\n",
    "### Esquemas de Entrada y Salida\n",
    "\n",
    "```python\n",
    "# src/schemas/predictions.py\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "class RiskCategory(str, Enum):\n",
    "    \"\"\"Categor√≠as de riesgo de churn\"\"\"\n",
    "    LOW = \"Low\"\n",
    "    MEDIUM = \"Medium\" \n",
    "    HIGH = \"High\"\n",
    "\n",
    "class ContractType(str, Enum):\n",
    "    \"\"\"Tipos de contrato disponibles\"\"\"\n",
    "    MONTH_TO_MONTH = \"Month-to-month\"\n",
    "    ONE_YEAR = \"One year\"\n",
    "    TWO_YEAR = \"Two year\"\n",
    "\n",
    "class PaymentMethod(str, Enum):\n",
    "    \"\"\"M√©todos de pago disponibles\"\"\"\n",
    "    ELECTRONIC_CHECK = \"Electronic check\"\n",
    "    MAILED_CHECK = \"Mailed check\"\n",
    "    BANK_TRANSFER = \"Bank transfer (automatic)\"\n",
    "    CREDIT_CARD = \"Credit card (automatic)\"\n",
    "\n",
    "class InternetService(str, Enum):\n",
    "    \"\"\"Tipos de servicio de internet\"\"\"\n",
    "    DSL = \"DSL\"\n",
    "    FIBER_OPTIC = \"Fiber optic\"\n",
    "    NO = \"No\"\n",
    "\n",
    "class CustomerInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo de entrada para datos del cliente.\n",
    "    \n",
    "    Todos los campos son validados autom√°ticamente por Pydantic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Informaci√≥n demogr√°fica\n",
    "    gender: str = Field(\n",
    "        ..., \n",
    "        description=\"G√©nero del cliente\",\n",
    "        example=\"Male\"\n",
    "    )\n",
    "    \n",
    "    senior_citizen: int = Field(\n",
    "        ..., \n",
    "        ge=0, \n",
    "        le=1,\n",
    "        description=\"Es ciudadano senior (0=No, 1=S√≠)\",\n",
    "        example=0\n",
    "    )\n",
    "    \n",
    "    partner: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene pareja\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    dependents: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene dependientes\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    # Informaci√≥n del servicio\n",
    "    tenure: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Meses como cliente\",\n",
    "        example=24\n",
    "    )\n",
    "    \n",
    "    phone_service: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene servicio telef√≥nico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    internet_service: InternetService = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de servicio de internet\",\n",
    "        example=\"Fiber optic\"\n",
    "    )\n",
    "    \n",
    "    online_security: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene seguridad online\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    tech_support: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene soporte t√©cnico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    # Informaci√≥n contractual y financiera\n",
    "    contract: ContractType = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de contrato\",\n",
    "        example=\"Month-to-month\"\n",
    "    )\n",
    "    \n",
    "    payment_method: PaymentMethod = Field(\n",
    "        ...,\n",
    "        description=\"M√©todo de pago\",\n",
    "        example=\"Electronic check\"\n",
    "    )\n",
    "    \n",
    "    monthly_charges: float = Field(\n",
    "        ...,\n",
    "        gt=0,\n",
    "        lt=200,\n",
    "        description=\"Cargos mensuales en USD\",\n",
    "        example=85.50\n",
    "    )\n",
    "    \n",
    "    total_charges: float = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Total de cargos acumulados en USD\",\n",
    "        example=2052.00\n",
    "    )\n",
    "    \n",
    "    # Campo opcional para ID del cliente\n",
    "    customer_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"ID opcional del cliente\",\n",
    "        example=\"CUST001\"\n",
    "    )\n",
    "    \n",
    "    @validator('gender')\n",
    "    def validate_gender(cls, v):\n",
    "        allowed_genders = ['Male', 'Female']\n",
    "        if v not in allowed_genders:\n",
    "            raise ValueError(f'Gender debe ser uno de: {allowed_genders}')\n",
    "        return v\n",
    "    \n",
    "    @validator('partner', 'dependents', 'phone_service')\n",
    "    def validate_yes_no_fields(cls, v, field):\n",
    "        allowed_values = ['Yes', 'No']\n",
    "        if v not in allowed_values:\n",
    "            raise ValueError(f'{field.name} debe ser \"Yes\" o \"No\"')\n",
    "        return v\n",
    "\n",
    "    class Config:\n",
    "        # Configuraci√≥n del modelo Pydantic\n",
    "        str_strip_whitespace = True  # Eliminar espacios en blanco\n",
    "        validate_assignment = True   # Validar en asignaciones\n",
    "        use_enum_values = True      # Usar valores de enum\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"gender\": \"Female\",\n",
    "                \"senior_citizen\": 0,\n",
    "                \"partner\": \"Yes\",\n",
    "                \"dependents\": \"No\", \n",
    "                \"tenure\": 24,\n",
    "                \"phone_service\": \"Yes\",\n",
    "                \"internet_service\": \"Fiber optic\",\n",
    "                \"online_security\": \"No\",\n",
    "                \"tech_support\": \"Yes\",\n",
    "                \"contract\": \"Month-to-month\",\n",
    "                \"payment_method\": \"Electronic check\",\n",
    "                \"monthly_charges\": 85.50,\n",
    "                \"total_charges\": 2052.00,\n",
    "                \"customer_id\": \"CUST001\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Respuesta de la predicci√≥n de churn\"\"\"\n",
    "    \n",
    "    prediction: int = Field(\n",
    "        ...,\n",
    "        description=\"Predicci√≥n de churn (0=No Churn, 1=Churn)\",\n",
    "        example=1\n",
    "    )\n",
    "    \n",
    "    churn_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de churn\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    retention_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de retenci√≥n\",\n",
    "        example=0.25\n",
    "    )\n",
    "    \n",
    "    risk_category: RiskCategory = Field(\n",
    "        ...,\n",
    "        description=\"Categor√≠a de riesgo\",\n",
    "        example=\"High\"\n",
    "    )\n",
    "    \n",
    "    confidence: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Confianza del modelo\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    model_info: Dict[str, Any] = Field(\n",
    "        ...,\n",
    "        description=\"Informaci√≥n del modelo utilizado\",\n",
    "        example={\n",
    "            \"name\": \"churn_logistic_regression\",\n",
    "            \"type\": \"Pipeline\",\n",
    "            \"version\": \"1.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time_ms: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Tiempo de procesamiento en milisegundos\",\n",
    "        example=150\n",
    "    )\n",
    "    \n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Timestamp de la predicci√≥n\",\n",
    "        example=\"2024-12-01T10:30:00\"\n",
    "    )\n",
    "\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    \"\"\"Solicitud de predicci√≥n por lotes\"\"\"\n",
    "    \n",
    "    customers: List[CustomerInput] = Field(\n",
    "        ...,\n",
    "        min_items=1,\n",
    "        max_items=1000,  # L√≠mite para evitar sobrecarga\n",
    "        description=\"Lista de clientes para predecir\"\n",
    "    )\n",
    "    \n",
    "    include_details: bool = Field(\n",
    "        True,\n",
    "        description=\"Incluir detalles completos en la respuesta\"\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cd044-6415-44bd-9968-f6b75acee71d",
   "metadata": {},
   "source": [
    "## 6. Contenedorizaci√≥n con Docker (...)\n",
    "\n",
    "### Dockerfile Optimizado\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile multi-stage optimizado para FastAPI + ML con uv\n",
    "\n",
    "# Etapa 1: Builder - Instalar dependencias\n",
    "FROM python:3.12-slim as builder\n",
    "\n",
    "# Instalar uv (gestor de paquetes r√°pido)\n",
    "COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n",
    "\n",
    "# Variables de entorno para optimizaci√≥n\n",
    "ENV UV_COMPILE_BYTECODE=1\n",
    "ENV UV_LINK_MODE=copy\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar archivos de dependencias\n",
    "COPY pyproject.toml ./\n",
    "\n",
    "# Crear entorno virtual e instalar dependencias\n",
    "RUN uv venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "RUN uv pip install -r pyproject.toml\n",
    "\n",
    "# Etapa 2: Runtime - Aplicaci√≥n final\n",
    "FROM python:3.12-slim as runtime\n",
    "\n",
    "# Instalar dependencias del sistema necesarias para ML\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libgomp1 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Variables de entorno\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Crear usuario no-root para seguridad\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar entorno virtual desde builder\n",
    "COPY --from=builder /opt/venv /opt/venv\n",
    "\n",
    "# Copiar c√≥digo de la aplicaci√≥n\n",
    "COPY src/ /app/src/\n",
    "COPY models/ /app/models/\n",
    "\n",
    "# Crear directorio para logs\n",
    "RUN mkdir -p /app/logs && chown -R appuser:appuser /app\n",
    "\n",
    "# Cambiar a usuario no-root\n",
    "USER appuser\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n",
    "    CMD python -c \"import requests; requests.get('http://localhost:8000/health')\"\n",
    "\n",
    "# Puerto de la aplicaci√≥n\n",
    "EXPOSE 8000\n",
    "\n",
    "# Comando por defecto - usar FastAPI CLI\n",
    "CMD [\"fastapi\", \"run\", \"src/main.py\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### Docker Compose para Desarrollo\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # Servicio principal de la API\n",
    "  churn-api:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    container_name: churn-prediction-api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - ENVIRONMENT=development\n",
    "      - LOG_LEVEL=INFO\n",
    "      - MODELS_PATH=/app/models\n",
    "    volumes:\n",
    "      # Volumen para desarrollo - hot reload\n",
    "      - ./src:/app/src:ro\n",
    "      - ./models:/app/models:ro\n",
    "      - ./logs:/app/logs\n",
    "    restart: unless-stopped\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 30s\n",
    "    networks:\n",
    "      - ml-network\n",
    "\n",
    "  # Redis para cach√© (opcional)\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: churn-api-cache\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    networks:\n",
    "      - ml-network\n",
    "    restart: unless-stopped\n",
    "    command: redis-server --appendonly yes\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "\n",
    "networks:\n",
    "  ml-network:\n",
    "    driver: bridge\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909b1f-9de6-4921-bbdb-63af64a803d5",
   "metadata": {},
   "source": [
    "## 7. Despliegue en la Nube con Fly.io (...)\n",
    "\n",
    "### Configuraci√≥n de Fly.io\n",
    "\n",
    "```toml\n",
    "# fly.toml\n",
    "app = \"churn-prediction-api\"\n",
    "primary_region = \"mad\"  # Madrid - cambiar seg√∫n tu preferencia\n",
    "\n",
    "# Build configuration\n",
    "[build]\n",
    "\n",
    "# Environment variables\n",
    "[env]\n",
    "  PORT = \"8000\"\n",
    "  ENVIRONMENT = \"production\"\n",
    "  LOG_LEVEL = \"INFO\"\n",
    "\n",
    "# HTTP service configuration\n",
    "[http_service]\n",
    "  internal_port = 8000\n",
    "  force_https = true\n",
    "  auto_stop_machines = true\n",
    "  auto_start_machines = true\n",
    "  min_machines_running = 0\n",
    "  processes = [\"app\"]\n",
    "\n",
    "  # Health checks\n",
    "  [[http_service.checks]]\n",
    "    grace_period = \"10s\"\n",
    "    interval = \"30s\"\n",
    "    method = \"GET\"\n",
    "    timeout = \"5s\"\n",
    "    path = \"/health\"\n",
    "    protocol = \"http\"\n",
    "\n",
    "# Machine configuration\n",
    "[[vm]]\n",
    "  memory = \"2gb\"      # Suficiente para modelos ML\n",
    "  cpu_kind = \"shared\"\n",
    "  cpus = 1\n",
    "  processes = [\"app\"]\n",
    "\n",
    "# Configuraci√≥n de procesos\n",
    "[processes]\n",
    "  app = \"fastapi run src/main.py --host 0.0.0.0 --port 8000\"\n",
    "```\n",
    "\n",
    "### Script de Deployment\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# scripts/deploy-fly.sh\n",
    "\n",
    "# Script de deployment para Fly.io\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"üöÄ Iniciando deployment a Fly.io\"\n",
    "\n",
    "# Variables\n",
    "FLY_APP_NAME=\"churn-prediction-api\"\n",
    "REGION=\"mad\"  # Madrid\n",
    "\n",
    "# Verificar que flyctl est√© instalado\n",
    "check_flyctl() {\n",
    "    if ! command -v flyctl &> /dev/null; then\n",
    "        echo \"‚ùå flyctl no est√° instalado\"\n",
    "        echo \"Instala flyctl desde: https://fly.io/docs/hands-on/install-flyctl/\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"‚úÖ flyctl instalado\"\n",
    "}\n",
    "\n",
    "# Verificar autenticaci√≥n\n",
    "check_auth() {\n",
    "    if ! flyctl auth whoami &> /dev/null; then\n",
    "        echo \"‚ö†Ô∏è No est√°s autenticado en Fly.io\"\n",
    "        echo \"Ejecutando 'flyctl auth login'...\"\n",
    "        flyctl auth login\n",
    "    fi\n",
    "    echo \"‚úÖ Autenticado en Fly.io\"\n",
    "}\n",
    "\n",
    "# Verificar que los modelos existen\n",
    "check_models() {\n",
    "    if [ ! -d \"models\" ] || [ -z \"$(ls -A models/*.joblib 2>/dev/null)\" ]; then\n",
    "        echo \"‚ùå No se encontraron modelos entrenados\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"‚úÖ Modelos encontrados\"\n",
    "}\n",
    "\n",
    "# Crear aplicaci√≥n si no existe\n",
    "create_or_update_app() {\n",
    "    if flyctl apps show $FLY_APP_NAME &> /dev/null; then\n",
    "        echo \"‚úÖ Aplicaci√≥n '$FLY_APP_NAME' ya existe\"\n",
    "    else\n",
    "        echo \"üì± Creando nueva aplicaci√≥n...\"\n",
    "        flyctl apps create $FLY_APP_NAME --region $REGION\n",
    "        echo \"‚úÖ Aplicaci√≥n creada\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Deploy de la aplicaci√≥n\n",
    "deploy_app() {\n",
    "    echo \"üöÄ Iniciando deployment...\"\n",
    "    flyctl deploy --remote-only --strategy immediate\n",
    "    echo \"‚úÖ Deployment completado\"\n",
    "}\n",
    "\n",
    "# Verificar que el deployment funcion√≥\n",
    "verify_deployment() {\n",
    "    local app_url=\"https://${FLY_APP_NAME}.fly.dev\"\n",
    "    \n",
    "    echo \"üîç Verificando deployment...\"\n",
    "    sleep 10\n",
    "    \n",
    "    if curl -f \"${app_url}/health\" > /dev/null 2>&1; then\n",
    "        echo \"‚úÖ ¬°Deployment exitoso!\"\n",
    "        echo \"üìñ Documentaci√≥n API: ${app_url}/docs\"\n",
    "        echo \"üîç Health check: ${app_url}/health\"\n",
    "        return 0\n",
    "    else\n",
    "        echo \"‚ùå Deployment fall√≥\"\n",
    "        flyctl logs --app $FLY_APP_NAME\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Funci√≥n principal\n",
    "main() {\n",
    "    echo \"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\"\n",
    "    echo \"   üöÄ DEPLOYMENT A FLY.IO\"\n",
    "    echo \"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\"\n",
    "    \n",
    "    check_flyctl\n",
    "    check_auth\n",
    "    check_models\n",
    "    create_or_update_app\n",
    "    deploy_app\n",
    "    \n",
    "    if verify_deployment; then\n",
    "        echo \"üéâ ¬°Deployment completado exitosamente!\"\n",
    "    else\n",
    "        echo \"üí• Deployment fall√≥. Revisa los logs.\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Ejecutar funci√≥n principal\n",
    "main \"$@\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e99e4-4c5d-471c-a5a7-a1a67ad45987",
   "metadata": {},
   "source": [
    "## 8. Testing de la API (...)\n",
    "\n",
    "### Tests Automatizados con Pytest\n",
    "\n",
    "```python\n",
    "# tests/test_api.py\n",
    "import pytest\n",
    "import httpx\n",
    "from fastapi.testclient import TestClient\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configurar path para imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n",
    "\n",
    "from main import app\n",
    "\n",
    "# Cliente de testing\n",
    "client = TestClient(app)\n",
    "\n",
    "class TestHealthEndpoints:\n",
    "    \"\"\"Tests para endpoints de salud y monitoreo.\"\"\"\n",
    "    \n",
    "    def test_root_endpoint(self):\n",
    "        \"\"\"Test del endpoint ra√≠z.\"\"\"\n",
    "        response = client.get(\"/\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"message\"] == \"üéØ Churn Prediction API\"\n",
    "        assert data[\"version\"] == \"1.0.0\"\n",
    "        assert \"status\" in data\n",
    "    \n",
    "    def test_health_check(self):\n",
    "        \"\"\"Test del health check b√°sico.\"\"\"\n",
    "        response = client.get(\"/health\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"status\"] == \"healthy\"\n",
    "        assert \"models_available\" in data\n",
    "\n",
    "class TestPredictionEndpoints:\n",
    "    \"\"\"Tests para endpoints de predicci√≥n.\"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def valid_customer_data(self):\n",
    "        \"\"\"Datos v√°lidos de cliente para testing.\"\"\"\n",
    "        return {\n",
    "            \"gender\": \"Female\",\n",
    "            \"senior_citizen\": 0,\n",
    "            \"partner\": \"Yes\",\n",
    "            \"dependents\": \"No\",\n",
    "            \"tenure\": 24,\n",
    "            \"phone_service\": \"Yes\",\n",
    "            \"internet_service\": \"Fiber optic\",\n",
    "            \"online_security\": \"No\",\n",
    "            \"tech_support\": \"Yes\",\n",
    "            \"contract\": \"Month-to-month\",\n",
    "            \"payment_method\": \"Electronic check\",\n",
    "            \"monthly_charges\": 85.50,\n",
    "            \"total_charges\": 2052.00,\n",
    "            \"customer_id\": \"TEST001\"\n",
    "        }\n",
    "    \n",
    "    def test_predict_valid_customer(self, valid_customer_data):\n",
    "        \"\"\"Test de predicci√≥n con datos v√°lidos.\"\"\"\n",
    "        response = client.post(\"/predict\", json=valid_customer_data)\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Verificar estructura de la respuesta\n",
    "        required_fields = [\n",
    "            \"prediction\", \"churn_probability\", \"retention_probability\",\n",
    "            \"risk_category\", \"confidence\", \"model_info\", \n",
    "            \"processing_time_ms\", \"timestamp\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            assert field in data, f\"Campo {field} faltante en respuesta\"\n",
    "        \n",
    "        # Verificar tipos y rangos\n",
    "        assert isinstance(data[\"prediction\"], int)\n",
    "        assert data[\"prediction\"] in [0, 1]\n",
    "        \n",
    "        assert 0 <= data[\"churn_probability\"] <= 1\n",
    "        assert 0 <= data[\"retention_probability\"] <= 1\n",
    "        \n",
    "        assert data[\"risk_category\"] in [\"Low\", \"Medium\", \"High\"]\n",
    "        assert data[\"processing_time_ms\"] > 0\n",
    "    \n",
    "    def test_predict_invalid_data(self):\n",
    "        \"\"\"Test con datos inv√°lidos.\"\"\"\n",
    "        invalid_data = {\n",
    "            \"gender\": \"Other\",  # No permitido\n",
    "            \"senior_citizen\": 2,  # Fuera de rango\n",
    "            \"tenure\": -5,  # Negativo\n",
    "            \"monthly_charges\": 0  # Debe ser > 0\n",
    "        }\n",
    "        \n",
    "        response = client.post(\"/predict\", json=invalid_data)\n",
    "        assert response.status_code == 422  # Unprocessable Entity\n",
    "\n",
    "# Script para ejecutar tests\n",
    "if __name__ == \"__main__\":\n",
    "    pytest.main([__file__])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2297c-47af-4aaa-8ad2-9bbae491128b",
   "metadata": {},
   "source": [
    "## 9. Mejores Pr√°cticas y Tips (...)\n",
    "\n",
    "### Checklist de Producci√≥n\n",
    "\n",
    "```\n",
    "# üìã CHECKLIST DE PRODUCCI√ìN PARA API DE ML\n",
    "\n",
    "## ‚úÖ C√≥digo y Arquitectura\n",
    "- [ ] C√≥digo limpio y bien documentado\n",
    "- [ ] Separaci√≥n clara entre entrenamiento e inferencia\n",
    "- [ ] Pipelines de scikit-learn para consistencia\n",
    "- [ ] Validaci√≥n robusta con Pydantic\n",
    "- [ ] Manejo de errores comprehensivo\n",
    "- [ ] Logging estructurado configurado\n",
    "- [ ] Tests unitarios e integraci√≥n (>80% cobertura)\n",
    "\n",
    "## ‚úÖ Modelo y Datos\n",
    "- [ ] Modelo validado en datos de prueba\n",
    "- [ ] M√©tricas de rendimiento documentadas\n",
    "- [ ] Versionado de modelos implementado\n",
    "- [ ] Backup de modelos configurado\n",
    "\n",
    "## ‚úÖ API y Rendimiento\n",
    "- [ ] Documentaci√≥n API completa (Swagger)\n",
    "- [ ] Health checks funcionando\n",
    "- [ ] CORS configurado apropiadamente\n",
    "- [ ] Timeouts configurados\n",
    "\n",
    "## ‚úÖ Seguridad\n",
    "- [ ] Variables sensibles en variables de entorno\n",
    "- [ ] Usuario no-root en contenedor Docker\n",
    "- [ ] HTTPS habilitado\n",
    "- [ ] Validaci√≥n de entrada estricta\n",
    "\n",
    "## ‚úÖ Infraestructura\n",
    "- [ ] Dockerfile optimizado (multi-stage)\n",
    "- [ ] Imagen Docker peque√±a y eficiente\n",
    "- [ ] Monitoreo y alertas configurados\n",
    "- [ ] Backup y recuperaci√≥n probados\n",
    "```\n",
    "\n",
    "### Optimizaciones de Rendimiento\n",
    "\n",
    "```python\n",
    "# T√©cnicas de optimizaci√≥n para APIs de ML\n",
    "\n",
    "# 1. Cache de modelos\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_model_cached(model_path: str):\n",
    "    \"\"\"Cargar modelo con cache para evitar recargas.\"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# 2. Procesamiento por lotes\n",
    "@app.post(\"/predict/batch\")\n",
    "async def batch_predict(requests: List[PredictionRequest]):\n",
    "    \"\"\"Procesar m√∫ltiples predicciones eficientemente.\"\"\"\n",
    "    # Preparar datos para predicci√≥n vectorizada\n",
    "    batch_data = [req.features.dict() for req in requests]\n",
    "    \n",
    "    # Predicci√≥n vectorizada (m√°s eficiente)\n",
    "    predictions = model.predict(batch_data)\n",
    "    probabilities = model.predict_proba(batch_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 3. Async/Await para I/O\n",
    "async def log_prediction_async(prediction_data: dict):\n",
    "    \"\"\"Logging as√≠ncrono para no bloquear requests.\"\"\"\n",
    "    async with aiofiles.open(\"predictions.log\", \"a\") as f:\n",
    "        await f.write(f\"{json.dumps(prediction_data)}\\n\")\n",
    "\n",
    "# 4. Configuraci√≥n de Uvicorn para producci√≥n\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        workers=4,  # N√∫mero de workers basado en CPU\n",
    "        loop=\"uvloop\",  # Loop m√°s r√°pido\n",
    "        http=\"httptools\",  # Parser HTTP m√°s r√°pido\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ae230-1d51-4d19-b2f3-c99fd001e4da",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "### Resumen de lo Implementado\n",
    "\n",
    "üéì **Has aprendido a implementar un sistema completo de ML en producci√≥n:**\n",
    "\n",
    "1. **Gesti√≥n moderna de proyectos** con UV y pyproject.toml\n",
    "2. **Machine Learning pipelines** con scikit-learn\n",
    "3. **API robusta** con FastAPI y validaci√≥n Pydantic\n",
    "4. **Contenedorizaci√≥n** optimizada con Docker\n",
    "5. **Deployment** en la nube con Fly.io\n",
    "6. **Testing automatizado** con pytest\n",
    "7. **Monitoreo** y observabilidad\n",
    "\n",
    "### Valor Agregado vs. Enfoques Tradicionales\n",
    "\n",
    "| Aspecto | Tradicional (Flask + pip) | Moderno (FastAPI + uv) |\n",
    "|---------|---------------------------|------------------------|\n",
    "| **Velocidad API** | ~1000 req/s | ~3000+ req/s |\n",
    "| **Documentaci√≥n** | Manual | Autom√°tica |\n",
    "| **Validaci√≥n** | Manual | Autom√°tica |\n",
    "| **Install deps** | pip install (30s) | uv sync (3s) |\n",
    "| **Typing** | Opcional | Nativo |\n",
    "| **Async** | Complejo | Nativo |\n",
    "\n",
    "### Pr√≥ximos Pasos Recomendados\n",
    "\n",
    "üõ£Ô∏è **Extensiones avanzadas:**\n",
    "\n",
    "1. **MLOps**: Integrar MLflow para model registry\n",
    "2. **Monitoreo**: A√±adir Prometheus + Grafana\n",
    "3. **Seguridad**: Implementar autenticaci√≥n JWT\n",
    "4. **Escalabilidad**: A√±adir Redis cache y load balancing\n",
    "5. **CI/CD**: GitHub Actions para deployment autom√°tico\n",
    "\n",
    "### Comandos Finales\n",
    "\n",
    "```bash\n",
    "# Configuraci√≥n inicial\n",
    "uv sync                                 # Instalar dependencias\n",
    "python scripts/setup.py               # Configurar proyecto\n",
    "\n",
    "# Desarrollo local\n",
    "uv run uvicorn src.main:app --reload  # Servidor desarrollo\n",
    "\n",
    "# Testing\n",
    "pytest tests/ --cov=src               # Tests con cobertura\n",
    "\n",
    "# Deployment\n",
    "./scripts/deploy-fly.sh              # Deploy a producci√≥n\n",
    "```\n",
    "\n",
    "### Estructura Final del Proyecto\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Aplicaci√≥n FastAPI\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Modelos Pydantic\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ml/                # L√≥gica ML\n",
    "‚îú‚îÄ‚îÄ models/                # Modelos entrenados (.joblib)\n",
    "‚îú‚îÄ‚îÄ tests/                 # Tests automatizados\n",
    "‚îú‚îÄ‚îÄ scripts/               # Scripts de utilidad\n",
    "‚îú‚îÄ‚îÄ Dockerfile             # Contenedorizaci√≥n\n",
    "‚îú‚îÄ‚îÄ fly.toml              # Config Fly.io\n",
    "‚îî‚îÄ‚îÄ pyproject.toml        # Dependencias UV\n",
    "```\n",
    "\n",
    "üéâ **¬°Felicitaciones! Has implementado una API de ML moderna, escalable y lista para producci√≥n usando las mejores pr√°cticas y herramientas de 2025.**\n",
    "\n",
    "Tu API ahora puede:\n",
    "- ‚úÖ Servir predicciones de ML a miles de usuarios\n",
    "- ‚úÖ Validar datos autom√°ticamente\n",
    "- ‚úÖ Documentarse a s√≠ misma\n",
    "- ‚úÖ Desplegarse globalmente en segundos\n",
    "- ‚úÖ Monitorearse y alertar autom√°ticamente\n",
    "- ‚úÖ Escalarse seg√∫n demanda\n",
    "\n",
    "**¬°Es hora de llevarlo a producci√≥n y ver tu modelo en acci√≥n!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de9431-3b8a-47a3-bab6-29f5000c1a0b",
   "metadata": {},
   "source": [
    "> **Nota**  \n",
    "> Esta notebook se inspir√≥ en el workshop [**mlzoomcamp-fastapi-uv**](https://github.com/alexeygrigorev/workshops/tree/main/mlzoomcamp-fastapi-uv), ofrecido por *Alexey Grigorev*, fundador de **DataTalks.Club**. \n",
    "> Agradecimientos a la comunidad por compartir estos recursos abiertos.\n",
    "> Adem√°s, me tom√© la molestia de guardar los archivos del workshop en la carpeta **`workshop_fastapi_ml`** para que tengas acceso r√°pido al material de referencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
