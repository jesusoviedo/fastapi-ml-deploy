{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe0e3c-fb18-4f8a-a8a8-7d3fd367cc3a",
   "metadata": {},
   "source": [
    "# Implementaci√≥n de Modelos de ML con FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215d90e-da16-4b5a-9792-c5c1afcde39f",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "Este notebook educativo completo te gu√≠a paso a paso en la implementaci√≥n de modelos de Machine Learning usando las herramientas m√°s modernas de 2025: **FastAPI**, **uv**, **Docker**, y **Fly.io**. Aprender√°s a crear un servicio web robusto para servir modelos de ML en producci√≥n.\n",
    "\n",
    "### ¬øQu√© aprender√°s?\n",
    "\n",
    "- Configuraci√≥n moderna de proyectos con **uv** (la alternativa r√°pida a pip/pipenv)\n",
    "- Entrenamiento y guardado de modelos con **scikit-learn pipelines**\n",
    "- Creaci√≥n de APIs robustas con **FastAPI**\n",
    "- Validaci√≥n de datos con **Pydantic**\n",
    "- Contenedorizaci√≥n con **Docker**\n",
    "- Despliegue en la nube con **Fly.io**\n",
    "\n",
    "### Caso de Uso: Predicci√≥n de Churn de Clientes\n",
    "\n",
    "Implementaremos un modelo para predecir si un cliente cancelar√° su servicio (churn), un problema com√∫n en telecomunicaciones y servicios de suscripci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8cc97-9d65-45e9-a1a9-251c65114bfa",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno con UV\n",
    "\n",
    "### ¬øQu√© es UV y por qu√© es tan r√°pido?\n",
    "\n",
    "Imagina que est√°s construyendo algo con bloques de LEGO. `pip` es como un ayudante que va a la tienda a por cada pieza que necesitas, una por una. Si una pieza necesita otra m√°s peque√±a, tiene que volver a la tienda. Es fiable, pero puede llevar su tiempo.\n",
    "\n",
    "**UV**, en cambio, es como un ayudante con un dron s√∫per-r√°pido y una tablet. Antes de salir, mira tu lista, calcula al instante todas las piezas y sub-piezas que necesitar√°s, y las recoge todas de la tienda en un solo viaje a m√°xima velocidad.\n",
    "\n",
    "En resumen, **UV es un instalador y gestor de entornos virtuales para Python, dise√±ado para ser extremadamente r√°pido**. Su objetivo es reemplazar a herramientas como `pip`, `pip-tools`, `venv` y `virtualenv` con una √∫nica interfaz de l√≠nea de comandos ultrarr√°pida.\n",
    "\n",
    "### El Secreto de su Velocidad\n",
    "\n",
    "La \"magia\" de UV no es una sola cosa, sino la combinaci√≥n de tres factores clave:\n",
    "\n",
    "1.  **Est√° escrito en Rust**: A diferencia de `pip` que est√° escrito en Python, UV est√° construido con Rust. Rust es un lenguaje de programaci√≥n que compila a c√≥digo m√°quina nativo, lo que le permite ejecutar tareas como la descarga e instalaci√≥n de archivos a una velocidad mucho mayor que un lenguaje interpretado como Python. ¬°Es como comparar un coche de F√≥rmula 1 (Rust) con un coche de calle (Python) para una carrera de velocidad!\n",
    "\n",
    "2.  **Resoluci√≥n de dependencias de √∫ltima generaci√≥n**: Cuando instalas un paquete (ej. `pandas`), este depende de otros (ej. `numpy`), que a su vez dependen de otros. Encontrar las versiones correctas que sean compatibles entre s√≠ es un rompecabezas complejo. UV utiliza un algoritmo muy avanzado para resolver este \"puzzle\" de dependencias de forma incre√≠blemente eficiente.\n",
    "\n",
    "3.  **Un sistema de cach√© global e inteligente**: La primera vez que UV descarga un paquete, lo guarda en una cach√© global en tu sistema. La pr√≥xima vez que necesites ese mismo paquete en *otro proyecto*, UV no lo descarga de nuevo. Simplemente crea un enlace a la versi√≥n que ya tiene guardada. Esto hace que la creaci√≥n de nuevos entornos sea casi instant√°nea.\n",
    "\n",
    "> **Dato curioso**: El creador de UV, Charlie Marsh, es tambi√©n el creador de **Ruff**, un *linter* de Python tambi√©n escrito en Rust que es cientos de veces m√°s r√°pido que sus predecesores.\n",
    "\n",
    "### UV vs. Pip y otras herramientas\n",
    "\n",
    "Pensar que UV es solo \"un pip m√°s r√°pido\" es quedarse corto. La verdadera revoluci√≥n es que **UV es una navaja suiza que reemplaza a un conjunto de herramientas**.\n",
    "\n",
    "La forma tradicional de trabajar en Python requiere un equipo de varias herramientas:\n",
    "* `venv` o `virtualenv`: Para crear y gestionar entornos virtuales aislados.\n",
    "* `pip`: Para instalar los paquetes dentro de ese entorno.\n",
    "* `pip-tools`: Una herramienta extra para compilar un `requirements.txt` a partir de un `pyproject.toml` y generar un archivo de bloqueo (`.txt`) que asegure la reproducibilidad.\n",
    "\n",
    "UV integra todas estas funciones (y m√°s) en un √∫nico ejecutable s√∫per r√°pido.\n",
    "\n",
    "Pensemos en una analog√≠a: `pip` + `venv` es como tener una caja de herramientas con un martillo, un destornillador y una llave inglesa. Funcionan bien, pero tienes que ir cambiando de herramienta para cada tarea. **UV es como una multiherramienta Leatherman de √∫ltima generaci√≥n**: tienes todo lo que necesitas en un solo lugar, es m√°s ligera y mucho m√°s eficiente. \n",
    "\n",
    "### Tabla Comparativa R√°pida\n",
    "\n",
    "| Caracter√≠stica | `pip` + `venv` | `uv` |\n",
    "| :--- | :--- | :--- |\n",
    "| **Velocidad** | Moderada. La resoluci√≥n de dependencias puede ser lenta. | **Extremadamente R√°pida**. Gracias a Rust y su resolutor avanzado. |\n",
    "| **Herramientas** | M√∫ltiples (`python -m venv`, `pip`). | **√önica y unificada** (un solo comando `uv`). |\n",
    "| **Crear Entorno** | `python -m venv .venv` | `uv venv` (notablemente m√°s r√°pido). |\n",
    "| **Instalaci√≥n** | `pip install pandas` | `uv pip install pandas` (sintaxis familiar). |\n",
    "| **Cach√© de Paquetes**| El cach√© de pip es bueno, pero a veces inconsistente. | **Cach√© global e inteligente**. Acelera la creaci√≥n de nuevos proyectos. |\n",
    "| **Reproducibilidad**| Se necesita `pip-tools` para crear un archivo `.txt` de bloqueo. | **Soporte nativo**. Puede leer y generar archivos de bloqueo (`uv.lock`, `requirements.lock`). |\n",
    "\n",
    "> La conclusi√≥n es simple: pasas de hacer malabares con 2 o 3 comandos a usar uno solo que, adem√°s, es entre **10 y 100 veces m√°s r√°pido**. En entornos de Integraci√≥n Continua (CI/CD), donde se crean y destruyen entornos constantemente, este ahorro de tiempo es gigantesco.\n",
    "\n",
    "\n",
    "### Instalaci√≥n y Configuraci√≥n\n",
    "\n",
    "```bash\n",
    "# En tu terminal, instala uv (solo una vez)\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "```\n",
    "\n",
    "> Otra alternativa: para usar `uv`, necesitas instalarlo en tu sistema. La forma m√°s f√°cil es con `pip` normal: `pip install uv`).\n",
    "\n",
    "### Primeros Pasos con UV\n",
    "\n",
    "Aqu√≠ tienes el flujo de trabajo t√≠pico para un nuevo proyecto, paso a paso.\n",
    "\n",
    "#### Paso 1: Crear el Entorno Virtual\n",
    "\n",
    "Olvida el `python -m venv .venv`. Con UV, es m√°s corto y mucho m√°s r√°pido:\n",
    "\n",
    "```bash\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "\n",
    "# Crea un entorno virtual en una carpeta llamada .venv\n",
    "uv venv\n",
    "```\n",
    "\n",
    "¬°Listo\\! En una fracci√≥n de segundo, tendr√°s tu entorno creado. Si quisieras usar una versi√≥n espec√≠fica de Python que tengas instalada, podr√≠as hacer `uv venv -p 3.11`.\n",
    "\n",
    "#### Paso 2: Activar el Entorno\n",
    "\n",
    "Esta parte es **exactamente igual** a como siempre lo has hecho. UV crea una estructura de carpetas compatible.\n",
    "\n",
    "```bash\n",
    "# En Linux o macOS\n",
    "source .venv/bin/activate\n",
    "\n",
    "# En Windows (Command Prompt)\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Una vez activado, tu terminal te mostrar√° `(.venv)` al principio de la l√≠nea.\n",
    "\n",
    "#### Paso 3: Instalar Paquetes\n",
    "\n",
    "La sintaxis es id√©ntica a la de `pip`, lo cual facilita enormemente la transici√≥n. Simplemente reemplazas `pip install` por `uv pip install`, otro comando valido es `uv add`.\n",
    "\n",
    "```bash\n",
    "# Instalar un solo paquete\n",
    "uv pip install fastapi\n",
    "\n",
    "# Instalar varios paquetes a la vez\n",
    "uv pip install \"pandas~=2.0\" pydantic\n",
    "\n",
    "# Instalar desde tu pyproject.toml\n",
    "uv pip install -e .\n",
    "```\n",
    "\n",
    "Aqu√≠ notar√°s la diferencia m√°s grande: la velocidad de descarga e instalaci√≥n es asombrosa.\n",
    "\n",
    "#### Paso 4: Generar un Archivo de Bloqueo\n",
    "\n",
    "Este es el paso que garantiza que el entorno de todo tu equipo sea id√©ntico. `uv` lee tu `pyproject.toml` y genera un archivo `requirements.lock` con las versiones exactas de cada paquete.\n",
    "\n",
    "```bash\n",
    "# Lee pyproject.toml y crea un archivo de bloqueo\n",
    "uv pip compile pyproject.toml -o requirements.lock\n",
    "```\n",
    "\n",
    "Este archivo `requirements.lock` es el que subir√≠as a tu repositorio de Git.\n",
    "\n",
    "#### Paso 5: Instalar desde el Archivo de Bloqueo\n",
    "\n",
    "Ahora, imagina que eres un nuevo desarrollador que se une al proyecto. Tienes el `pyproject.toml` y el `requirements.lock`. Despu√©s de crear y activar tu entorno, solo necesitas un comando:\n",
    "\n",
    "```bash\n",
    "# Lee el archivo de bloqueo y sincroniza tu entorno.\n",
    "# ¬°Instala, elimina y actualiza paquetes para que coincida 100%!\n",
    "uv sync requirements.lock\n",
    "```\n",
    "\n",
    "Este comando es incre√≠blemente r√°pido y eficiente. Es el que usar√≠as en tus flujos de CI/CD o para que un compa√±ero se ponga al d√≠a.\n",
    "\n",
    "### Estructura de Proyecto para ML\n",
    "\n",
    "Esta es la estructura de directorios recomendada para el proyecto, siguiendo las mejores pr√°cticas de desarrollo de software y MLOps.\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "‚îú‚îÄ‚îÄ .env                  # Variables de entorno y secretos\n",
    "‚îú‚îÄ‚îÄ .gitignore\n",
    "‚îú‚îÄ‚îÄ .python-version       # Versi√≥n de Python fijada para el proyecto\n",
    "‚îú‚îÄ‚îÄ pyproject.toml        # Definici√≥n de dependencias y configuraci√≥n\n",
    "‚îú‚îÄ‚îÄ uv.lock               # Archivo de bloqueo para reproducibilidad\n",
    "‚îú‚îÄ‚îÄ README.md\n",
    "‚îú‚îÄ‚îÄ Dockerfile            # Instrucciones para la contenedorizaci√≥n\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ artifacts/            # Modelos entrenados, serializadores y otros artefactos\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ sentiment_model_v1.pkl\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ data/                 # Datasets del proyecto (ignorado por Git)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Datos originales, sin modificar\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Datos limpios y listos para el entrenamiento\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ notebooks/            # Jupyter Notebooks para exploraci√≥n y an√°lisis\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 1.0-eda-initial-exploration.ipynb\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ src/                  # C√≥digo fuente de la aplicaci√≥n\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Punto de entrada de la API (FastAPI)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ config.py         # M√≥dulo de configuraci√≥n\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ api/              # L√≥gica de la API (endpoints)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ml/               # C√≥digo de Machine Learning\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ schemas/          # Esquemas de datos (Pydantic)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ tests/                # Pruebas autom√°ticas\n",
    "‚îî‚îÄ‚îÄ scripts/              # Scripts de utilidad (ej. para descargar datos)\n",
    "```\n",
    "\n",
    "### Explicaci√≥n de la Estructura\n",
    "\n",
    "La organizaci√≥n de este proyecto est√° dise√±ada para ser **clara, modular y escalable**. Cada directorio tiene una responsabilidad bien definida:\n",
    "\n",
    "  * **Configuraci√≥n (Ra√≠z)**: Los archivos en la ra√≠z del proyecto (`pyproject.toml`, `uv.lock`, `.python-version`, etc.) definen el entorno, las dependencias y las reglas del proyecto, asegurando que cualquier colaborador pueda replicar el entorno de desarrollo de forma id√©ntica.\n",
    "\n",
    "  * **`src/` (C√≥digo Fuente)**: Es el coraz√≥n de la aplicaci√≥n. Contiene todo el c√≥digo Python que se ejecuta como parte del servicio final. La l√≥gica est√° modularizada en subpaquetes como `api/`, `ml/` y `schemas/` para mantener el c√≥digo organizado y f√°cil de mantener.\n",
    "\n",
    "  * **`artifacts/` (Artefactos)**: Esta carpeta almacena los **productos generados por nuestro c√≥digo**, no el c√≥digo en s√≠. Su principal contenido son los modelos ya entrenados (ej. un archivo `.pkl` o `.h5`).\n",
    "\n",
    "  * **`data/` (Datos)**: Un lugar centralizado para todos los datos necesarios. Se divide en `raw` para los datos originales e inmutables y `processed` para las versiones limpias y transformadas, listas para ser usadas en el entrenamiento. Esta carpeta se a√±ade al `.gitignore` para evitar subir grandes vol√∫menes de datos al repositorio.\n",
    "\n",
    "  * **`notebooks/` (Experimentaci√≥n)**: Este es el \"laboratorio\". Contiene los Jupyter Notebooks usados para el An√°lisis Exploratorio de Datos (EDA), prototipado de modelos y visualizaciones. Separar los notebooks del c√≥digo de producci√≥n en `src/` es crucial para mantener el proyecto limpio.\n",
    "\n",
    "  * **`tests/` y `scripts/` (Soporte)**: `tests/` asegura la calidad y fiabilidad de nuestro c√≥digo mediante pruebas autom√°ticas, mientras que `scripts/` nos proporciona un lugar para herramientas de un solo uso que facilitan tareas de desarrollo.\n",
    "\n",
    "Esta separaci√≥n de responsabilidades hace que el proyecto sea m√°s f√°cil de entender, probar, y finalmente, desplegar a producci√≥n.\n",
    "\n",
    "\n",
    "### Configuraci√≥n de Dependencias (pyproject.toml)\n",
    "\n",
    "`pyproject.toml` es el cerebro detr√°s de la gesti√≥n de proyectos modernos en Python, y herramientas como **UV** est√°n dise√±adas para leerlo a la perfecci√≥n.\n",
    "\n",
    "Piensa en `pyproject.toml` como el **carn√© de identidad y el panel de control** de tu proyecto, todo en un √∫nico archivo.\n",
    "\n",
    "Antes, la configuraci√≥n de un proyecto de Python estaba repartida en varios archivos: `setup.py`, `requirements.txt`, `setup.cfg`, `MANIFEST.in`... ¬°Era un poco ca√≥tico\\! El archivo `pyproject.toml` fue introducido (en el [PEP 518](https://peps.python.org/pep-0518/)) para estandarizar y centralizar toda esa informaci√≥n en un solo lugar.\n",
    "\n",
    "### ¬øQu√© hay dentro de un `pyproject.toml`?\n",
    "\n",
    "Este archivo utiliza el formato [TOML](https://www.google.com/search?q=https://toml.io/es/) (Tom's Obvious, Minimal Language), que es muy f√°cil de leer para los humanos. Se organiza en secciones, pero nos centraremos en las m√°s importantes para las dependencias.\n",
    "\n",
    "Veamos un ejemplo pr√°ctico:\n",
    "\n",
    "```toml\n",
    "# Esta secci√≥n le dice a Python C√ìMO construir tu proyecto.\n",
    "# No necesitas preocuparte mucho por ella al principio.\n",
    "[build-system]\n",
    "requires = [\"setuptools>=61.0\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "# --- Aqu√≠ empieza lo interesante ---\n",
    "\n",
    "# Esta es la \"ficha de identidad\" de tu proyecto.\n",
    "[project]\n",
    "name = \"mi-proyecto-genial\"\n",
    "version = \"0.1.0\"\n",
    "authors = [\n",
    "  { name=\"Tu Nombre\", email=\"tu@email.com\" },\n",
    "]\n",
    "description = \"Un peque√±o proyecto de ejemplo.\"\n",
    "\n",
    "# Aqu√≠ declaras las dependencias PRINCIPALES.\n",
    "# Estas son las que se necesitan para que tu programa funcione.\n",
    "dependencies = [\n",
    "    \"fastapi>=0.90.0\", # Necesitamos fastapi, versi√≥n 0.90.0 o superior.\n",
    "    \"pandas\",         # La √∫ltima versi√≥n estable de pandas.\n",
    "]\n",
    "\n",
    "# Dependencias OPCIONALES. No son necesarias para todos los usuarios.\n",
    "[project.optional-dependencies]\n",
    "test = [\n",
    "    \"pytest\",\n",
    "    \"pytest-cov\",\n",
    "]\n",
    "docs = [\n",
    "    \"sphinx\",\n",
    "]\n",
    "\n",
    "# En esta secci√≥n, otras herramientas pueden guardar su configuraci√≥n.\n",
    "# Por ejemplo, Ruff (el linter del que hablamos) se configura aqu√≠.\n",
    "[tool.ruff]\n",
    "line-length = 88\n",
    "```\n",
    "\n",
    "Las dos secciones clave son:\n",
    "\n",
    "1.  `[project.dependencies]`: Esta es tu lista principal de \"ingredientes\". Es el equivalente moderno al archivo `requirements.txt`. Aqu√≠ pones los paquetes que tu proyecto **necesita** para funcionar.\n",
    "2.  `[project.optional-dependencies]`: Aqu√≠ defines grupos de dependencias para situaciones espec√≠ficas. El caso m√°s com√∫n es `test` (para instalar librer√≠as de testing como `pytest`) o `dev` (para herramientas de desarrollo). Esto es genial porque alguien que solo quiere *usar* tu programa no necesita descargar todas las herramientas que t√∫ usaste para *crearlo*.\n",
    "\n",
    "### ¬øY c√≥mo se relaciona esto con UV?\n",
    "\n",
    "Aqu√≠ es donde todo encaja. **UV est√° dise√±ado para leer este archivo de forma nativa y ultrarr√°pida**.\n",
    "\n",
    "  - Si ejecutas `uv pip install -e .` en la carpeta de tu proyecto, UV leer√° la lista de `[project.dependencies]` y las instalar√°.\n",
    "  - Si quieres instalar tambi√©n las dependencias de testing, ejecutar√≠as `uv pip install -e \".[test]\"`. UV entender√° que debe instalar las dependencias principales **Y** las del grupo `test`.\n",
    "\n",
    "Usar `pyproject.toml` centraliza toda la configuraci√≥n, haciendo tu proyecto m√°s limpio, reproducible y f√°cil de entender tanto para otros desarrolladores como para herramientas autom√°ticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca28df-73a6-4b9d-9052-02fe3c079616",
   "metadata": {},
   "source": [
    "## 2. Generaci√≥n de Datos Sint√©ticos para Churn\n",
    "\n",
    "### Crear Dataset de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb78d-00ff-49ca-8648-dbd2368b4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def create_churn_dataset(n_samples=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Crear un dataset sint√©tico realista para predicci√≥n de churn.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con caracter√≠sticas de clientes y etiquetas de churn\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Crear datos base\n",
    "    data = {\n",
    "        'customer_id': range(1, n_samples + 1),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'senior_citizen': np.random.choice([0, 1], n_samples, p=[0.84, 0.16]),\n",
    "        'partner': np.random.choice(['Yes', 'No'], n_samples, p=[0.48, 0.52]),\n",
    "        'dependents': np.random.choice(['Yes', 'No'], n_samples, p=[0.30, 0.70]),\n",
    "        'tenure': np.random.randint(1, 73, n_samples),  # Meses\n",
    "        'phone_service': np.random.choice(['Yes', 'No'], n_samples, p=[0.90, 0.10]),\n",
    "        'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], \n",
    "                                           n_samples, p=[0.34, 0.44, 0.22]),\n",
    "        'online_security': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                          n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                       n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], \n",
    "                                   n_samples, p=[0.55, 0.21, 0.24]),\n",
    "        'payment_method': np.random.choice([\n",
    "            'Electronic check', 'Mailed check', 'Bank transfer (automatic)', \n",
    "            'Credit card (automatic)'\n",
    "        ], n_samples, p=[0.34, 0.23, 0.22, 0.21]),\n",
    "        'monthly_charges': np.round(np.random.normal(64.76, 30.0, n_samples), 2),\n",
    "        'total_charges': np.round(np.random.normal(2283.30, 2266.77, n_samples), 2)\n",
    "    }\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Limpiar valores negativos en charges\n",
    "    df['monthly_charges'] = df['monthly_charges'].clip(lower=18.25)\n",
    "    df['total_charges'] = df['total_charges'].clip(lower=18.80)\n",
    "    \n",
    "    # Crear etiquetas de churn con l√≥gica realista\n",
    "    churn_probability = 0.2  # Baseline\n",
    "    \n",
    "    # Factores que aumentan churn\n",
    "    tenure_factor = np.where(df['tenure'] < 12, 0.15, 0)  # Clientes nuevos\n",
    "    contract_factor = np.where(df['contract'] == 'Month-to-month', 0.20, 0)  # Sin compromiso\n",
    "    payment_factor = np.where(df['payment_method'] == 'Electronic check', 0.10, 0)  # M√©todo de pago\n",
    "    charges_factor = np.where(df['monthly_charges'] > 80, 0.08, 0)  # Cargos altos\n",
    "    \n",
    "    # Factores que reducen churn\n",
    "    partner_factor = np.where(df['partner'] == 'Yes', -0.08, 0)  # Con pareja\n",
    "    dependents_factor = np.where(df['dependents'] == 'Yes', -0.05, 0)  # Con dependientes\n",
    "    long_tenure_factor = np.where(df['tenure'] > 48, -0.12, 0)  # Clientes antiguos\n",
    "    \n",
    "    # Calcular probabilidad final\n",
    "    final_probability = (churn_probability + tenure_factor + contract_factor + \n",
    "                        payment_factor + charges_factor + partner_factor + \n",
    "                        dependents_factor + long_tenure_factor)\n",
    "    \n",
    "    # Generar etiquetas de churn\n",
    "    df['churn'] = np.random.binomial(1, final_probability.clip(0.05, 0.85))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear el dataset\n",
    "print(\"Generando dataset sint√©tico de churn...\")\n",
    "churn_data = create_churn_dataset(n_samples=10000)\n",
    "\n",
    "print(f\"Dataset creado:\")\n",
    "print(f\"   ‚Ä¢ Muestras: {len(churn_data)}\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {churn_data.shape[1]-2}\")  # -2 para customer_id y churn\n",
    "print(f\"   ‚Ä¢ Tasa de churn: {churn_data['churn'].mean():.1%}\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212f30-8fd3-46bc-b753-30031c19dc63",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del Modelo con Pipelines de Scikit-learn\n",
    "\n",
    "### ¬øPor qu√© usar Pipelines?\n",
    "\n",
    "Los **pipelines** de scikit-learn combinan m√∫ltiples pasos de preprocesamiento y modelado en un solo objeto, lo que:\n",
    "- Simplifica el c√≥digo\n",
    "- Evita errores de data leakage\n",
    "- Facilita la serializaci√≥n\n",
    "- Permite usar el modelo con datos en formato crudo\n",
    "\n",
    "Pensemos en un **Pipeline** de Scikit-learn como una **receta de cocina** o una **l√≠nea de ensamblaje** para tu modelo de Machine Learning.\n",
    "\n",
    "En lugar de realizar cada paso por separado (lavar los ingredientes, cortarlos, mezclarlos, hornearlos), un Pipeline te permite definir toda la secuencia de una vez. Le entregas los ingredientes crudos (tus datos) al principio, y al final obtienes el plato terminado (la predicci√≥n).\n",
    "\n",
    "### Simplifica el C√≥digo\n",
    "\n",
    "Imagina que necesitas rellenar valores faltantes y luego escalar tus datos antes de entrenar un modelo.\n",
    "\n",
    "**Sin un Pipeline**, tu c√≥digo se ver√≠a as√≠, con pasos separados:\n",
    "\n",
    "```python\n",
    "# 1. Rellenar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test) # ¬°Ojo! Solo 'transform' en test\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed) # De nuevo, solo 'transform'\n",
    "\n",
    "# 3. Entrenar el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "```\n",
    "\n",
    "Es f√°cil cometer errores, como aplicar `fit_transform` en el conjunto de prueba por accidente.\n",
    "\n",
    "**Con un Pipeline**, todos esos pasos se encapsulan en uno solo:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Definimos la \"receta\" completa\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Paso 1: Rellenar\n",
    "    ('scaler', StandardScaler()),              # Paso 2: Escalar\n",
    "    ('model', LogisticRegression())            # Paso 3: Modelo\n",
    "])\n",
    "\n",
    "# Entrenamos todo el pipeline de una vez\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "El c√≥digo es m√°s **limpio, corto y legible**.\n",
    "\n",
    "### Evita Errores de \"Data Leakage\" (Fuga de Datos)\n",
    "\n",
    "La **fuga de datos** es uno de los errores m√°s peligrosos en Machine Learning. Ocurre cuando la informaci√≥n del conjunto de prueba (datos que el modelo \"no deber√≠a haber visto\") se \"filtra\" accidentalmente en el proceso de entrenamiento.\n",
    "\n",
    "Pi√©nsalo como si un estudiante **viera las respuestas del examen final mientras estudia**. Obviamente, sacar√° una nota perfecta en el examen, pero no habr√° aprendido nada y no podr√° resolver problemas nuevos.\n",
    "\n",
    "Un Pipeline evita esto porque garantiza que cada paso (como el escalado de datos) se **ajuste (`fit`) √∫nicamente con los datos de entrenamiento** y luego solo se **aplique (`transform`)** a los datos de prueba o a nuevos datos, imitando perfectamente las condiciones del mundo real.\n",
    "\n",
    "### Facilita la Serializaci√≥n (Guardar el Modelo)\n",
    "\n",
    "Cuando quieres guardar tu trabajo, no solo necesitas el modelo, sino tambi√©n todos los pasos de preprocesamiento que lo acompa√±an (el `imputer`, el `scaler`, etc.).\n",
    "\n",
    "Sin un Pipeline, tendr√≠as que guardar cada objeto por separado, lo cual es engorroso y propenso a errores. Con un Pipeline, **guardas un solo objeto** que contiene toda la secuencia de trabajo. Es como guardar el archivo de una receta completa en lugar de una lista desordenada de ingredientes y pasos.\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Guardas TODO el flujo de trabajo en un solo archivo\n",
    "joblib.dump(pipeline, 'modelo_completo.pkl')\n",
    "\n",
    "# Para cargarlo, es igual de simple\n",
    "loaded_pipeline = joblib.load('modelo_completo.pkl')\n",
    "```\n",
    "\n",
    "### Permite Usar el Modelo con Datos Crudos\n",
    "\n",
    "Esta es la consecuencia m√°s pr√°ctica. Una vez que tu Pipeline est√° entrenado y guardado, puedes darle **datos nuevos y sin procesar** (datos \"crudos\"), y √©l se encargar√° de aplicar autom√°ticamente toda la secuencia de preprocesamiento antes de hacer la predicci√≥n.\n",
    "\n",
    "```python\n",
    "# Datos nuevos, tal como llegan del mundo real\n",
    "new_data = [[5.1, 3.5, None, 0.2]] # Tiene un valor faltante\n",
    "\n",
    "# El pipeline se encarga de todo: imputa, escala y predice\n",
    "prediction = loaded_pipeline.predict(new_data)\n",
    "print(prediction)\n",
    "```\n",
    "\n",
    "Esto hace que poner tu modelo en producci√≥n sea **infinitamente m√°s sencillo y seguro**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd85a76-6c4a-4ddf-90c0-4f5e06a2b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Preparar caracter√≠sticas para el modelo.\n",
    "    Convertir DataFrame a lista de diccionarios (formato requerido por DictVectorizer)\n",
    "    \"\"\"\n",
    "    # Seleccionar caracter√≠sticas relevantes\n",
    "    feature_columns = [\n",
    "        'gender', 'senior_citizen', 'partner', 'dependents', 'tenure',\n",
    "        'phone_service', 'internet_service', 'online_security', 'tech_support',\n",
    "        'contract', 'payment_method', 'monthly_charges', 'total_charges'\n",
    "    ]\n",
    "    \n",
    "    # Convertir a lista de diccionarios\n",
    "    X = df[feature_columns].to_dict('records')\n",
    "    y = df['churn']\n",
    "    \n",
    "    return X, y, feature_columns\n",
    "\n",
    "def train_churn_model(df, model_type='logistic_regression'):\n",
    "    \"\"\"\n",
    "    Entrenar modelo de predicci√≥n de churn usando pipelines.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos\n",
    "        model_type: Tipo de modelo ('logistic_regression' o 'random_forest')\n",
    "    \n",
    "    Returns:\n",
    "        pipeline: Modelo entrenado\n",
    "        metrics: M√©tricas de evaluaci√≥n\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Iniciando entrenamiento de modelo: {model_type}\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X, y, feature_columns = prepare_features(df)\n",
    "    \n",
    "    # Split train/validation/test (60/20/20)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Split de datos:\")\n",
    "    print(f\"   ‚Ä¢ Entrenamiento: {len(X_train)} muestras\")\n",
    "    print(f\"   ‚Ä¢ Validaci√≥n: {len(X_val)} muestras\")\n",
    "    print(f\"   ‚Ä¢ Prueba: {len(X_test)} muestras\")\n",
    "    \n",
    "    # Crear pipeline seg√∫n el tipo de modelo\n",
    "    if model_type == 'logistic_regression':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            LogisticRegression(\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced'  # Manejar desbalance\n",
    "            )\n",
    "        )\n",
    "    elif model_type == 'random_forest':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                max_depth=10\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_type debe ser 'logistic_regression' o 'random_forest'\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"üîÑ Entrenando modelo...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluaci√≥n en conjunto de validaci√≥n\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Evaluaci√≥n en conjunto de prueba\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    y_test_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_type': model_type,\n",
    "        'validation_auc': val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_count': len(feature_columns),\n",
    "        'training_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ Entrenamiento completado!\")\n",
    "    print(f\"üìà AUC Validaci√≥n: {val_auc:.4f}\")\n",
    "    print(f\"üìà AUC Prueba: {test_auc:.4f}\")\n",
    "    \n",
    "    # Reporte detallado\n",
    "    print(f\"\\nüìã Reporte de Clasificaci√≥n (Conjunto de Prueba):\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['No Churn', 'Churn']))\n",
    "    \n",
    "    return pipeline, metrics, (X_test, y_test)\n",
    "\n",
    "# Entrenar modelos\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modelo 1: Regresi√≥n Log√≠stica\n",
    "lr_model, lr_metrics, (X_test, y_test) = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='logistic_regression'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Modelo 2: Random Forest\n",
    "rf_model, rf_metrics, _ = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='random_forest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c70e3-35a7-4321-b5ef-9cc2ad5188be",
   "metadata": {},
   "source": [
    "### Guardar Modelos Entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c15f21-65e0-42da-bf68-d243dba6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model_with_metadata(pipeline, metrics, model_name, models_dir=\"./models\"):\n",
    "    \"\"\"\n",
    "    Guardar modelo y sus metadatos de forma organizada.\n",
    "    \"\"\"\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Nombres de archivos\n",
    "    model_filename = f\"{model_name}_{datetime.now().strftime('%Y%m%d')}.joblib\"\n",
    "    metadata_filename = f\"{model_name}_metadata.json\"\n",
    "    \n",
    "    model_path = os.path.join(models_dir, model_filename)\n",
    "    metadata_path = os.path.join(models_dir, metadata_filename)\n",
    "    \n",
    "    # Guardar modelo usando joblib (m√°s eficiente que pickle para sklearn)\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    \n",
    "    # Guardar metadatos\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üíæ Modelo guardado: {model_path}\")\n",
    "    print(f\"üìÑ Metadatos guardados: {metadata_path}\")\n",
    "    \n",
    "    return model_path, metadata_path\n",
    "\n",
    "# Guardar ambos modelos\n",
    "lr_model_path, lr_metadata_path = save_model_with_metadata(\n",
    "    lr_model, lr_metrics, \"churn_logistic_regression\"\n",
    ")\n",
    "\n",
    "rf_model_path, rf_metadata_path = save_model_with_metadata(\n",
    "    rf_model, rf_metrics, \"churn_random_forest\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Modelos guardados exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c169cc-0164-45b1-9908-bca03eda7c69",
   "metadata": {},
   "source": [
    "## 4. Creaci√≥n de API con FastAPI\n",
    "\n",
    "Piensa en una API (Interfaz de Programaci√≥n de Aplicaciones) como un **camarero en un restaurante**. T√∫ (el cliente) no necesitas saber c√≥mo funciona la cocina; solo le das tu pedido al camarero, √©l lo lleva a la cocina, y te trae el plato listo. La API hace exactamente eso, pero con datos.\n",
    "\n",
    "FastAPI es un framework que te permite construir a ese \"camarero\" de una manera incre√≠blemente eficiente, r√°pida y moderna.\n",
    "\n",
    "### Velocidad\n",
    "\n",
    "FastAPI est√° construido sobre dos pilares de alto rendimiento:\n",
    "\n",
    "1.  **Starlette**: Es un microframework web ultrarr√°pido. FastAPI lo usa como su motor principal para manejar las peticiones web.\n",
    "2.  **Pydantic**: Se encarga de la validaci√≥n de datos y est√° escrito en parte en Rust, lo que lo hace extremadamente veloz.\n",
    "\n",
    "Gracias a esto, FastAPI es uno de los frameworks de Python m√°s r√°pidos que existen, comparable en rendimiento a aplicaciones escritas en lenguajes compilados como Go o Node.js. Esto significa que tu API puede atender a muchos m√°s usuarios al mismo tiempo sin ralentizarse.\n",
    "\n",
    "### Documentaci√≥n Autom√°tica\n",
    "\n",
    "Este es uno de los superpoderes de FastAPI. Imagina que cada vez que escribes el c√≥digo de tu API, se **escribe solo un manual de instrucciones interactivo**.\n",
    "\n",
    "FastAPI genera autom√°ticamente una documentaci√≥n en dos formatos:\n",
    "\n",
    "  * **Swagger UI**\n",
    "  * **ReDoc**\n",
    "\n",
    "Solo tienes que ir a la URL `/docs` de tu API, y encontrar√°s una p√°gina donde puedes ver todos tus *endpoints* (las diferentes \"√≥rdenes\" que tu camarero puede tomar), qu√© datos necesitan, y qu√© datos devuelven. ¬°Incluso puedes probar la API directamente desde esa p√°gina\\! Esto ahorra una cantidad enorme de tiempo en documentaci√≥n y facilita el trabajo en equipo.\n",
    "\n",
    "### Validaci√≥n con Pydantic\n",
    "\n",
    "Piensa en Pydantic como el **guardia de seguridad de tu API**. Antes de que cualquier dato entre a tu l√≥gica, Pydantic lo revisa para asegurarse de que tiene el formato correcto.\n",
    "\n",
    "T√∫ defines la \"forma\" de los datos que esperas usando clases de Python, y Pydantic se encarga del resto.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "    is_offer: bool | None = None\n",
    "```\n",
    "\n",
    "Si alguien intenta enviar un `price` que no es un n√∫mero, FastAPI autom√°ticamente le devolver√° un error claro y descriptivo. Esto hace tu c√≥digo mucho m√°s seguro y robusto, evitando errores inesperados.\n",
    "\n",
    "### Soporte As√≠ncrono (Async)\n",
    "\n",
    "Imagina un chef que solo puede hacer una cosa a la vez (s√≠ncrono). Si est√° esperando que el agua hierva, no puede hacer nada m√°s.\n",
    "\n",
    "Un chef as√≠ncrono, en cambio, pone el agua a hervir y, **mientras espera**, se pone a cortar las verduras. Es mucho m√°s eficiente.\n",
    "\n",
    "FastAPI te permite usar `async` y `await` para manejar operaciones que toman tiempo (como llamar a otra API o consultar una base de datos) sin bloquear todo el programa. Esto es fundamental para construir aplicaciones que necesitan manejar muchas conexiones simult√°neas de manera eficiente.\n",
    "\n",
    "### Tipado Nativo de Python (Type Hints)\n",
    "\n",
    "FastAPI utiliza las **pistas de tipos** de Python (`str`, `int`, `bool`, etc.) para todo. No tienes que aprender una sintaxis nueva.\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/items/{item_id}\")\n",
    "def read_item(item_id: int, q: str | None = None):\n",
    "    return {\"item_id\": item_id, \"q\": q}\n",
    "```\n",
    "\n",
    "Al declarar que `item_id` debe ser un `int`, FastAPI autom√°ticamente:\n",
    "\n",
    "1.  **Valida** que el dato recibido es un entero.\n",
    "2.  **Documenta** que este endpoint espera un entero.\n",
    "3.  Le da a tu editor de c√≥digo (como VS Code) informaci√≥n para **autocompletar** y detectar errores mientras escribes.\n",
    "\n",
    "En resumen, FastAPI usa caracter√≠sticas modernas de Python para darte una experiencia de desarrollo r√°pida, segura y muy agradable.\n",
    "\n",
    "### Decoradores\n",
    "\n",
    "Un **decorador** en Python es como ponerle un \"sombrero\" especial a una funci√≥n para darle superpoderes o un nuevo comportamiento. Usas el s√≠mbolo `@` para aplicarlo.\n",
    "\n",
    "En FastAPI, los decoradores le dicen a tu \"camarero\" (la API) qu√© hacer cuando alguien llega a una URL espec√≠fica con un m√©todo de petici√≥n concreto (GET, POST, etc.).\n",
    "\n",
    "### Los \"Sombreros\" de Operaci√≥n: GET, POST, PUT, DELETE\n",
    "\n",
    "Piensa en estos decoradores como las diferentes tareas que un camarero puede realizar: tomar una orden, entregar un plato, actualizar una orden o cancelarla.\n",
    "\n",
    "  * **`@app.get(\"/ruta\")`**: **Leer datos.** Se usa cuando un cliente quiere *obtener* informaci√≥n. Es como preguntar el men√∫ del d√≠a. Es la operaci√≥n m√°s com√∫n.\n",
    "\n",
    "    ```python\n",
    "    @app.get(\"/items/{item_id}\")\n",
    "    def leer_item(item_id: int):\n",
    "        # Aqu√≠ ir√≠a el c√≥digo para buscar el item en una base de datos\n",
    "        return {\"item_id\": item_id, \"nombre\": \"Ejemplo de item\"}\n",
    "    ```\n",
    "\n",
    "  * **`@app.post(\"/ruta\")`**: **Crear datos.** Se usa cuando un cliente quiere *a√±adir* nueva informaci√≥n al sistema. Es como hacer un pedido nuevo en la cocina.\n",
    "\n",
    "    ```python\n",
    "    from pydantic import BaseModel\n",
    "\n",
    "    class Item(BaseModel):\n",
    "        name: str\n",
    "        price: float\n",
    "\n",
    "    @app.post(\"/items/\")\n",
    "    def crear_item(item: Item):\n",
    "        # Aqu√≠ guardar√≠as el nuevo 'item' en la base de datos\n",
    "        return {\"mensaje\": f\"Item '{item.name}' creado exitosamente.\"}\n",
    "    ```\n",
    "\n",
    "  * **`@app.put(\"/ruta\")`**: **Actualizar datos.** Se usa para reemplazar o actualizar por completo un recurso existente. Es como cambiar tu pedido por completo.\n",
    "\n",
    "    ```python\n",
    "    @app.put(\"/items/{item_id}\")\n",
    "    def actualizar_item(item_id: int, item: Item):\n",
    "        # L√≥gica para actualizar el item con el id correspondiente\n",
    "        return {\"item_id\": item_id, **item.dict()}\n",
    "    ```\n",
    "\n",
    "  * **`@app.delete(\"/ruta\")`**: **Borrar datos.** Se usa para eliminar un recurso. Es como cancelar un plato de tu orden.\n",
    "\n",
    "    ```python\n",
    "    @app.delete(\"/items/{item_id}\")\n",
    "    def borrar_item(item_id: int):\n",
    "        # L√≥gica para borrar el item de la base de datos\n",
    "        return {\"mensaje\": f\"Item con id {item_id} ha sido eliminado.\"}\n",
    "    ```\n",
    "\n",
    "\n",
    "### Par√°metros de Ruta y Consultas\n",
    "\n",
    "FastAPI es inteligente y usa los argumentos de tu funci√≥n para entender los datos que llegan:\n",
    "\n",
    "1.  **Par√°metros de Ruta (Path Parameters)**: Son valores que forman parte de la propia URL y se definen con llaves `{}`. En `@app.get(\"/items/{item_id}\")`, `item_id` es un par√°metro de ruta. FastAPI entiende que debe extraer ese valor de la URL y pasarlo a tu funci√≥n.\n",
    "\n",
    "2.  **Par√°metros de Consulta (Query Parameters)**: Son par√°metros opcionales que van al final de la URL despu√©s de un `?`. Por ejemplo, en `/users?role=admin`, `role` es un par√°metro de consulta. Si un argumento de tu funci√≥n **no** est√° en la ruta, FastAPI asume que es un par√°metro de consulta.\n",
    "\n",
    "    ```python\n",
    "    @app.get(\"/users/\")\n",
    "    # 'limit' es un par√°metro de consulta con un valor por defecto.\n",
    "    # Se usar√≠a as√≠: /users/ o /users/?limit=50\n",
    "    def leer_usuarios(limit: int = 100):\n",
    "        # ...l√≥gica para devolver usuarios...\n",
    "        return {\"limite\": limit, \"usuarios\": []}\n",
    "    ```\n",
    "\n",
    "### El Cuerpo de la Petici√≥n (Request Body)\n",
    "\n",
    "Para operaciones como `POST` y `PUT`, los datos suelen ser demasiado complejos para ir en la URL. En su lugar, se env√≠an en el \"cuerpo\" de la petici√≥n, normalmente como un objeto JSON.\n",
    "\n",
    "Aqu√≠ es donde usas un **modelo de Pydantic**. Al declarar un argumento de tu funci√≥n con el tipo de un modelo Pydantic (como `item: Item`), le dices a FastAPI:\n",
    "\n",
    "1.  Espera recibir un JSON en el cuerpo de la petici√≥n.\n",
    "2.  Verifica que el JSON tenga la misma estructura que la clase `Item`.\n",
    "3.  Si es v√°lido, convierte el JSON en un objeto de Python y p√°salo a mi funci√≥n.\n",
    "4.  Si no es v√°lido, responde autom√°ticamente con un error claro.\n",
    "\n",
    "Esto hace que manejar datos de entrada complejos sea incre√≠blemente simple y seguro.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207ff63-ff36-42d1-9841-4578206c690f",
   "metadata": {},
   "source": [
    "### Aplicaci√≥n FastAPI Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0bcea-4fbb-4ec7-8038-a9df229caec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/main.py\n",
    "from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from contextlib import asynccontextmanager\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from schemas.predictions import CustomerInput, PredictionResponse, BatchPredictionRequest\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Almacenamiento global para modelos\n",
    "ml_models: Dict[str, Any] = {}\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Gesti√≥n del ciclo de vida de la aplicaci√≥n\"\"\"\n",
    "    logger.info(\"üöÄ Iniciando carga de modelos...\")\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelos disponibles\n",
    "        models_dir = \"models\"\n",
    "        if os.path.exists(models_dir):\n",
    "            for filename in os.listdir(models_dir):\n",
    "                if filename.endswith('.joblib'):\n",
    "                    model_name = filename.replace('.joblib', '')\n",
    "                    model_path = os.path.join(models_dir, filename)\n",
    "                    \n",
    "                    model = joblib.load(model_path)\n",
    "                    ml_models[model_name] = model\n",
    "                    logger.info(f\"‚úÖ Modelo cargado: {model_name}\")\n",
    "        \n",
    "        if not ml_models:\n",
    "            logger.warning(\"‚ö†Ô∏è No se encontraron modelos en el directorio\")\n",
    "        \n",
    "        logger.info(f\"üìä Total modelos cargados: {len(ml_models)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error cargando modelos: {e}\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    # Limpieza al cerrar\n",
    "    ml_models.clear()\n",
    "    logger.info(\"üîÑ Recursos liberados\")\n",
    "\n",
    "# Crear aplicaci√≥n FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Churn Prediction API\",\n",
    "    description=\"\"\"\n",
    "    üéØ **API para Predicci√≥n de Churn de Clientes**\n",
    "    \n",
    "    Esta API utiliza modelos de Machine Learning para predecir la probabilidad\n",
    "    de que un cliente cancele su servicio (churn).\n",
    "    \n",
    "    ## Caracter√≠sticas\n",
    "    \n",
    "    * **Predicciones individuales**: Predice churn para un cliente\n",
    "    * **Predicciones por lotes**: Procesa m√∫ltiples clientes\n",
    "    * **M√∫ltiples modelos**: Soporte para diferentes algoritmos\n",
    "    * **Validaci√≥n autom√°tica**: Verificaci√≥n de datos de entrada\n",
    "    * **Documentaci√≥n interactiva**: Swagger UI integrado\n",
    "    \n",
    "    ## Modelos Disponibles\n",
    "    \n",
    "    * **Regresi√≥n Log√≠stica**: Modelo interpretable y r√°pido\n",
    "    * **Random Forest**: Modelo ensemble con alta precisi√≥n\n",
    "    \"\"\",\n",
    "    version=\"1.0.0\",\n",
    "    contact={\n",
    "        \"name\": \"Equipo ML\",\n",
    "        \"email\": \"ml@tuempresa.com\",\n",
    "    },\n",
    "    license_info={\n",
    "        \"name\": \"Apache 2.0\",\n",
    "        \"url\": \"https://www.apache.org/licenses/LICENSE-2.0.html\",\n",
    "    },\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Configurar CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # En producci√≥n, especifica dominios espec√≠ficos\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Dependencia para obtener modelo\n",
    "async def get_model(model_name: str = \"churn_logistic_regression_20241201\"):\n",
    "    if model_name not in ml_models:\n",
    "        available_models = list(ml_models.keys())\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Modelo '{model_name}' no encontrado. Modelos disponibles: {available_models}\"\n",
    "        )\n",
    "    return ml_models[model_name]\n",
    "\n",
    "# === ENDPOINTS ===\n",
    "\n",
    "@app.get(\"/\", tags=[\"info\"])\n",
    "async def root():\n",
    "    \"\"\"Informaci√≥n b√°sica de la API\"\"\"\n",
    "    return {\n",
    "        \"message\": \"üéØ Churn Prediction API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"active\",\n",
    "        \"models_loaded\": len(ml_models),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\", tags=[\"monitoring\"])\n",
    "async def health_check():\n",
    "    \"\"\"Health check para monitoreo\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"models_count\": len(ml_models),\n",
    "        \"models_available\": list(ml_models.keys()),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/models\", tags=[\"models\"])\n",
    "async def list_models():\n",
    "    \"\"\"Listar modelos disponibles\"\"\"\n",
    "    model_info = {}\n",
    "    \n",
    "    for name, model in ml_models.items():\n",
    "        model_info[name] = {\n",
    "            \"type\": type(model).__name__,\n",
    "            \"steps\": [step[0] for step in model.steps] if hasattr(model, 'steps') else \"Pipeline\",\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"available_models\": model_info,\n",
    "        \"total_count\": len(ml_models)\n",
    "    }\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"predictions\"])\n",
    "async def predict_churn(\n",
    "    customer: CustomerInput,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    model_name: str = \"churn_logistic_regression_20241201\",\n",
    "    model = Depends(get_model)\n",
    "):\n",
    "    \"\"\"\n",
    "    üéØ Predecir probabilidad de churn para un cliente\n",
    "    \n",
    "    Utiliza el modelo especificado para calcular la probabilidad de que\n",
    "    el cliente cancele su servicio.\n",
    "    \n",
    "    - **customer**: Datos del cliente (ver esquema completo abajo)\n",
    "    - **model_name**: Nombre del modelo a utilizar\n",
    "    \n",
    "    Retorna predicci√≥n, probabilidades y metadatos del modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Convertir datos de entrada a formato de diccionario\n",
    "        customer_dict = customer.model_dump()\n",
    "        \n",
    "        # Hacer predicci√≥n\n",
    "        prediction = model.predict([customer_dict])[0]\n",
    "        probabilities = model.predict_proba([customer_dict])[0]\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        churn_probability = float(probabilities[1])\n",
    "        retention_probability = float(probabilities[0])\n",
    "        confidence = max(probabilities)\n",
    "        \n",
    "        # Determinar categor√≠a de riesgo\n",
    "        if churn_probability >= 0.7:\n",
    "            risk_category = \"High\"\n",
    "        elif churn_probability >= 0.4:\n",
    "            risk_category = \"Medium\"  \n",
    "        else:\n",
    "            risk_category = \"Low\"\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        response = PredictionResponse(\n",
    "            prediction=int(prediction),\n",
    "            churn_probability=churn_probability,\n",
    "            retention_probability=retention_probability,\n",
    "            risk_category=risk_category,\n",
    "            confidence=float(confidence),\n",
    "            model_info={\n",
    "                \"name\": model_name,\n",
    "                \"type\": type(model).__name__,\n",
    "                \"version\": \"1.0.0\"\n",
    "            },\n",
    "            processing_time_ms=int(processing_time),\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        # Log en background (no bloquea la respuesta)\n",
    "        background_tasks.add_task(\n",
    "            log_prediction,\n",
    "            customer_dict,\n",
    "            response.model_dump(),\n",
    "            model_name\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en predicci√≥n: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Error procesando predicci√≥n: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Funci√≥n de logging as√≠ncrono\n",
    "async def log_prediction(customer_data: dict, prediction_result: dict, model_name: str):\n",
    "    \"\"\"Registrar predicci√≥n para monitoreo y an√°lisis\"\"\"\n",
    "    logger.info(\n",
    "        f\"PREDICTION - Model: {model_name}, \"\n",
    "        f\"Churn_Prob: {prediction_result['churn_probability']:.3f}, \"\n",
    "        f\"Risk: {prediction_result['risk_category']}, \"\n",
    "        f\"Tenure: {customer_data.get('tenure', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True,\n",
    "        log_level=\"info\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bf7a0-1171-45b6-b954-844ea3f7b5f0",
   "metadata": {},
   "source": [
    "## 5. Modelos de Validaci√≥n con Pydantic\n",
    "\n",
    "Imagina que tu aplicaci√≥n es un club exclusivo y los datos que intentan entrar son los invitados. Pydantic es el **guardia de seguridad en la puerta** . T√∫ le das al guardia una lista estricta de invitados (`BaseModel`), y √©l se encarga de:\n",
    "\n",
    "1.  **Verificar la identidad**: Comprueba que los datos que llegan tienen los campos que esperas (nombre, edad, etc.).\n",
    "2.  **Revisar la edad**: Se asegura de que cada dato sea del tipo correcto (que la edad sea un n√∫mero, no texto).\n",
    "3.  **No dejar entrar a cualquiera**: Rechaza los datos que no cumplen las reglas y te dice exactamente por qu√©.\n",
    "\n",
    "En resumen, Pydantic usa las pistas de tipos de Python (`type hints`) para definir la \"forma\" que deben tener tus datos y luego se asegura de que se cumpla.\n",
    "\n",
    "### ¬øC√≥mo se usa?\n",
    "\n",
    "Para definir tu \"lista de invitados\", creas una clase que hereda de `BaseModel`.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class Usuario(BaseModel):\n",
    "    id: int\n",
    "    nombre: str\n",
    "    es_miembro_activo: bool\n",
    "    intereses: List[str] = []  # Valor por defecto: una lista vac√≠a\n",
    "    edad: Optional[int] = None # Campo opcional (puede ser int o None)\n",
    "```\n",
    "\n",
    "Este modelo le dice a Pydantic: \"Un `Usuario` **debe** tener un `id` (entero), un `nombre` (texto) y un estado `es_miembro_activo` (booleano). Opcionalmente, puede tener una `edad` (entero) y una lista de `intereses`.\"\n",
    "\n",
    "### La Validaci√≥n en Acci√≥n\n",
    "\n",
    "Ahora, cuando recibes datos (por ejemplo, un JSON de una API), se los pasas al modelo.\n",
    "\n",
    "```python\n",
    "datos_externos = {\n",
    "    \"id\": \"123\", # ¬°Ojo, es un string!\n",
    "    \"nombre\": \"Gema\",\n",
    "    \"es_miembro_activo\": \"true\", # ¬°Otro string!\n",
    "    \"intereses\": [\"AI\", \"Python\"]\n",
    "}\n",
    "\n",
    "try:\n",
    "    usuario_validado = Usuario(**datos_externos)\n",
    "    print(usuario_validado)\n",
    "    # SALIDA:\n",
    "    # id=123 es_miembro_activo=True intereses=['AI', 'Python'] edad=None nombre='Gema'\n",
    "    \n",
    "    print(usuario_validado.id)\n",
    "    # SALIDA:\n",
    "    # 123 (¬°como un entero!)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "```\n",
    "\n",
    "Pydantic no solo **valida**, sino que tambi√©n **convierte** los datos al tipo correcto (el `\"123\"` se convierte en el n√∫mero `123`). Si los datos fueran incorrectos (por ejemplo, `id: \"hola\"`), Pydantic generar√≠a un error muy claro que te dir√≠a exactamente qu√© campo est√° mal y por qu√©.\n",
    "\n",
    "Esto hace que tu c√≥digo sea extremadamente **robusto y seguro**, especialmente cuando trabajas con APIs como FastAPI, donde Pydantic es una pieza fundamental.\n",
    "\n",
    "\n",
    "### Exportando Modelos\n",
    "\n",
    "Una vez que Pydantic ha validado y creado tu objeto, a menudo necesitas convertirlo de nuevo a un formato est√°ndar, como un diccionario de Python o un string JSON (por ejemplo, para enviarlo como respuesta en una API). Pydantic hace esto trivial.\n",
    "\n",
    "  - **`.dict()`**: Convierte el modelo a un diccionario de Python.\n",
    "  - **`.json()`**: Convierte el modelo directamente a un string con formato JSON.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Producto(BaseModel):\n",
    "    id: int\n",
    "    nombre: str\n",
    "    stock: int = 0\n",
    "\n",
    "# Creamos una instancia del modelo\n",
    "producto_a = Producto(id=1, nombre=\"Laptop Pro\", stock=55)\n",
    "\n",
    "# Lo convertimos a un diccionario\n",
    "print(producto_a.dict())\n",
    "# SALIDA: {'id': 1, 'nombre': 'Laptop Pro', 'stock': 55}\n",
    "\n",
    "# Lo convertimos a un string JSON\n",
    "print(producto_a.json())\n",
    "# SALIDA: '{\"id\": 1, \"nombre\": \"Laptop Pro\", \"stock\": 55}'\n",
    "```\n",
    "\n",
    "### Personalizaci√≥n de Campos con `Field`\n",
    "\n",
    "A veces, no basta con definir un tipo. Es posible que necesites a√±adir m√°s reglas o metadatos a un campo, como validaciones num√©ricas, longitudes m√°ximas, o un nombre diferente para cuando los datos vienen de fuera. Para esto se usa `Field`.\n",
    "\n",
    "Una de sus funciones m√°s √∫tiles es el **alias**. Imagina que una API externa te env√≠a datos en `camelCase` (`productId`), pero en Python prefieres usar `snake_case` (`product_id`). Pydantic maneja esta conversi√≥n por ti.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Artista(BaseModel):\n",
    "    # Pydantic esperar√° una clave \"artistName\" en los datos de entrada\n",
    "    nombre_artista: str = Field(alias='artistName')\n",
    "    edad: int = Field(\n",
    "        gt=0, # gt = greater than (mayor que 0)\n",
    "        le=120, # le = less than or equal (menor o igual a 120)\n",
    "        description=\"La edad del artista debe estar entre 1 y 120.\"\n",
    "    )\n",
    "\n",
    "datos_externos = {\"artistName\": \"Leo\", \"edad\": 35}\n",
    "artista_validado = Artista(**datos_externos)\n",
    "\n",
    "print(artista_validado.nombre_artista) # Imprime \"Leo\"\n",
    "```\n",
    "\n",
    "Con `Field` puedes a√±adir restricciones como: **`gt`** (mayor que), **`lt`** (menor que), **`max_length`**, **`min_length`**, etc.\n",
    "\n",
    "### Validadores Personalizados (`@validator`)\n",
    "\n",
    "Mientras que `Field` te da reglas predefinidas (como `gt` o `max_length`), `@validator` te permite crear **tus propias funciones de validaci√≥n** para implementar cualquier l√≥gica que necesites. Es como pasar de una lista de reglas a contratar a un detective que puede hacer una investigaci√≥n a fondo.\n",
    "\n",
    "Se aplica como un decorador a un m√©todo dentro de tu clase. Este m√©todo recibe el valor del campo y debe devolverlo (posiblemente transformado) o lanzar un `ValueError` si no es v√°lido.\n",
    "\n",
    "**Ejemplo**: Asegurarse de que un nombre de usuario no contenga caracteres especiales.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class Usuario(BaseModel):\n",
    "    username: str\n",
    "\n",
    "    @validator('username')\n",
    "    def username_no_debe_contener_especiales(cls, v):\n",
    "        # v es el valor del campo 'username'\n",
    "        if not v.isalnum(): # isalnum() comprueba si es alfanum√©rico\n",
    "            raise ValueError('El nombre de usuario solo puede contener letras y n√∫meros.')\n",
    "        return v\n",
    "\n",
    "# Esto funcionar√°\n",
    "usuario_ok = Usuario(username='gema123')\n",
    "\n",
    "# Esto lanzar√° el ValueError que definimos\n",
    "try:\n",
    "    usuario_malo = Usuario(username='gema-123!')\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "### Validadores Ra√≠z (`@root_validator`)\n",
    "\n",
    "Un validador ra√≠z es a√∫n m√°s potente: se ejecuta **despu√©s de todos los validadores de campos individuales** y tiene acceso a **todos los datos del modelo** a la vez. Es perfecto para validaciones que dependen de la relaci√≥n entre varios campos.\n",
    "\n",
    "**Ejemplo**: Confirmar que dos campos de contrase√±a coinciden.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, root_validator\n",
    "\n",
    "class FormularioRegistro(BaseModel):\n",
    "    password: str\n",
    "    confirm_password: str\n",
    "\n",
    "    @root_validator()\n",
    "    def las_contrase√±as_deben_coincidir(cls, values):\n",
    "        # 'values' es un diccionario con todos los campos: {'password': '...', 'confirm_password': '...'}\n",
    "        password = values.get('password')\n",
    "        confirm_password = values.get('confirm_password')\n",
    "\n",
    "        if password is not None and password != confirm_password:\n",
    "            raise ValueError('Las contrase√±as no coinciden.')\n",
    "        \n",
    "        return values\n",
    "\n",
    "# Esto funcionar√°\n",
    "formulario_ok = FormularioRegistro(password='1234', confirm_password='1234')\n",
    "\n",
    "# Esto lanzar√° el ValueError\n",
    "try:\n",
    "    formulario_malo = FormularioRegistro(password='1234', confirm_password='abcd')\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "### Configuraci√≥n del Modelo (clase `Config`)\n",
    "\n",
    "Puedes cambiar el comportamiento general de tu modelo Pydantic a√±adiendo una clase interna llamada `Config`. Esto te permite ajustar muchas opciones.\n",
    "\n",
    "Algunas de las m√°s √∫tiles son:\n",
    "\n",
    "  - **`orm_mode = True`**: Permite que el modelo se cree a partir de objetos de un ORM (como SQLAlchemy), leyendo sus atributos directamente. Esencial para trabajar con bases de datos.\n",
    "  - **`anystr_strip_whitespace = True`**: Elimina autom√°ticamente los espacios en blanco al principio y al final de todos los campos de texto.\n",
    "  - **`validate_assignment = True`**: Hace que el modelo vuelva a validar un campo cada vez que le asignas un nuevo valor, no solo durante la creaci√≥n.\n",
    "  - **`allow_population_by_field_name = True`**: Permite poblar el modelo usando tanto el nombre del campo como su alias.\n",
    "\n",
    "**Ejemplo**:\n",
    "\n",
    "```python\n",
    "class Usuario(BaseModel):\n",
    "    nombre: str\n",
    "\n",
    "    class Config:\n",
    "        anystr_strip_whitespace = True\n",
    "\n",
    "# Pydantic eliminar√° los espacios autom√°ticamente\n",
    "usuario = Usuario(nombre=\"  Usera  \")\n",
    "print(usuario.nombre) # Salida: \"Usera\"\n",
    "```\n",
    "\n",
    "En resumen, con los validadores y la clase `Config`, tienes un control total sobre c√≥mo tus modelos interpretan, validan y gestionan los datos.\n",
    "\n",
    "### Modelos Anidados\n",
    "\n",
    "Los datos del mundo real rara vez son planos. Es muy com√∫n tener objetos dentro de otros objetos. Pydantic maneja esto de forma muy natural: simplemente usas un modelo como el tipo de otro campo.\n",
    "\n",
    "```python\n",
    "from typing import List\n",
    "\n",
    "class Cancion(BaseModel):\n",
    "    titulo: str\n",
    "    duracion_seg: int\n",
    "\n",
    "class Album(BaseModel):\n",
    "    titulo_album: str\n",
    "    a√±o_lanzamiento: int\n",
    "    canciones: List[Cancion] # ¬°Una lista de otros modelos!\n",
    "\n",
    "datos_album = {\n",
    "    \"titulo_album\": \"Grandes √âxitos\",\n",
    "    \"a√±o_lanzamiento\": 2024,\n",
    "    \"canciones\": [\n",
    "        {\"titulo\": \"Mi Primera Canci√≥n\", \"duracion_seg\": 180},\n",
    "        {\"titulo\": \"El Hit del Verano\", \"duracion_seg\": 210}\n",
    "    ]\n",
    "}\n",
    "\n",
    "album_obj = Album(**datos_album)\n",
    "\n",
    "# Accedes a los datos de forma intuitiva\n",
    "print(album_obj.titulo_album) # Imprime \"Grandes √âxitos\"\n",
    "print(album_obj.canciones[0].titulo) # Imprime \"Mi Primera Canci√≥n\"\n",
    "```\n",
    "\n",
    "### Tipos Comunes Pre-validados\n",
    "\n",
    "Pydantic viene con una gran variedad de **tipos de datos ya preparados** que tienen validaciones complejas incorporadas, ahorr√°ndote el trabajo de escribirlas t√∫ mismo.\n",
    "\n",
    "Estos tipos especiales se importan directamente de Pydantic o de la biblioteca est√°ndar de Python y se usan como cualquier otro tipo (`str`, `int`, etc.).\n",
    "\n",
    "Aqu√≠ tienes una lista de algunos de los m√°s √∫tiles con ejemplos.\n",
    "\n",
    "#### 1\\. Direcciones de Correo Electr√≥nico\n",
    "\n",
    "Para validar que una cadena de texto tiene el formato de un email, usas `EmailStr`.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, EmailStr\n",
    "\n",
    "class Usuario(BaseModel):\n",
    "    email: EmailStr\n",
    "\n",
    "# Esto funciona\n",
    "usuario_ok = Usuario(email=\"usuario@google.com\")\n",
    "\n",
    "# Esto fallar√° con un error de validaci√≥n\n",
    "try:\n",
    "    usuario_malo = Usuario(email=\"texto-invalido\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "#### 2\\. URLs\n",
    "\n",
    "Pydantic ofrece varios tipos para validar URLs, siendo `AnyHttpUrl` uno de los m√°s comunes para validar direcciones web `http` o `httpsapps`.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, AnyHttpUrl\n",
    "\n",
    "class PaginaWeb(BaseModel):\n",
    "    url: AnyHttpUrl\n",
    "\n",
    "# Esto funciona\n",
    "pagina_ok = PaginaWeb(url=\"https://www.google.com\")\n",
    "\n",
    "# Esto fallar√°\n",
    "try:\n",
    "    pagina_mala = PaginaWeb(url=\"ftp://servidor.com\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "```\n",
    "\n",
    "#### 3\\. UUIDs\n",
    "\n",
    "Si trabajas con identificadores √∫nicos universales (UUID), puedes usar el tipo `UUID` de la biblioteca est√°ndar de Python. Pydantic lo soporta nativamente.\n",
    "\n",
    "```python\n",
    "from uuid import UUID\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Pedido(BaseModel):\n",
    "    id_pedido: UUID\n",
    "\n",
    "# Esto funciona\n",
    "pedido_ok = Pedido(id_pedido=\"123e4567-e89b-12d3-a456-426614174000\")\n",
    "\n",
    "# Esto fallar√°\n",
    "try:\n",
    "    pedido_malo = Pedido(id_pedido=\"no-es-un-uuid\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "#### 4\\. Tipos Estrictos\n",
    "\n",
    "A veces, quieres evitar que Pydantic convierta tipos (por ejemplo, que `\"123\"` no se convierta en `123`). Para eso, existen los tipos estrictos como `StrictStr` o `StrictInt`.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, StrictInt\n",
    "\n",
    "class Producto(BaseModel):\n",
    "    stock: StrictInt\n",
    "\n",
    "# Esto funciona\n",
    "prod_ok = Producto(stock=50)\n",
    "\n",
    "# Esto fallar√° porque \"50\" es un string, no un entero\n",
    "try:\n",
    "    prod_malo = Producto(stock=\"50\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "```\n",
    "\n",
    "Esta es solo una peque√±a muestra. La documentaci√≥n de Pydantic tiene una lista completa que incluye tipos para redes (`IPv4Address`), archivos (`FilePath`), colores (`Color`), y muchos m√°s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227d033-79b6-4bf5-9132-7fa77c94c62c",
   "metadata": {},
   "source": [
    "### Esquemas de Entrada y Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dfb20-d02e-46fd-bdd9-8b51bd45d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/schemas/predictions.py\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "class RiskCategory(str, Enum):\n",
    "    \"\"\"Categor√≠as de riesgo de churn\"\"\"\n",
    "    LOW = \"Low\"\n",
    "    MEDIUM = \"Medium\" \n",
    "    HIGH = \"High\"\n",
    "\n",
    "class ContractType(str, Enum):\n",
    "    \"\"\"Tipos de contrato disponibles\"\"\"\n",
    "    MONTH_TO_MONTH = \"Month-to-month\"\n",
    "    ONE_YEAR = \"One year\"\n",
    "    TWO_YEAR = \"Two year\"\n",
    "\n",
    "class PaymentMethod(str, Enum):\n",
    "    \"\"\"M√©todos de pago disponibles\"\"\"\n",
    "    ELECTRONIC_CHECK = \"Electronic check\"\n",
    "    MAILED_CHECK = \"Mailed check\"\n",
    "    BANK_TRANSFER = \"Bank transfer (automatic)\"\n",
    "    CREDIT_CARD = \"Credit card (automatic)\"\n",
    "\n",
    "class InternetService(str, Enum):\n",
    "    \"\"\"Tipos de servicio de internet\"\"\"\n",
    "    DSL = \"DSL\"\n",
    "    FIBER_OPTIC = \"Fiber optic\"\n",
    "    NO = \"No\"\n",
    "\n",
    "class CustomerInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo de entrada para datos del cliente.\n",
    "    \n",
    "    Todos los campos son validados autom√°ticamente por Pydantic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Informaci√≥n demogr√°fica\n",
    "    gender: str = Field(\n",
    "        ..., \n",
    "        description=\"G√©nero del cliente\",\n",
    "        example=\"Male\"\n",
    "    )\n",
    "    \n",
    "    senior_citizen: int = Field(\n",
    "        ..., \n",
    "        ge=0, \n",
    "        le=1,\n",
    "        description=\"Es ciudadano senior (0=No, 1=S√≠)\",\n",
    "        example=0\n",
    "    )\n",
    "    \n",
    "    partner: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene pareja\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    dependents: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene dependientes\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    # Informaci√≥n del servicio\n",
    "    tenure: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Meses como cliente\",\n",
    "        example=24\n",
    "    )\n",
    "    \n",
    "    phone_service: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene servicio telef√≥nico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    internet_service: InternetService = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de servicio de internet\",\n",
    "        example=\"Fiber optic\"\n",
    "    )\n",
    "    \n",
    "    online_security: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene seguridad online\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    tech_support: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene soporte t√©cnico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    # Informaci√≥n contractual y financiera\n",
    "    contract: ContractType = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de contrato\",\n",
    "        example=\"Month-to-month\"\n",
    "    )\n",
    "    \n",
    "    payment_method: PaymentMethod = Field(\n",
    "        ...,\n",
    "        description=\"M√©todo de pago\",\n",
    "        example=\"Electronic check\"\n",
    "    )\n",
    "    \n",
    "    monthly_charges: float = Field(\n",
    "        ...,\n",
    "        gt=0,\n",
    "        lt=200,\n",
    "        description=\"Cargos mensuales en USD\",\n",
    "        example=85.50\n",
    "    )\n",
    "    \n",
    "    total_charges: float = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Total de cargos acumulados en USD\",\n",
    "        example=2052.00\n",
    "    )\n",
    "    \n",
    "    # Campo opcional para ID del cliente\n",
    "    customer_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"ID opcional del cliente\",\n",
    "        example=\"CUST001\"\n",
    "    )\n",
    "    \n",
    "    @validator('gender')\n",
    "    def validate_gender(cls, v):\n",
    "        allowed_genders = ['Male', 'Female']\n",
    "        if v not in allowed_genders:\n",
    "            raise ValueError(f'Gender debe ser uno de: {allowed_genders}')\n",
    "        return v\n",
    "    \n",
    "    @validator('partner', 'dependents', 'phone_service')\n",
    "    def validate_yes_no_fields(cls, v, field):\n",
    "        allowed_values = ['Yes', 'No']\n",
    "        if v not in allowed_values:\n",
    "            raise ValueError(f'{field.name} debe ser \"Yes\" o \"No\"')\n",
    "        return v\n",
    "\n",
    "    class Config:\n",
    "        # Configuraci√≥n del modelo Pydantic\n",
    "        str_strip_whitespace = True  # Eliminar espacios en blanco\n",
    "        validate_assignment = True   # Validar en asignaciones\n",
    "        use_enum_values = True      # Usar valores de enum\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"gender\": \"Female\",\n",
    "                \"senior_citizen\": 0,\n",
    "                \"partner\": \"Yes\",\n",
    "                \"dependents\": \"No\", \n",
    "                \"tenure\": 24,\n",
    "                \"phone_service\": \"Yes\",\n",
    "                \"internet_service\": \"Fiber optic\",\n",
    "                \"online_security\": \"No\",\n",
    "                \"tech_support\": \"Yes\",\n",
    "                \"contract\": \"Month-to-month\",\n",
    "                \"payment_method\": \"Electronic check\",\n",
    "                \"monthly_charges\": 85.50,\n",
    "                \"total_charges\": 2052.00,\n",
    "                \"customer_id\": \"CUST001\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Respuesta de la predicci√≥n de churn\"\"\"\n",
    "    \n",
    "    prediction: int = Field(\n",
    "        ...,\n",
    "        description=\"Predicci√≥n de churn (0=No Churn, 1=Churn)\",\n",
    "        example=1\n",
    "    )\n",
    "    \n",
    "    churn_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de churn\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    retention_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de retenci√≥n\",\n",
    "        example=0.25\n",
    "    )\n",
    "    \n",
    "    risk_category: RiskCategory = Field(\n",
    "        ...,\n",
    "        description=\"Categor√≠a de riesgo\",\n",
    "        example=\"High\"\n",
    "    )\n",
    "    \n",
    "    confidence: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Confianza del modelo\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    model_info: Dict[str, Any] = Field(\n",
    "        ...,\n",
    "        description=\"Informaci√≥n del modelo utilizado\",\n",
    "        example={\n",
    "            \"name\": \"churn_logistic_regression\",\n",
    "            \"type\": \"Pipeline\",\n",
    "            \"version\": \"1.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time_ms: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Tiempo de procesamiento en milisegundos\",\n",
    "        example=150\n",
    "    )\n",
    "    \n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Timestamp de la predicci√≥n\",\n",
    "        example=\"2024-12-01T10:30:00\"\n",
    "    )\n",
    "\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    \"\"\"Solicitud de predicci√≥n por lotes\"\"\"\n",
    "    \n",
    "    customers: List[CustomerInput] = Field(\n",
    "        ...,\n",
    "        min_items=1,\n",
    "        max_items=1000,  # L√≠mite para evitar sobrecarga\n",
    "        description=\"Lista de clientes para predecir\"\n",
    "    )\n",
    "    \n",
    "    include_details: bool = Field(\n",
    "        True,\n",
    "        description=\"Incluir detalles completos en la respuesta\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984d960-a61a-467d-bbaf-a50967d46df5",
   "metadata": {},
   "source": [
    "## 6. Contenedorizaci√≥n con Docker\n",
    "\n",
    "Docker es una plataforma que te permite **empaquetar y ejecutar aplicaciones en contenedores**.\n",
    "\n",
    "Piensa en un **contenedor** como una **caja de env√≠o estandarizada**. No importa lo que pongas dentro (una aplicaci√≥n de Python, una base de datos, un servidor web), la caja tiene la misma forma por fuera. Esto significa que puedes mover y ejecutar esa caja en cualquier lugar que entienda el est√°ndar (cualquier m√°quina con Docker), y lo que est√° adentro funcionar√° exactamente igual.\n",
    "\n",
    "Esto resuelve el cl√°sico problema de \"en mi m√°quina s√≠ funciona\", asegurando que el entorno de desarrollo sea id√©ntico al de producci√≥n.\n",
    "\n",
    "### ¬øQu√© es un Contenedor?\n",
    "\n",
    "Un **contenedor** es un paquete ligero y ejecutable que incluye todo lo necesario para que una aplicaci√≥n se ejecute: el c√≥digo, las librer√≠as, las herramientas del sistema y las dependencias.\n",
    "\n",
    "La diferencia clave con una m√°quina virtual (VM) es que los contenedores **comparten el kernel del sistema operativo anfitri√≥n**, mientras que una VM incluye un sistema operativo completo. Esto los hace mucho m√°s **ligeros, r√°pidos y eficientes**.\n",
    "\n",
    "  - **M√°quina Virtual**: Es como construir una casa entera (con cimientos, paredes, techo) para cada aplicaci√≥n.\n",
    "  - **Contenedor**: Es como alquilar un apartamento en un edificio ya existente. Todos los apartamentos (contenedores) comparten los cimientos (el kernel del SO), pero est√°n completamente aislados unos de otros.\n",
    "\n",
    "### El Flujo de Trabajo de Docker\n",
    "\n",
    "El proceso se basa en dos conceptos claves: **Im√°genes** y **Contenedores**.\n",
    "\n",
    "**Dockerfile: La Receta**\n",
    "\n",
    "Todo comienza con un `Dockerfile`, que es un archivo de texto con instrucciones paso a paso para construir el entorno de tu aplicaci√≥n. Es como la receta para hornear un pastel.\n",
    "\n",
    "```dockerfile\n",
    "# Usar una imagen base oficial de Python\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Establecer el directorio de trabajo dentro del contenedor\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar los archivos de dependencias\n",
    "COPY pyproject.toml uv.lock ./\n",
    "\n",
    "# Instalar las dependencias\n",
    "RUN pip install uv && uv sync uv.lock\n",
    "\n",
    "# Copiar el resto del c√≥digo de la aplicaci√≥n\n",
    "COPY ./src /app/src\n",
    "\n",
    "# Comando para ejecutar la aplicaci√≥n cuando el contenedor se inicie\n",
    "CMD [\"uvicorn\", \"src.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n",
    "```\n",
    "\n",
    "\n",
    "**Imagen Docker: El Pastel Pre-hecho**\n",
    "\n",
    "Cuando ejecutas el comando `docker build` usando un `Dockerfile`, Docker sigue las instrucciones y crea una **Imagen Docker**. Una imagen es una **plantilla inmutable y de solo lectura**. Es como el pastel ya horneado y empaquetado, listo para ser distribuido. Estas im√°genes se pueden subir a un registro como Docker Hub para compartirlas.\n",
    "\n",
    "**Contenedor Docker: Comi√©ndose el Pastel**\n",
    "\n",
    "Finalmente, para ejecutar tu aplicaci√≥n, creas un **Contenedor** a partir de la imagen con el comando `docker run`. Un contenedor es una **instancia en ejecuci√≥n de una imagen**. Puedes crear tantos contenedores como quieras a partir de la misma imagen, al igual que puedes repartir muchas porciones del mismo pastel.\n",
    "\n",
    "### Comandos Esenciales de Docker\n",
    "\n",
    "Para trabajar con Docker, usar√°s un pu√±ado de comandos clave en tu terminal. Aqu√≠ est√°n los m√°s importantes:\n",
    "\n",
    "- **`docker build -t mi-aplicacion .`**\n",
    "  Construye una **imagen** a partir de un `Dockerfile` en el directorio actual (`.`). La `-t` le pone un \"tag\" o nombre (`mi-aplicacion`) para que puedas encontrarla f√°cilmente.\n",
    "\n",
    "- **`docker run -p 8000:80 mi-aplicacion`**\n",
    "  Crea y ejecuta un **contenedor** a partir de la imagen `mi-aplicacion`. El `-p 8000:80` es clave: **mapea el puerto** 8000 de tu m√°quina al puerto 80 dentro del contenedor, permiti√©ndote acceder a la aplicaci√≥n desde tu navegador en `http://localhost:8000`.\n",
    "\n",
    "- **`docker ps`**\n",
    "  Muestra una lista de todos los **contenedores que est√°n en ejecuci√≥n**. (`ps` viene de \"processes\"). Si a√±ades `-a`, te mostrar√° todos los contenedores, incluso los que est√°n detenidos.\n",
    "\n",
    "- **`docker stop <id_del_contenedor>`**\n",
    "  Detiene un contenedor en ejecuci√≥n de forma segura.\n",
    "\n",
    "- **`docker rm <id_del_contenedor>`**\n",
    "  Elimina un contenedor que ya ha sido detenido.\n",
    "\n",
    "- **`docker images`**\n",
    "  Muestra todas las **im√°genes** que tienes descargadas en tu m√°quina.\n",
    "\n",
    "- **`docker rmi <id_de_la_imagen>`**\n",
    "  Elimina una imagen de tu m√°quina.\n",
    "\n",
    "- **`docker run -it`**\n",
    "\n",
    "  Cuando ejecutas un contenedor, a veces no solo quieres que corra en segundo plano, sino que necesitas **interactuar con √©l** a trav√©s de una terminal, como si estuvieras \"dentro\" del contenedor. Para esto se combinan las banderas `-i` y `-t`.\n",
    "    \n",
    "  **`-i` (`--interactive`)**: Mantiene la entrada est√°ndar (STDIN) abierta. Esto significa que el contenedor puede **recibir** lo que escribes en tu teclado.\n",
    "  **`-t` (`--tty`)**: Asigna una \"pseudo-TTY\" o terminal. Esto le da al contenedor una **interfaz de terminal** para que pueda mostrarte la salida de forma legible.\n",
    "    \n",
    "  Juntos, `-it`, te dan un **shell interactivo** dentro del contenedor. Es perfecto para depurar, explorar el sistema de archivos del contenedor o ejecutar comandos manualmente.\n",
    "\n",
    "  **Ejemplo Pr√°ctico**: Iniciar un shell en un contenedor con Ubuntu.\n",
    "    \n",
    "  ```bash\n",
    "      # Descarga la imagen de Ubuntu y te da una terminal de bash dentro\n",
    "      docker run -it ubuntu bash\n",
    "  ```\n",
    "  \n",
    "   Una vez que ejecutas esto, tu terminal cambiar√° y estar√°s \"dentro\" del contenedor, donde podr√°s ejecutar comandos como `ls`, `pwd`, o `apt-get install`.\n",
    "\n",
    "### Vol√∫menes\n",
    "\n",
    "Por defecto, los contenedores son **ef√≠meros**. Si eliminas un contenedor de base de datos, ¬°todos los datos se van con √©l! Para solucionar esto, se usan los **vol√∫menes**.\n",
    "\n",
    "Un **volumen** es como una \"mochila\" de almacenamiento que conectas a tu contenedor. Es un directorio en tu m√°quina anfitriona que se sincroniza con un directorio dentro del contenedor. De esta forma, los datos importantes (como los de una base de datos) se guardan de forma segura en tu m√°quina, incluso si el contenedor se detiene o se elimina.\n",
    "\n",
    "### Orquestando M√∫ltiples Contenedores con Docker Compose\n",
    "\n",
    "Una aplicaci√≥n real rara vez es un solo contenedor. Normalmente tienes varios servicios que necesitan comunicarse entre s√≠: un contenedor para tu API de Python, otro para una base de datos PostgreSQL, y quiz√°s otro para un sistema de cach√© como Redis.\n",
    "\n",
    "Gestionar todo esto con comandos `docker run` individuales ser√≠a un caos. Para eso existe **Docker Compose**.\n",
    "\n",
    "**Docker Compose** es una herramienta que te permite definir y ejecutar aplicaciones multi-contenedor usando un solo archivo de configuraci√≥n llamado `docker-compose.yml`.  En este archivo, describes todos tus servicios, c√≥mo se conectan entre s√≠, qu√© vol√∫menes usan y qu√© puertos exponen.\n",
    "\n",
    "Luego, con un solo comando (`docker-compose up`), levantas toda tu aplicaci√≥n, y con (`docker-compose down`), la detienes y eliminas todo de forma limpia. Es el est√°ndar de facto para el desarrollo local con Docker.\n",
    "\n",
    "#### Estructura de `docker-compose.yml`\n",
    "\n",
    "El archivo `docker-compose.yml` es el **plano de construcci√≥n** de tu aplicaci√≥n multi-contenedor. Utiliza el formato YAML, que es muy legible.\n",
    "\n",
    "Un archivo t√≠pico tiene las siguientes secciones principales:\n",
    "\n",
    "  - **`services`**: Es el coraz√≥n del archivo. Aqu√≠ defines cada uno de los contenedores (llamados \"servicios\") que componen tu aplicaci√≥n.\n",
    "  - **`volumes`**: Aqu√≠ puedes definir \"vol√∫menes con nombre\" para que tus datos persistan.\n",
    "  - **`networks`**: Permite configurar redes personalizadas para que tus contenedores se comuniquen de forma aislada.\n",
    "\n",
    "#### Desglose de un Servicio\n",
    "\n",
    "Dentro de la secci√≥n `services`, cada servicio que defines (por ejemplo, `api` o `db`) tiene una serie de claves para configurarlo:\n",
    "\n",
    "  - **`image`**: Especifica la imagen de Docker Hub que se usar√° (ej. `postgres:15`).\n",
    "  - **`build`**: Si tienes un `Dockerfile`, aqu√≠ indicas la ruta para que Docker Compose construya la imagen por ti (ej. `build: .`).\n",
    "  - **`container_name`**: Un nombre personalizado para el contenedor.\n",
    "  - **`ports`**: Mapea los puertos. La sintaxis es `\"PUERTO_HOST:PUERTO_CONTENEDOR\"`.\n",
    "  - **`environment`**: Define variables de entorno, ideal para pasar configuraciones o secretos como contrase√±as de bases de datos.\n",
    "  - **`volumes`**: Conecta los vol√∫menes. Puede ser un volumen con nombre o una ruta de tu m√°quina (`./mi-codigo:/app`).\n",
    "  - **`depends_on`**: Le dice a Docker Compose que un servicio depende de otro. Por ejemplo, tu API no deber√≠a iniciar hasta que la base de datos est√© lista.\n",
    "\n",
    "#### Ejemplo Completo\n",
    "\n",
    "```yaml\n",
    "# Versi√≥n del formato del archivo (opcional en versiones recientes)\n",
    "version: '3.8'\n",
    "\n",
    "# Definici√≥n de todos los servicios (contenedores)\n",
    "services:\n",
    "  # Nuestro primer servicio: la API de Python\n",
    "  api:\n",
    "    build: . # Construye la imagen usando el Dockerfile en el directorio actual\n",
    "    container_name: mi_api_python\n",
    "    ports:\n",
    "      - \"8000:80\" # Mapea el puerto 8000 de mi m√°quina al 80 del contenedor\n",
    "    volumes:\n",
    "      - ./src:/app/src # Sincroniza el c√≥digo fuente para desarrollo en vivo\n",
    "    environment:\n",
    "      - DATABASE_URL=postgresql://user:password@db:5432/mydatabase\n",
    "    depends_on:\n",
    "      - db # Le dice a Docker que no inicie 'api' hasta que 'db' est√© listo\n",
    "\n",
    "  # Nuestro segundo servicio: la base de datos PostgreSQL\n",
    "  db:\n",
    "    image: postgres:15-alpine # Usa una imagen oficial de PostgreSQL\n",
    "    container_name: mi_base_de_datos\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    environment:\n",
    "      - POSTGRES_USER=user\n",
    "      - POSTGRES_PASSWORD=password\n",
    "      - POSTGRES_DB=mydatabase\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data # Usa un volumen con nombre para guardar los datos\n",
    "\n",
    "# Definici√≥n de los vol√∫menes con nombre\n",
    "volumes:\n",
    "  postgres_data: # Este volumen persistir√° aunque eliminemos el contenedor 'db'\n",
    "\n",
    "```\n",
    "\n",
    "### Docker Hub\n",
    "\n",
    "No siempre tienes que crear tus im√°genes desde cero. **Docker Hub** es un registro p√∫blico (una biblioteca gigante) donde la comunidad y las empresas publican im√°genes oficiales y pre-configuradas.\n",
    "\n",
    "Cuando en tu `Dockerfile` escribes `FROM python:3.11-slim`, Docker va a Docker Hub, descarga la imagen oficial de Python y la usa como base. De la misma manera, puedes encontrar im√°genes para `postgres`, `nginx`, `mongo`, y casi cualquier tecnolog√≠a que se te ocurra, lo que acelera enormemente el desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cd044-6415-44bd-9968-f6b75acee71d",
   "metadata": {},
   "source": [
    "### Dockerfile Optimizado\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile multi-stage optimizado para FastAPI + ML con uv\n",
    "\n",
    "# Etapa 1: Builder - Instalar dependencias\n",
    "FROM python:3.12-slim as builder\n",
    "\n",
    "# Instalar uv (gestor de paquetes r√°pido)\n",
    "COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n",
    "\n",
    "# Variables de entorno para optimizaci√≥n\n",
    "ENV UV_COMPILE_BYTECODE=1\n",
    "ENV UV_LINK_MODE=copy\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar archivos de dependencias\n",
    "COPY pyproject.toml ./\n",
    "\n",
    "# Crear entorno virtual e instalar dependencias\n",
    "RUN uv venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "RUN uv pip install -r pyproject.toml\n",
    "\n",
    "# Etapa 2: Runtime - Aplicaci√≥n final\n",
    "FROM python:3.12-slim as runtime\n",
    "\n",
    "# Instalar dependencias del sistema necesarias para ML\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libgomp1 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Variables de entorno\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Crear usuario no-root para seguridad\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar entorno virtual desde builder\n",
    "COPY --from=builder /opt/venv /opt/venv\n",
    "\n",
    "# Copiar c√≥digo de la aplicaci√≥n\n",
    "COPY src/ /app/src/\n",
    "COPY models/ /app/models/\n",
    "\n",
    "# Crear directorio para logs\n",
    "RUN mkdir -p /app/logs && chown -R appuser:appuser /app\n",
    "\n",
    "# Cambiar a usuario no-root\n",
    "USER appuser\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n",
    "    CMD python -c \"import requests; requests.get('http://localhost:8000/health')\"\n",
    "\n",
    "# Puerto de la aplicaci√≥n\n",
    "EXPOSE 8000\n",
    "\n",
    "# Comando por defecto - usar FastAPI CLI\n",
    "CMD [\"fastapi\", \"run\", \"src/main.py\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### Docker Compose para Desarrollo\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # Servicio principal de la API\n",
    "  churn-api:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    container_name: churn-prediction-api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - ENVIRONMENT=development\n",
    "      - LOG_LEVEL=INFO\n",
    "      - MODELS_PATH=/app/models\n",
    "    volumes:\n",
    "      # Volumen para desarrollo - hot reload\n",
    "      - ./src:/app/src:ro\n",
    "      - ./models:/app/models:ro\n",
    "      - ./logs:/app/logs\n",
    "    restart: unless-stopped\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 30s\n",
    "    networks:\n",
    "      - ml-network\n",
    "\n",
    "  # Redis para cach√© (opcional)\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: churn-api-cache\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    networks:\n",
    "      - ml-network\n",
    "    restart: unless-stopped\n",
    "    command: redis-server --appendonly yes\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "\n",
    "networks:\n",
    "  ml-network:\n",
    "    driver: bridge\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2aeaa4-5f3a-49ef-86b7-6df0a5ad2124",
   "metadata": {},
   "source": [
    "## 7. Despliegue en la Nube con Fly.io\n",
    "\n",
    "Fly.io es una moderna plataforma en la nube que facilita **desplegar aplicaciones y bases de datos cerca de tus usuarios**, sin importar en qu√© parte del mundo se encuentren.\n",
    "\n",
    "Piensa en Fly.io como una **aerol√≠nea de carga para tu c√≥digo**. En lugar de tener un √∫nico y gran almac√©n central (como un servidor tradicional en una sola regi√≥n), Fly.io tiene peque√±os centros de distribuci√≥n (servidores) en ciudades de todo el mundo. Cuando despliegas tu aplicaci√≥n, la empaquetan en un contenedor y la env√≠an a las ubicaciones m√°s cercanas a tus usuarios, lo que resulta en una latencia muy baja y una experiencia mucho m√°s r√°pida.\n",
    "\n",
    "### Despliegue en el \"Edge\"\n",
    "\n",
    "El superpoder de Fly.io es el **despliegue en el borde (edge)**. En lugar de ejecutar tu aplicaci√≥n en un centro de datos masivo en Virginia (EE. UU.), Fly.io puede ejecutarla simult√°neamente en Santiago, S√£o Paulo, Madrid y Tokio.  Cuando un usuario de Chile visita tu sitio, se conecta al servidor de Santiago, no al de EE. UU., lo que reduce dr√°sticamente el tiempo de respuesta.\n",
    "\n",
    "Fly.io logra esto tomando tu aplicaci√≥n (empaquetada como un contenedor Docker) y ejecut√°ndola en sus propias m√°quinas virtuales ligeras llamadas **Firecracker**.\n",
    "\n",
    "### El Flujo de Trabajo T√≠pico\n",
    "\n",
    "Desplegar en Fly.io es un proceso muy sencillo que se realiza desde la terminal con su herramienta `flyctl`.\n",
    "\n",
    "1.  **Instalar `flyctl`**: Primero, instalas su interfaz de l√≠nea de comandos (CLI) en tu m√°quina.\n",
    "2.  **`fly launch`**: Navegas al directorio de tu proyecto y ejecutas este comando. `flyctl` es inteligente:\n",
    "    -   **Inspecciona tu c√≥digo**: Detecta qu√© tipo de aplicaci√≥n tienes (Python/FastAPI, Node.js, etc.).\n",
    "    -   **Genera la configuraci√≥n**: Crea un archivo `fly.toml`, que es el \"manual de instrucciones\" de tu aplicaci√≥n para la plataforma Fly.io.\n",
    "    -   **Primer despliegue**: Empaqueta tu aplicaci√≥n en un contenedor Docker y la despliega en la nube.\n",
    "3.  **`fly deploy`**: Una vez que haces cambios en tu c√≥digo, simplemente ejecutas este comando para redesplegar la nueva versi√≥n.\n",
    "4.  **Monitoreo**: Usas comandos como `fly logs` para ver los registros de tu aplicaci√≥n en tiempo real o `fly status` para comprobar su estado.\n",
    "\n",
    "### El Archivo de Configuraci√≥n: `fly.toml`\n",
    "\n",
    "Este archivo es el centro de control de tu despliegue. Define todo lo que Fly.io necesita saber:\n",
    "\n",
    "-   El nombre de tu aplicaci√≥n (`app`).\n",
    "-   C√≥mo construir la imagen de Docker (`[build]`).\n",
    "-   Qu√© puertos necesita exponer tu aplicaci√≥n al mundo exterior (`[[services]]`).\n",
    "-   Verificaciones de estado (`[checks]`) para asegurarse de que tu aplicaci√≥n funciona correctamente.\n",
    "-   Variables de entorno y secretos.\n",
    "\n",
    "Aunque `fly launch` lo genera autom√°ticamente, puedes editarlo para personalizar completamente tu despliegue.\n",
    "\n",
    "### ¬øPor qu√© es tan popular?\n",
    "\n",
    "-   **Simplicidad**: El flujo de trabajo con `flyctl` es extremadamente directo y f√°cil de aprender.\n",
    "-   **Rendimiento**: El despliegue en el borde ofrece una latencia muy baja para usuarios de todo el mundo.\n",
    "-   **Plan Gratuito Generoso**: Fly.io ofrece un plan gratuito que es m√°s que suficiente para muchos proyectos personales, prototipos y aplicaciones peque√±as, permiti√©ndote desplegar hasta 3 aplicaciones peque√±as y bases de datos Postgres sin costo.\n",
    "-   **Bases de Datos**: Facilita enormemente el despliegue y la gesti√≥n de bases de datos **PostgreSQL**, que se pueden conectar f√°cilmente a tu aplicaci√≥n.\n",
    "\n",
    "### M√°quinas Virtuales Firecracker\n",
    "\n",
    "En lugar de usar contenedores Docker directamente en un servidor compartido, Fly.io ejecuta cada contenedor dentro de su propia **Micro M√°quina Virtual (MicroVM) Firecracker**.\n",
    "\n",
    "**Firecracker** es una tecnolog√≠a de virtualizaci√≥n de c√≥digo abierto desarrollada por Amazon (usada en AWS Lambda). Piensa en ellas como un punto intermedio perfecto entre un contenedor y una m√°quina virtual tradicional:\n",
    "\n",
    "-   **Arranque ultrarr√°pido**: Se inician en milisegundos, casi tan r√°pido como un contenedor.\n",
    "-   **Aislamiento de hardware**: Ofrecen la seguridad y el aislamiento de una m√°quina virtual completa. Tu aplicaci√≥n est√° completamente separada de las dem√°s, lo que es mucho m√°s seguro.\n",
    "-   **Ligeras**: Consumen muy pocos recursos.\n",
    "\n",
    "Este enfoque le da a Fly.io la velocidad de los contenedores con la seguridad de las m√°quinas virtuales.\n",
    "\n",
    "### \"Apps\" vs. \"Machines\"\n",
    "\n",
    "En la terminolog√≠a de Fly.io:\n",
    "-   Una **\"App\"** es tu proyecto completo (por ejemplo, `mi-api-python`). Es una agrupaci√≥n l√≥gica.\n",
    "-   Una **\"Machine\"** es una instancia individual de tu contenedor corriendo en una MicroVM Firecracker.\n",
    "\n",
    "Cuando despliegas tu aplicaci√≥n en varias regiones (por ejemplo, Chile, Brasil y Espa√±a), en realidad est√°s ejecutando tres **\"Machines\"** id√©nticas, todas parte de la misma **\"App\"**. Fly.io se encarga de dirigir a tus usuarios a la \"Machine\" m√°s cercana.\n",
    "\n",
    "### Almacenamiento Persistente con Vol√∫menes\n",
    "\n",
    "Para aplicaciones que necesitan guardar datos (como una base de datos), Fly.io ofrece **vol√∫menes de almacenamiento**. Estos son discos duros virtuales **NVMe** de alta velocidad que se adjuntan a tus Machines.\n",
    "\n",
    "Un punto clave es que un volumen est√° **atado a una regi√≥n espec√≠fica**. Si creas un volumen para tu base de datos en Santiago (Chile), esa base de datos principal vivir√° all√≠. Puedes crear r√©plicas de lectura en otras regiones para acelerar las consultas, pero la escritura principal se har√° en la regi√≥n del volumen.\n",
    "\n",
    "### Red Privada Segura (Private Networking)\n",
    "\n",
    "Esta es una de las caracter√≠sticas m√°s potentes. Cuando despliegas una \"App\", Fly.io crea autom√°ticamente una **red privada y segura** para todas las \"Machines\" que pertenecen a esa aplicaci√≥n, sin importar en qu√© parte del mundo se encuentren. \n",
    "\n",
    "Esto significa que tu `api-web` en Madrid puede hablar con tu `base-de-datos` en S√£o Paulo a trav√©s de esta red interna, usando direcciones IPv6 privadas, sin exponer nunca la base de datos a la internet p√∫blica. Es como si todas tus m√°quinas estuvieran conectadas por un cable secreto y seguro.\n",
    "\n",
    "### Fly Postgres: Bases de Datos Simplificadas\n",
    "\n",
    "Fly.io tiene un soporte de primera clase para **PostgreSQL**. Con unos pocos comandos `flyctl`, puedes:\n",
    "-   **Crear un cl√∫ster de Postgres** de alta disponibilidad en segundos.\n",
    "-   **Asociarlo** a tu aplicaci√≥n para que se conecten a trav√©s de la red privada.\n",
    "-   **Escalarlo** f√°cilmente, a√±adiendo r√©plicas de lectura en otras regiones para acelerar las consultas de tus usuarios globales.\n",
    "\n",
    "Esto elimina gran parte de la complejidad de administrar y escalar bases de datos, permiti√©ndote concentrarte en tu aplicaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909b1f-9de6-4921-bbdb-63af64a803d5",
   "metadata": {},
   "source": [
    "### Script de Deployment\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# scripts/deploy-fly.sh\n",
    "\n",
    "# Script de deployment para Fly.io\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"üöÄ Iniciando deployment a Fly.io\"\n",
    "\n",
    "# Variables\n",
    "FLY_APP_NAME=\"churn-prediction-api\"\n",
    "REGION=\"mad\"  # Madrid\n",
    "\n",
    "# Verificar que flyctl est√© instalado\n",
    "check_flyctl() {\n",
    "    if ! command -v flyctl &> /dev/null; then\n",
    "        echo \"‚ùå flyctl no est√° instalado\"\n",
    "        echo \"Instala flyctl desde: https://fly.io/docs/hands-on/install-flyctl/\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"‚úÖ flyctl instalado\"\n",
    "}\n",
    "\n",
    "# Verificar autenticaci√≥n\n",
    "check_auth() {\n",
    "    if ! flyctl auth whoami &> /dev/null; then\n",
    "        echo \"‚ö†Ô∏è No est√°s autenticado en Fly.io\"\n",
    "        echo \"Ejecutando 'flyctl auth login'...\"\n",
    "        flyctl auth login\n",
    "    fi\n",
    "    echo \"‚úÖ Autenticado en Fly.io\"\n",
    "}\n",
    "\n",
    "# Verificar que los modelos existen\n",
    "check_models() {\n",
    "    if [ ! -d \"models\" ] || [ -z \"$(ls -A models/*.joblib 2>/dev/null)\" ]; then\n",
    "        echo \"‚ùå No se encontraron modelos entrenados\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"‚úÖ Modelos encontrados\"\n",
    "}\n",
    "\n",
    "# Crear aplicaci√≥n si no existe\n",
    "create_or_update_app() {\n",
    "    if flyctl apps show $FLY_APP_NAME &> /dev/null; then\n",
    "        echo \"‚úÖ Aplicaci√≥n '$FLY_APP_NAME' ya existe\"\n",
    "    else\n",
    "        echo \"üì± Creando nueva aplicaci√≥n...\"\n",
    "        flyctl apps create $FLY_APP_NAME --region $REGION\n",
    "        echo \"‚úÖ Aplicaci√≥n creada\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Deploy de la aplicaci√≥n\n",
    "deploy_app() {\n",
    "    echo \"üöÄ Iniciando deployment...\"\n",
    "    flyctl deploy --remote-only --strategy immediate\n",
    "    echo \"‚úÖ Deployment completado\"\n",
    "}\n",
    "\n",
    "# Verificar que el deployment funcion√≥\n",
    "verify_deployment() {\n",
    "    local app_url=\"https://${FLY_APP_NAME}.fly.dev\"\n",
    "    \n",
    "    echo \"üîç Verificando deployment...\"\n",
    "    sleep 10\n",
    "    \n",
    "    if curl -f \"${app_url}/health\" > /dev/null 2>&1; then\n",
    "        echo \"‚úÖ ¬°Deployment exitoso!\"\n",
    "        echo \"üìñ Documentaci√≥n API: ${app_url}/docs\"\n",
    "        echo \"üîç Health check: ${app_url}/health\"\n",
    "        return 0\n",
    "    else\n",
    "        echo \"‚ùå Deployment fall√≥\"\n",
    "        flyctl logs --app $FLY_APP_NAME\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Funci√≥n principal\n",
    "main() {\n",
    "    echo \"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\"\n",
    "    echo \"   üöÄ DEPLOYMENT A FLY.IO\"\n",
    "    echo \"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\"\n",
    "    \n",
    "    check_flyctl\n",
    "    check_auth\n",
    "    check_models\n",
    "    create_or_update_app\n",
    "    deploy_app\n",
    "    \n",
    "    if verify_deployment; then\n",
    "        echo \"üéâ ¬°Deployment completado exitosamente!\"\n",
    "    else\n",
    "        echo \"üí• Deployment fall√≥. Revisa los logs.\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Ejecutar funci√≥n principal\n",
    "main \"$@\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e99e4-4c5d-471c-a5a7-a1a67ad45987",
   "metadata": {},
   "source": [
    "## 8. Testing\n",
    "\n",
    "Las **pruebas de software** son actividades dise√±adas para verificar que una aplicaci√≥n cumple con los requisitos esperados y funciona correctamente. Permiten detectar errores, validar comportamientos y garantizar calidad antes de poner el software en producci√≥n.\n",
    "\n",
    "### Conceptos clave\n",
    "- **Caso de prueba**: conjunto de condiciones y entradas que verifican un comportamiento espec√≠fico.\n",
    "- **Resultado esperado**: lo que deber√≠a ocurrir al ejecutar el caso de prueba.\n",
    "- **Resultado real**: lo que ocurre efectivamente durante la prueba.\n",
    "- **Bug o defecto**: discrepancia entre el resultado esperado y el real.\n",
    "\n",
    "\n",
    "### ¬øPor qu√© son importantes las Pruebas?\n",
    "\n",
    "Escribir pruebas puede parecer trabajo extra al principio, pero los beneficios son enormes. Son como la **red de seguridad para un trapecista**.\n",
    "\n",
    "  * **Confianza para el cambio (Refactoring):** Te permiten modificar y mejorar tu c√≥digo con la seguridad de que no romper√°s algo sin darte cuenta. Si tus pruebas siguen pasando, tus cambios son seguros.\n",
    "  * **Detecci√≥n temprana de errores:** Atrapas los bugs mucho antes en el ciclo de desarrollo, cuando son m√°s f√°ciles y baratos de arreglar.\n",
    "  * **Documentaci√≥n viva:** Las pruebas son el mejor ejemplo de c√≥mo se debe usar tu c√≥digo. Un nuevo desarrollador puede leer las pruebas para entender la funcionalidad.\n",
    "  * **Despliegues sin miedo:** Automatizar tus pruebas te da la confianza para lanzar nuevas versiones de tu software sabiendo que las funcionalidades clave han sido verificadas.\n",
    "\n",
    "\n",
    "### Tipos Comunes de Pruebas (La Pir√°mide de Pruebas)\n",
    "\n",
    "No todas las pruebas son iguales. Se suelen clasificar seg√∫n lo que abarcan:\n",
    "\n",
    "  * **Pruebas Unitarias (Unit Tests):** Son la base de la pir√°mide. Se enfocan en la pieza m√°s peque√±a de c√≥digo posible (una sola funci√≥n o m√©todo) de forma **aislada**. Si una funci√≥n suma dos n√∫meros, la prueba unitaria solo verifica eso, sin preocuparse por la base de datos o la interfaz de usuario. Son **muy r√°pidas** de ejecutar.\n",
    "\n",
    "  * **Pruebas de Integraci√≥n (Integration Tests):** Est√°n en el medio. Verifican que **varias partes de tu sistema funcionan bien juntas**. Por ejemplo, ¬øpuede tu c√≥digo escribir correctamente en la base de datos? ¬øSe comunica bien tu aplicaci√≥n con una API externa? Son m√°s lentas que las unitarias.\n",
    "\n",
    "  * **Pruebas End-to-End (E2E):** Est√°n en la cima. Simulan el **flujo completo de un usuario real** a trav√©s de toda la aplicaci√≥n. Por ejemplo, una prueba E2E podr√≠a automatizar un navegador para que inicie sesi√≥n, agregue un producto al carrito y complete la compra. Son las m√°s **lentas y complejas**, pero verifican que todo el sistema funciona como un todo.\n",
    "\n",
    "Dentro de este universo, se encuentran las **pruebas de API**, que abordaremos a continuaci√≥n.\n",
    "\n",
    "### Pruebas de API\n",
    "\n",
    "Imagina una API (Interfaz de Programaci√≥n de Aplicaciones) como el **mesero de un restaurante**. T√∫ (el cliente o *frontend*) le pides algo al mesero (la **API**), √©l lleva tu pedido a la cocina (el servidor o *backend*), y te trae de vuelta tu plato (los **datos**).\n",
    "\n",
    "Las **pruebas de API** consisten en enviar solicitudes a una API (generalmente REST o GraphQL) y verificar que las respuestas:\n",
    "- Tengan el **c√≥digo de estado HTTP** esperado.\n",
    "- Devuelvan la **estructura y datos correctos** (JSON, XML, etc.).\n",
    "- Cumplan con las **reglas de negocio**.\n",
    "\n",
    "Ejemplo: verificar que al consultar un usuario, la API retorne su nombre, email y estado correcto.\n",
    "\n",
    "La librer√≠a m√°s popular para esto en Python es **`requests`**. Te permite hacer solicitudes HTTP (GET, POST, PUT, DELETE) de forma muy simple.\n",
    "\n",
    "**Ejemplo simple con `requests`:**\n",
    "\n",
    "Este c√≥digo hace una petici√≥n a una API p√∫blica de prueba y verifica que la respuesta sea exitosa (c√≥digo 200) y que el `id` del usuario sea el que pedimos.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# 1. Definir la URL del endpoint de la API\n",
    "api_url = \"https://jsonplaceholder.typicode.com/users/1\"\n",
    "\n",
    "# 2. Hacer la solicitud GET a la API\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# 3. Verificar los resultados\n",
    "# Verificar que la solicitud fue exitosa (c√≥digo 200 OK)\n",
    "assert response.status_code == 200\n",
    "\n",
    "# Convertir la respuesta a formato JSON (un diccionario de Python)\n",
    "user_data = response.json()\n",
    "\n",
    "# Verificar que los datos recibidos son correctos\n",
    "assert user_data['id'] == 1\n",
    "assert user_data['name'] == \"Leanne Graham\"\n",
    "\n",
    "print(\"‚úÖ ¬°El test de la API pas√≥ correctamente!\")\n",
    "\n",
    "```\n",
    "\n",
    "### ¬øPor qu√© automatizar pruebas de API?\n",
    "\n",
    "- **Rapidez**: ejecutar pruebas autom√°ticamente despu√©s de cada cambio.\n",
    "- **Confiabilidad**: evita errores humanos en pruebas manuales.\n",
    "- **Repetibilidad**: se pueden ejecutar en CI/CD.\n",
    "- **Cobertura**: validan m√∫ltiples casos (errores, respuestas v√°lidas, l√≠mites, etc.).\n",
    "\n",
    "### Buenas pr√°cticas en pruebas de API\n",
    "\n",
    "- Usar **fixtures de pytest** para inicializar configuraciones.\n",
    "- Separar pruebas por **m√≥dulos** (ej: `test_users.py`, `test_posts.py`).\n",
    "- Incluir **tests positivos y negativos**.\n",
    "- Integrar con CI/CD (GitHub Actions, GitLab CI, etc.).\n",
    "\n",
    "### Tests Automatizados con Pytest\n",
    "\n",
    "**Pytest** es un *framework* que hace que escribir, organizar y ejecutar tests en Python sea incre√≠blemente f√°cil y potente. Su objetivo es que puedas enfocarte en qu√© probar, no en c√≥mo hacerlo.\n",
    "\n",
    "Piensa en Pytest como el **gerente del restaurante**. En lugar de que t√∫ vayas a la cocina a verificar cada plato, le das al gerente una lista de \"verificaciones\" y √©l se encarga de ejecutarlas todas, cada vez que hay un cambio en el men√∫, y te entrega un informe detallado de lo que est√° bien y lo que est√° mal.\n",
    "\n",
    "### ¬øPor qu√© usar Pytest?\n",
    "\n",
    "  * **Sintaxis Sencilla:** Usa `assert` directamente, lo que hace el c√≥digo muy legible. No necesitas aprender comandos complejos.\n",
    "  * **Detecci√≥n Autom√°tica:** Simplemente nombra tus archivos como `test_*.py` y tus funciones de prueba como `test_*()`, y Pytest los encontrar√° y ejecutar√° autom√°ticamente.\n",
    "  * **Fixtures:** Son funciones de ayuda que preparan el \"escenario\" para tus tests (ej: conectarse a una base de datos, crear un usuario de prueba) y lo limpian despu√©s. Son reutilizables y muy potentes.\n",
    "  * **Informes Detallados:** Si un test falla, Pytest te dice exactamente en qu√© l√≠nea y por qu√©, comparando los valores esperados con los obtenidos.\n",
    "  * **Gran Ecosistema:** Tiene cientos de *plugins* para extender su funcionalidad (ej: reportes de cobertura, ejecuci√≥n en paralelo, etc.).\n",
    "\n",
    "### Estructura b√°sica de un test\n",
    "\n",
    "Un test en `pytest` es simplemente una funci√≥n cuyo nombre empieza con `test_`:\n",
    "\n",
    "```python\n",
    "def test_suma():\n",
    "    assert 1 + 1 == 2\n",
    "```\n",
    "\n",
    "### Juntando todo: Testing de API con Pytest\n",
    "\n",
    "Ahora, combinemos los dos conceptos. Usamos la librer√≠a `requests` para comunicarnos con la API y `pytest` para estructurar y automatizar las pruebas. Vamos a probar la API gratuita de [JSONPlaceholder](https://jsonplaceholder.typicode.com/) que simula datos falsos.\n",
    "\n",
    "Primero, instala las librer√≠as si no las tienes:\n",
    "\n",
    "```bash\n",
    "uv add pytest requests\n",
    "```\n",
    "\n",
    "Luego, crea un archivo llamado `test_api.py`:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# La URL base de la API que vamos a probar\n",
    "BASE_URL = \"https://jsonplaceholder.typicode.com\"\n",
    "\n",
    "def test_get_user_by_id():\n",
    "    \"\"\"\n",
    "    Prueba que se puede obtener un usuario por su ID y que sus datos son correctos.\n",
    "    \"\"\"\n",
    "    # Hacer la petici√≥n a un endpoint espec√≠fico\n",
    "    response = requests.get(f\"{BASE_URL}/users/1\")\n",
    "    \n",
    "    # Verificar el c√≥digo de estado\n",
    "    assert response.status_code == 200, \"El c√≥digo de estado deber√≠a ser 200 OK\"\n",
    "    \n",
    "    # Verificar el contenido de la respuesta\n",
    "    user_data = response.json()\n",
    "    assert user_data['id'] == 1\n",
    "    assert user_data['email'] == \"Sincere@april.biz\"\n",
    "\n",
    "def test_get_all_posts():\n",
    "    \"\"\"\n",
    "    Prueba que se puede obtener una lista de posts y que no est√° vac√≠a.\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"{BASE_URL}/posts\")\n",
    "    \n",
    "    assert response.status_code == 200\n",
    "    \n",
    "    posts = response.json()\n",
    "    # Verificar que la respuesta es una lista y contiene 100 posts\n",
    "    assert isinstance(posts, list)\n",
    "    assert len(posts) == 100\n",
    "\n",
    "```\n",
    "\n",
    "Para ejecutar estas pruebas, simplemente abre tu terminal en la carpeta donde guardaste el archivo y ejecuta el comando:\n",
    "\n",
    "```bash\n",
    "pytest\n",
    "```\n",
    "\n",
    "Pytest encontrar√° y ejecutar√° autom√°ticamente las funciones `test_get_user_by_id` y `test_get_all_posts`, y te mostrar√° un resumen claro de los resultados.\n",
    "\n",
    "\n",
    "### Manejo de escenarios negativos\n",
    "\n",
    "Tambi√©n es importante probar **casos de error**:\n",
    "\n",
    "```python\n",
    "def test_user_not_found():\n",
    "    response = requests.get(f\"{BASE_URL}/users/9999\")\n",
    "    assert response.status_code == 404\n",
    "```\n",
    "\n",
    "### La Anatom√≠a de un Buen Test\n",
    "\n",
    "Una excelente pr√°ctica para que tus pruebas sean claras y legibles es seguir el patr√≥n **AAA**:\n",
    "\n",
    "1.  **Arrange (Preparar):** Configura todo lo necesario para la prueba. Define las variables, crea objetos, prepara el fixture.\n",
    "2.  **Act (Actuar):** Ejecuta la √∫nica pieza de c√≥digo que quieres probar. Llama a tu funci√≥n o m√©todo.\n",
    "3.  **Assert (Verificar):** Comprueba que el resultado de la acci√≥n es el esperado.\n",
    "\n",
    "\n",
    "```python\n",
    "def test_convertir_a_mayusculas():\n",
    "    # 1. Arrange (Preparar)\n",
    "    texto_original = \"hola mundo\"\n",
    "    \n",
    "    # 2. Act (Actuar)\n",
    "    texto_convertido = texto_original.upper()\n",
    "    \n",
    "    # 3. Assert (Verificar)\n",
    "    assert texto_convertido == \"HOLA MUNDO\"\n",
    "```\n",
    "\n",
    "Este patr√≥n hace que sea muy f√°cil entender qu√© est√° probando cada test.\n",
    "\n",
    "\n",
    "### Profundizando en Pytest\n",
    "\n",
    "Ya vimos lo b√°sico, pero aqu√≠ es donde Pytest realmente brilla.\n",
    "\n",
    "**Fixtures:**\n",
    "\n",
    "Los **fixtures** son el concepto m√°s poderoso de Pytest. Son funciones que preparan el \"escenario\" para tus pruebas (setup) y lo limpian despu√©s (teardown). Son reutilizables y se inyectan en tus pruebas simplemente pas√°ndolos como argumentos.\n",
    "\n",
    "**Ejemplo:** Un fixture para crear un archivo temporal antes de una prueba y asegurarse de que se borre despu√©s, aunque la prueba falle.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "import os\n",
    "\n",
    "# Define el fixture\n",
    "@pytest.fixture\n",
    "def archivo_temporal():\n",
    "    # --- ARRANGE (Setup) ---\n",
    "    print(\"\\nCreando archivo temporal...\")\n",
    "    ruta_archivo = \"test_file.txt\"\n",
    "    with open(ruta_archivo, \"w\") as f:\n",
    "        f.write(\"hola mundo\")\n",
    "    \n",
    "    yield ruta_archivo  # Aqu√≠ se ejecuta la prueba que usa el fixture\n",
    "    \n",
    "    # --- TEARDOWN (Cleanup) ---\n",
    "    print(\"\\nBorrando archivo temporal...\")\n",
    "    os.remove(ruta_archivo)\n",
    "\n",
    "# Usa el fixture en una prueba\n",
    "def test_leer_archivo(archivo_temporal):\n",
    "    with open(archivo_temporal, \"r\") as f:\n",
    "        contenido = f.read()\n",
    "    assert contenido == \"hola mundo\"\n",
    "\n",
    "```\n",
    "\n",
    "**Parametrize**\n",
    "\n",
    "A menudo quieres probar la misma funci√≥n con diferentes entradas y salidas. En lugar de escribir un test para cada caso, puedes usar `@pytest.mark.parametrize`.\n",
    "\n",
    "```python\n",
    "# test_calculadora.py\n",
    "import pytest\n",
    "\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "\n",
    "@pytest.mark.parametrize(\"a, b, esperado\", [\n",
    "    (1, 2, 3),        # Caso 1: positivos\n",
    "    (-1, 1, 0),       # Caso 2: con negativos\n",
    "    (5, 0, 5),        # Caso 3: con cero\n",
    "    (-2, -3, -5)      # Caso 4: negativos\n",
    "])\n",
    "def test_suma_multiple(a, b, esperado):\n",
    "    resultado = sumar(a, b)\n",
    "    assert resultado == esperado\n",
    "```\n",
    "\n",
    "Pytest ejecutar√° `test_suma_multiple` **cuatro veces**, una por cada grupo de datos, d√°ndote un informe detallado de cada caso.\n",
    "\n",
    "**Markers**\n",
    "\n",
    "Los marcadores te permiten categorizar tus pruebas. Puedes crear marcadores personalizados (ej: `@pytest.mark.slow`, `@pytest.mark.api`) y luego decirle a Pytest que ejecute solo las pruebas con una etiqueta espec√≠fica.\n",
    "\n",
    "```python\n",
    "@pytest.mark.slow\n",
    "def test_proceso_largo():\n",
    "    # ... un test que tarda mucho en ejecutarse\n",
    "\n",
    "@pytest.mark.api\n",
    "def test_conexion_api_externa():\n",
    "    # ... un test que depende de una API\n",
    "```\n",
    "\n",
    "Para ejecutar solo los tests de API, usar√≠as: `pytest -m api`\n",
    "\n",
    "\n",
    "**Mocks**\n",
    "\n",
    "Para no depender de una API externa en cada prueba, podemos usar `unittest.mock` para simular respuestas.\n",
    "\n",
    "```python\n",
    "from unittest.mock import patch, Mock\n",
    "\n",
    "@patch(\"requests.get\")\n",
    "def test_mocked_api(mock_get):\n",
    "    mock_response = Mock()\n",
    "    mock_response.status_code = 200\n",
    "    mock_response.json.return_value = {\"id\": 1, \"name\": \"Test User\"}\n",
    "    mock_get.return_value = mock_response\n",
    "\n",
    "    response = requests.get(\"https://fakeapi.com/users/1\")\n",
    "    assert response.status_code == 200\n",
    "    data = response.json()\n",
    "    assert data[\"name\"] == \"Test User\"\n",
    "```\n",
    "\n",
    "**Pruebas as√≠ncronas con `pytest-asyncio`**\n",
    "\n",
    "Si la API o cliente HTTP es as√≠ncrono (ej: `httpx`, `aiohttp`), usamos `pytest-asyncio`:\n",
    "\n",
    "Instalaci√≥n:\n",
    "```bash\n",
    "uv add pytest-asyncio httpx\n",
    "```\n",
    "\n",
    "Ejemplo:\n",
    "```python\n",
    "import pytest\n",
    "import httpx\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_async_api():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
    "        assert response.status_code == 200\n",
    "        data = response.json()\n",
    "        assert \"title\" in data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257f8db-0b4a-479b-8c67-b16b44454ccf",
   "metadata": {},
   "source": [
    "### Tests de la App de FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562f81b-e5b3-4655-b63f-f42e9cba5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_api.py\n",
    "import pytest\n",
    "import httpx\n",
    "from fastapi.testclient import TestClient\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configurar path para imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n",
    "\n",
    "from main import app\n",
    "\n",
    "# Cliente de testing\n",
    "client = TestClient(app)\n",
    "\n",
    "class TestHealthEndpoints:\n",
    "    \"\"\"Tests para endpoints de salud y monitoreo.\"\"\"\n",
    "    \n",
    "    def test_root_endpoint(self):\n",
    "        \"\"\"Test del endpoint ra√≠z.\"\"\"\n",
    "        response = client.get(\"/\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"message\"] == \"üéØ Churn Prediction API\"\n",
    "        assert data[\"version\"] == \"1.0.0\"\n",
    "        assert \"status\" in data\n",
    "    \n",
    "    def test_health_check(self):\n",
    "        \"\"\"Test del health check b√°sico.\"\"\"\n",
    "        response = client.get(\"/health\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"status\"] == \"healthy\"\n",
    "        assert \"models_available\" in data\n",
    "\n",
    "class TestPredictionEndpoints:\n",
    "    \"\"\"Tests para endpoints de predicci√≥n.\"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def valid_customer_data(self):\n",
    "        \"\"\"Datos v√°lidos de cliente para testing.\"\"\"\n",
    "        return {\n",
    "            \"gender\": \"Female\",\n",
    "            \"senior_citizen\": 0,\n",
    "            \"partner\": \"Yes\",\n",
    "            \"dependents\": \"No\",\n",
    "            \"tenure\": 24,\n",
    "            \"phone_service\": \"Yes\",\n",
    "            \"internet_service\": \"Fiber optic\",\n",
    "            \"online_security\": \"No\",\n",
    "            \"tech_support\": \"Yes\",\n",
    "            \"contract\": \"Month-to-month\",\n",
    "            \"payment_method\": \"Electronic check\",\n",
    "            \"monthly_charges\": 85.50,\n",
    "            \"total_charges\": 2052.00,\n",
    "            \"customer_id\": \"TEST001\"\n",
    "        }\n",
    "    \n",
    "    def test_predict_valid_customer(self, valid_customer_data):\n",
    "        \"\"\"Test de predicci√≥n con datos v√°lidos.\"\"\"\n",
    "        response = client.post(\"/predict\", json=valid_customer_data)\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Verificar estructura de la respuesta\n",
    "        required_fields = [\n",
    "            \"prediction\", \"churn_probability\", \"retention_probability\",\n",
    "            \"risk_category\", \"confidence\", \"model_info\", \n",
    "            \"processing_time_ms\", \"timestamp\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            assert field in data, f\"Campo {field} faltante en respuesta\"\n",
    "        \n",
    "        # Verificar tipos y rangos\n",
    "        assert isinstance(data[\"prediction\"], int)\n",
    "        assert data[\"prediction\"] in [0, 1]\n",
    "        \n",
    "        assert 0 <= data[\"churn_probability\"] <= 1\n",
    "        assert 0 <= data[\"retention_probability\"] <= 1\n",
    "        \n",
    "        assert data[\"risk_category\"] in [\"Low\", \"Medium\", \"High\"]\n",
    "        assert data[\"processing_time_ms\"] > 0\n",
    "    \n",
    "    def test_predict_invalid_data(self):\n",
    "        \"\"\"Test con datos inv√°lidos.\"\"\"\n",
    "        invalid_data = {\n",
    "            \"gender\": \"Other\",  # No permitido\n",
    "            \"senior_citizen\": 2,  # Fuera de rango\n",
    "            \"tenure\": -5,  # Negativo\n",
    "            \"monthly_charges\": 0  # Debe ser > 0\n",
    "        }\n",
    "        \n",
    "        response = client.post(\"/predict\", json=invalid_data)\n",
    "        assert response.status_code == 422  # Unprocessable Entity\n",
    "\n",
    "# Script para ejecutar tests\n",
    "if __name__ == \"__main__\":\n",
    "    pytest.main([__file__])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2297c-47af-4aaa-8ad2-9bbae491128b",
   "metadata": {},
   "source": [
    "## 9. Mejores Pr√°cticas y Tips (...)\n",
    "\n",
    "### Checklist de Producci√≥n\n",
    "\n",
    "```\n",
    "# üìã CHECKLIST DE PRODUCCI√ìN PARA API DE ML\n",
    "\n",
    "## ‚úÖ C√≥digo y Arquitectura\n",
    "- [ ] C√≥digo limpio y bien documentado\n",
    "- [ ] Separaci√≥n clara entre entrenamiento e inferencia\n",
    "- [ ] Pipelines de scikit-learn para consistencia\n",
    "- [ ] Validaci√≥n robusta con Pydantic\n",
    "- [ ] Manejo de errores comprehensivo\n",
    "- [ ] Logging estructurado configurado\n",
    "- [ ] Tests unitarios e integraci√≥n (>80% cobertura)\n",
    "\n",
    "## ‚úÖ Modelo y Datos\n",
    "- [ ] Modelo validado en datos de prueba\n",
    "- [ ] M√©tricas de rendimiento documentadas\n",
    "- [ ] Versionado de modelos implementado\n",
    "- [ ] Backup de modelos configurado\n",
    "\n",
    "## ‚úÖ API y Rendimiento\n",
    "- [ ] Documentaci√≥n API completa (Swagger)\n",
    "- [ ] Health checks funcionando\n",
    "- [ ] CORS configurado apropiadamente\n",
    "- [ ] Timeouts configurados\n",
    "\n",
    "## ‚úÖ Seguridad\n",
    "- [ ] Variables sensibles en variables de entorno\n",
    "- [ ] Usuario no-root en contenedor Docker\n",
    "- [ ] HTTPS habilitado\n",
    "- [ ] Validaci√≥n de entrada estricta\n",
    "\n",
    "## ‚úÖ Infraestructura\n",
    "- [ ] Dockerfile optimizado (multi-stage)\n",
    "- [ ] Imagen Docker peque√±a y eficiente\n",
    "- [ ] Monitoreo y alertas configurados\n",
    "- [ ] Backup y recuperaci√≥n probados\n",
    "```\n",
    "\n",
    "### Optimizaciones de Rendimiento\n",
    "\n",
    "```python\n",
    "# T√©cnicas de optimizaci√≥n para APIs de ML\n",
    "\n",
    "# 1. Cache de modelos\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_model_cached(model_path: str):\n",
    "    \"\"\"Cargar modelo con cache para evitar recargas.\"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# 2. Procesamiento por lotes\n",
    "@app.post(\"/predict/batch\")\n",
    "async def batch_predict(requests: List[PredictionRequest]):\n",
    "    \"\"\"Procesar m√∫ltiples predicciones eficientemente.\"\"\"\n",
    "    # Preparar datos para predicci√≥n vectorizada\n",
    "    batch_data = [req.features.dict() for req in requests]\n",
    "    \n",
    "    # Predicci√≥n vectorizada (m√°s eficiente)\n",
    "    predictions = model.predict(batch_data)\n",
    "    probabilities = model.predict_proba(batch_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 3. Async/Await para I/O\n",
    "async def log_prediction_async(prediction_data: dict):\n",
    "    \"\"\"Logging as√≠ncrono para no bloquear requests.\"\"\"\n",
    "    async with aiofiles.open(\"predictions.log\", \"a\") as f:\n",
    "        await f.write(f\"{json.dumps(prediction_data)}\\n\")\n",
    "\n",
    "# 4. Configuraci√≥n de Uvicorn para producci√≥n\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        workers=4,  # N√∫mero de workers basado en CPU\n",
    "        loop=\"uvloop\",  # Loop m√°s r√°pido\n",
    "        http=\"httptools\",  # Parser HTTP m√°s r√°pido\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ae230-1d51-4d19-b2f3-c99fd001e4da",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "### Resumen de lo Implementado\n",
    "\n",
    "üéì **Has aprendido a implementar un sistema completo de ML en producci√≥n:**\n",
    "\n",
    "1. **Gesti√≥n moderna de proyectos** con UV y pyproject.toml\n",
    "2. **Machine Learning pipelines** con scikit-learn\n",
    "3. **API robusta** con FastAPI y validaci√≥n Pydantic\n",
    "4. **Contenedorizaci√≥n** optimizada con Docker\n",
    "5. **Deployment** en la nube con Fly.io\n",
    "6. **Testing automatizado** con pytest\n",
    "7. **Monitoreo** y observabilidad\n",
    "\n",
    "### Valor Agregado vs. Enfoques Tradicionales\n",
    "\n",
    "| Aspecto | Tradicional (Flask + pip) | Moderno (FastAPI + uv) |\n",
    "|---------|---------------------------|------------------------|\n",
    "| **Velocidad API** | ~1000 req/s | ~3000+ req/s |\n",
    "| **Documentaci√≥n** | Manual | Autom√°tica |\n",
    "| **Validaci√≥n** | Manual | Autom√°tica |\n",
    "| **Install deps** | pip install (30s) | uv sync (3s) |\n",
    "| **Typing** | Opcional | Nativo |\n",
    "| **Async** | Complejo | Nativo |\n",
    "\n",
    "### Pr√≥ximos Pasos Recomendados\n",
    "\n",
    "üõ£Ô∏è **Extensiones avanzadas:**\n",
    "\n",
    "1. **MLOps**: Integrar MLflow para model registry\n",
    "2. **Monitoreo**: A√±adir Prometheus + Grafana\n",
    "3. **Seguridad**: Implementar autenticaci√≥n JWT\n",
    "4. **Escalabilidad**: A√±adir Redis cache y load balancing\n",
    "5. **CI/CD**: GitHub Actions para deployment autom√°tico\n",
    "\n",
    "### Comandos Finales\n",
    "\n",
    "```bash\n",
    "# Configuraci√≥n inicial\n",
    "uv sync                                 # Instalar dependencias\n",
    "python scripts/setup.py               # Configurar proyecto\n",
    "\n",
    "# Desarrollo local\n",
    "uv run uvicorn src.main:app --reload  # Servidor desarrollo\n",
    "\n",
    "# Testing\n",
    "pytest tests/ --cov=src               # Tests con cobertura\n",
    "\n",
    "# Deployment\n",
    "./scripts/deploy-fly.sh              # Deploy a producci√≥n\n",
    "```\n",
    "\n",
    "### Estructura Final del Proyecto\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Aplicaci√≥n FastAPI\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Modelos Pydantic\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ml/                # L√≥gica ML\n",
    "‚îú‚îÄ‚îÄ models/                # Modelos entrenados (.joblib)\n",
    "‚îú‚îÄ‚îÄ tests/                 # Tests automatizados\n",
    "‚îú‚îÄ‚îÄ scripts/               # Scripts de utilidad\n",
    "‚îú‚îÄ‚îÄ Dockerfile             # Contenedorizaci√≥n\n",
    "‚îú‚îÄ‚îÄ fly.toml              # Config Fly.io\n",
    "‚îî‚îÄ‚îÄ pyproject.toml        # Dependencias UV\n",
    "```\n",
    "\n",
    "üéâ **¬°Felicitaciones! Has implementado una API de ML moderna, escalable y lista para producci√≥n usando las mejores pr√°cticas y herramientas de 2025.**\n",
    "\n",
    "Tu API ahora puede:\n",
    "- ‚úÖ Servir predicciones de ML a miles de usuarios\n",
    "- ‚úÖ Validar datos autom√°ticamente\n",
    "- ‚úÖ Documentarse a s√≠ misma\n",
    "- ‚úÖ Desplegarse globalmente en segundos\n",
    "- ‚úÖ Monitorearse y alertar autom√°ticamente\n",
    "- ‚úÖ Escalarse seg√∫n demanda\n",
    "\n",
    "**¬°Es hora de llevarlo a producci√≥n y ver tu modelo en acci√≥n!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de9431-3b8a-47a3-bab6-29f5000c1a0b",
   "metadata": {},
   "source": [
    "> **Nota**  \n",
    "> Esta notebook se inspir√≥ en el workshop [**mlzoomcamp-fastapi-uv**](https://github.com/alexeygrigorev/workshops/tree/main/mlzoomcamp-fastapi-uv), ofrecido por *Alexey Grigorev*, fundador de **DataTalks.Club**. \n",
    "> Agradecimientos a la comunidad por compartir estos recursos abiertos.\n",
    "> Adem√°s, me tom√© la molestia de guardar los archivos del workshop en la carpeta **`workshop_fastapi_ml`** para que tengas acceso r√°pido al material de referencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
