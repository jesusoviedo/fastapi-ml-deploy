{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe0e3c-fb18-4f8a-a8a8-7d3fd367cc3a",
   "metadata": {},
   "source": [
    "# Implementación de Modelos de ML con FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215d90e-da16-4b5a-9792-c5c1afcde39f",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Este notebook educativo completo te guía paso a paso en la implementación de modelos de Machine Learning usando las herramientas más modernas de 2025: **FastAPI**, **uv**, **Docker**, y **Fly.io**. Aprenderás a crear un servicio web robusto para servir modelos de ML en producción.\n",
    "\n",
    "### ¿Qué aprenderás?\n",
    "\n",
    "- Configuración moderna de proyectos con **uv** (la alternativa rápida a pip/pipenv)\n",
    "- Entrenamiento y guardado de modelos con **scikit-learn pipelines**\n",
    "- Creación de APIs robustas con **FastAPI**\n",
    "- Validación de datos con **Pydantic**\n",
    "- Contenedorización con **Docker**\n",
    "- Despliegue en la nube con **Fly.io**\n",
    "\n",
    "### Caso de Uso: Predicción de Churn de Clientes\n",
    "\n",
    "Implementaremos un modelo para predecir si un cliente cancelará su servicio (churn), un problema común en telecomunicaciones y servicios de suscripción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8cc97-9d65-45e9-a1a9-251c65114bfa",
   "metadata": {},
   "source": [
    "## 1. Configuración del Entorno con UV\n",
    "\n",
    "### ¿Qué es UV?\n",
    "\n",
    "**uv** es una herramienta moderna de gestión de paquetes Python escrita en Rust, que es significativamente más rápida que pip y pipenv. Es la evolución natural para proyectos Python modernos.\n",
    "\n",
    "### Instalación y Configuración\n",
    "\n",
    "```bash\n",
    "# En tu terminal, instala uv (solo una vez)\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Crear nuevo proyecto\n",
    "uv init mi-proyecto-ml\n",
    "cd mi-proyecto-ml\n",
    "```\n",
    "\n",
    "### Estructura del Proyecto Recomendada\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "├── .env                          # Variables de entorno\n",
    "├── .gitignore\n",
    "├── .python-version              # Versión Python para UV\n",
    "├── pyproject.toml               # Configuración del proyecto\n",
    "├── uv.lock                      # Archivo de bloqueo de UV\n",
    "├── README.md\n",
    "├── Dockerfile                   # Para contenedorización\n",
    "├── \n",
    "├── src/\n",
    "│   ├── __init__.py\n",
    "│   ├── main.py                  # Punto de entrada FastAPI\n",
    "│   ├── config.py                # Configuración global\n",
    "│   ├── \n",
    "│   ├── api/                     # Endpoints de la API\n",
    "│   │   ├── __init__.py\n",
    "│   │   └── routes.py\n",
    "│   ├── \n",
    "│   ├── ml/                      # Módulo de Machine Learning\n",
    "│   │   ├── __init__.py\n",
    "│   │   ├── models.py\n",
    "│   │   ├── training.py\n",
    "│   │   └── inference.py\n",
    "│   ├── \n",
    "│   └── schemas/                # Modelos Pydantic\n",
    "│       ├── __init__.py\n",
    "│       └── predictions.py\n",
    "├── \n",
    "├── models/                     # Modelos entrenados\n",
    "├── tests/                      # Tests\n",
    "└── scripts/                    # Scripts de utilidad\n",
    "```\n",
    "\n",
    "### Configuración de Dependencias (pyproject.toml)\n",
    "\n",
    "```toml\n",
    "[project]\n",
    "name = \"churn-prediction-api\"\n",
    "version = \"0.1.0\"\n",
    "description = \"API FastAPI para predicción de churn de clientes\"\n",
    "readme = \"README.md\"\n",
    "authors = [\n",
    "    {name = \"Tu Nombre\", email = \"tu@email.com\"}\n",
    "]\n",
    "requires-python = \">=3.11\"\n",
    "\n",
    "# Dependencias principales\n",
    "dependencies = [\n",
    "    \"fastapi[standard]>=0.115.0\",\n",
    "    \"uvicorn[standard]>=0.30.0\",\n",
    "    \"pydantic>=2.8.0\",\n",
    "    \"pydantic-settings>=2.4.0\",\n",
    "    \"scikit-learn>=1.5.0\",\n",
    "    \"pandas>=2.2.0\",\n",
    "    \"numpy>=1.26.0\",\n",
    "    \"joblib>=1.4.0\",\n",
    "]\n",
    "\n",
    "# Dependencias de desarrollo\n",
    "[dependency-groups]\n",
    "dev = [\n",
    "    \"pytest>=8.0.0\",\n",
    "    \"pytest-asyncio>=0.23.0\",\n",
    "    \"httpx>=0.27.0\",\n",
    "    \"ruff>=0.5.0\",\n",
    "    \"mypy>=1.10.0\",\n",
    "]\n",
    "\n",
    "# Scripts útiles\n",
    "[project.scripts]\n",
    "start-api = \"src.main:main\"\n",
    "train-model = \"src.ml.training:train\"\n",
    "\n",
    "[build-system]\n",
    "requires = [\"hatchling\"]\n",
    "build-backend = \"hatchling.build\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca28df-73a6-4b9d-9052-02fe3c079616",
   "metadata": {},
   "source": [
    "## 2. Generación de Datos Sintéticos para Churn\n",
    "\n",
    "### Crear Dataset de Ejemplo\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def create_churn_dataset(n_samples=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Crear un dataset sintético realista para predicción de churn.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con características de clientes y etiquetas de churn\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Crear datos base\n",
    "    data = {\n",
    "        'customer_id': range(1, n_samples + 1),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'senior_citizen': np.random.choice([0, 1], n_samples, p=[0.84, 0.16]),\n",
    "        'partner': np.random.choice(['Yes', 'No'], n_samples, p=[0.48, 0.52]),\n",
    "        'dependents': np.random.choice(['Yes', 'No'], n_samples, p=[0.30, 0.70]),\n",
    "        'tenure': np.random.randint(1, 73, n_samples),  # Meses\n",
    "        'phone_service': np.random.choice(['Yes', 'No'], n_samples, p=[0.90, 0.10]),\n",
    "        'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], \n",
    "                                           n_samples, p=[0.34, 0.44, 0.22]),\n",
    "        'online_security': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                          n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                       n_samples, p=[0.29, 0.50, 0.21]),\n",
    "        'contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], \n",
    "                                   n_samples, p=[0.55, 0.21, 0.24]),\n",
    "        'payment_method': np.random.choice([\n",
    "            'Electronic check', 'Mailed check', 'Bank transfer (automatic)', \n",
    "            'Credit card (automatic)'\n",
    "        ], n_samples, p=[0.34, 0.23, 0.22, 0.21]),\n",
    "        'monthly_charges': np.round(np.random.normal(64.76, 30.0, n_samples), 2),\n",
    "        'total_charges': np.round(np.random.normal(2283.30, 2266.77, n_samples), 2)\n",
    "    }\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Limpiar valores negativos en charges\n",
    "    df['monthly_charges'] = df['monthly_charges'].clip(lower=18.25)\n",
    "    df['total_charges'] = df['total_charges'].clip(lower=18.80)\n",
    "    \n",
    "    # Crear etiquetas de churn con lógica realista\n",
    "    churn_probability = 0.2  # Baseline\n",
    "    \n",
    "    # Factores que aumentan churn\n",
    "    tenure_factor = np.where(df['tenure'] < 12, 0.15, 0)  # Clientes nuevos\n",
    "    contract_factor = np.where(df['contract'] == 'Month-to-month', 0.20, 0)  # Sin compromiso\n",
    "    payment_factor = np.where(df['payment_method'] == 'Electronic check', 0.10, 0)  # Método de pago\n",
    "    charges_factor = np.where(df['monthly_charges'] > 80, 0.08, 0)  # Cargos altos\n",
    "    \n",
    "    # Factores que reducen churn\n",
    "    partner_factor = np.where(df['partner'] == 'Yes', -0.08, 0)  # Con pareja\n",
    "    dependents_factor = np.where(df['dependents'] == 'Yes', -0.05, 0)  # Con dependientes\n",
    "    long_tenure_factor = np.where(df['tenure'] > 48, -0.12, 0)  # Clientes antiguos\n",
    "    \n",
    "    # Calcular probabilidad final\n",
    "    final_probability = (churn_probability + tenure_factor + contract_factor + \n",
    "                        payment_factor + charges_factor + partner_factor + \n",
    "                        dependents_factor + long_tenure_factor)\n",
    "    \n",
    "    # Generar etiquetas de churn\n",
    "    df['churn'] = np.random.binomial(1, final_probability.clip(0.05, 0.85))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear el dataset\n",
    "print(\"🔄 Generando dataset sintético de churn...\")\n",
    "churn_data = create_churn_dataset(n_samples=10000)\n",
    "\n",
    "print(f\"📊 Dataset creado:\")\n",
    "print(f\"   • Muestras: {len(churn_data)}\")\n",
    "print(f\"   • Características: {churn_data.shape[1]-2}\")  # -2 para customer_id y churn\n",
    "print(f\"   • Tasa de churn: {churn_data['churn'].mean():.1%}\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "churn_data.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212f30-8fd3-46bc-b753-30031c19dc63",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del Modelo con Pipelines de Scikit-learn\n",
    "\n",
    "### ¿Por qué usar Pipelines?\n",
    "\n",
    "Los **pipelines** de scikit-learn combinan múltiples pasos de preprocesamiento y modelado en un solo objeto, lo que:\n",
    "- Simplifica el código\n",
    "- Evita errores de data leakage\n",
    "- Facilita la serialización\n",
    "- Permite usar el modelo con datos en formato crudo\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Preparar características para el modelo.\n",
    "    Convertir DataFrame a lista de diccionarios (formato requerido por DictVectorizer)\n",
    "    \"\"\"\n",
    "    # Seleccionar características relevantes\n",
    "    feature_columns = [\n",
    "        'gender', 'senior_citizen', 'partner', 'dependents', 'tenure',\n",
    "        'phone_service', 'internet_service', 'online_security', 'tech_support',\n",
    "        'contract', 'payment_method', 'monthly_charges', 'total_charges'\n",
    "    ]\n",
    "    \n",
    "    # Convertir a lista de diccionarios\n",
    "    X = df[feature_columns].to_dict('records')\n",
    "    y = df['churn']\n",
    "    \n",
    "    return X, y, feature_columns\n",
    "\n",
    "def train_churn_model(df, model_type='logistic_regression'):\n",
    "    \"\"\"\n",
    "    Entrenar modelo de predicción de churn usando pipelines.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos\n",
    "        model_type: Tipo de modelo ('logistic_regression' o 'random_forest')\n",
    "    \n",
    "    Returns:\n",
    "        pipeline: Modelo entrenado\n",
    "        metrics: Métricas de evaluación\n",
    "    \"\"\"\n",
    "    print(f\"🚀 Iniciando entrenamiento de modelo: {model_type}\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X, y, feature_columns = prepare_features(df)\n",
    "    \n",
    "    # Split train/validation/test (60/20/20)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Split de datos:\")\n",
    "    print(f\"   • Entrenamiento: {len(X_train)} muestras\")\n",
    "    print(f\"   • Validación: {len(X_val)} muestras\")\n",
    "    print(f\"   • Prueba: {len(X_test)} muestras\")\n",
    "    \n",
    "    # Crear pipeline según el tipo de modelo\n",
    "    if model_type == 'logistic_regression':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            LogisticRegression(\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced'  # Manejar desbalance\n",
    "            )\n",
    "        )\n",
    "    elif model_type == 'random_forest':\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(sparse=False),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                max_depth=10\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_type debe ser 'logistic_regression' o 'random_forest'\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"🔄 Entrenando modelo...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluación en conjunto de validación\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Evaluación en conjunto de prueba\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    y_test_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_type': model_type,\n",
    "        'validation_auc': val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_count': len(feature_columns),\n",
    "        'training_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✅ Entrenamiento completado!\")\n",
    "    print(f\"📈 AUC Validación: {val_auc:.4f}\")\n",
    "    print(f\"📈 AUC Prueba: {test_auc:.4f}\")\n",
    "    \n",
    "    # Reporte detallado\n",
    "    print(f\"\\n📋 Reporte de Clasificación (Conjunto de Prueba):\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['No Churn', 'Churn']))\n",
    "    \n",
    "    return pipeline, metrics, (X_test, y_test)\n",
    "\n",
    "# Entrenar modelos\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modelo 1: Regresión Logística\n",
    "lr_model, lr_metrics, (X_test, y_test) = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='logistic_regression'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Modelo 2: Random Forest\n",
    "rf_model, rf_metrics, _ = train_churn_model(\n",
    "    churn_data, \n",
    "    model_type='random_forest'\n",
    ")\n",
    "```\n",
    "\n",
    "### Guardar Modelos Entrenados\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "def save_model_with_metadata(pipeline, metrics, model_name, models_dir=\"./models\"):\n",
    "    \"\"\"\n",
    "    Guardar modelo y sus metadatos de forma organizada.\n",
    "    \"\"\"\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Nombres de archivos\n",
    "    model_filename = f\"{model_name}_{datetime.now().strftime('%Y%m%d')}.joblib\"\n",
    "    metadata_filename = f\"{model_name}_metadata.json\"\n",
    "    \n",
    "    model_path = os.path.join(models_dir, model_filename)\n",
    "    metadata_path = os.path.join(models_dir, metadata_filename)\n",
    "    \n",
    "    # Guardar modelo usando joblib (más eficiente que pickle para sklearn)\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    \n",
    "    # Guardar metadatos\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"💾 Modelo guardado: {model_path}\")\n",
    "    print(f\"📄 Metadatos guardados: {metadata_path}\")\n",
    "    \n",
    "    return model_path, metadata_path\n",
    "\n",
    "# Guardar ambos modelos\n",
    "lr_model_path, lr_metadata_path = save_model_with_metadata(\n",
    "    lr_model, lr_metrics, \"churn_logistic_regression\"\n",
    ")\n",
    "\n",
    "rf_model_path, rf_metadata_path = save_model_with_metadata(\n",
    "    rf_model, rf_metrics, \"churn_random_forest\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Modelos guardados exitosamente!\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c169cc-0164-45b1-9908-bca03eda7c69",
   "metadata": {},
   "source": [
    "## 4. Creación de API con FastAPI\n",
    "\n",
    "### ¿Por qué FastAPI?\n",
    "\n",
    "**FastAPI** es el framework web moderno para Python que ofrece:\n",
    "- **Velocidad**: Hasta 3x más rápido que Flask\n",
    "- **Documentación automática**: Genera Swagger UI automáticamente\n",
    "- **Validación**: Integración nativa con Pydantic\n",
    "- **Async**: Soporte completo para programación asíncrona\n",
    "- **Tipado**: Type hints nativos de Python\n",
    "\n",
    "### Aplicación FastAPI Principal\n",
    "\n",
    "```python\n",
    "# src/main.py\n",
    "from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from contextlib import asynccontextmanager\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from schemas.predictions import CustomerInput, PredictionResponse, BatchPredictionRequest\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Almacenamiento global para modelos\n",
    "ml_models: Dict[str, Any] = {}\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Gestión del ciclo de vida de la aplicación\"\"\"\n",
    "    logger.info(\"🚀 Iniciando carga de modelos...\")\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelos disponibles\n",
    "        models_dir = \"models\"\n",
    "        if os.path.exists(models_dir):\n",
    "            for filename in os.listdir(models_dir):\n",
    "                if filename.endswith('.joblib'):\n",
    "                    model_name = filename.replace('.joblib', '')\n",
    "                    model_path = os.path.join(models_dir, filename)\n",
    "                    \n",
    "                    model = joblib.load(model_path)\n",
    "                    ml_models[model_name] = model\n",
    "                    logger.info(f\"✅ Modelo cargado: {model_name}\")\n",
    "        \n",
    "        if not ml_models:\n",
    "            logger.warning(\"⚠️ No se encontraron modelos en el directorio\")\n",
    "        \n",
    "        logger.info(f\"📊 Total modelos cargados: {len(ml_models)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error cargando modelos: {e}\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    # Limpieza al cerrar\n",
    "    ml_models.clear()\n",
    "    logger.info(\"🔄 Recursos liberados\")\n",
    "\n",
    "# Crear aplicación FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Churn Prediction API\",\n",
    "    description=\"\"\"\n",
    "    🎯 **API para Predicción de Churn de Clientes**\n",
    "    \n",
    "    Esta API utiliza modelos de Machine Learning para predecir la probabilidad\n",
    "    de que un cliente cancele su servicio (churn).\n",
    "    \n",
    "    ## Características\n",
    "    \n",
    "    * **Predicciones individuales**: Predice churn para un cliente\n",
    "    * **Predicciones por lotes**: Procesa múltiples clientes\n",
    "    * **Múltiples modelos**: Soporte para diferentes algoritmos\n",
    "    * **Validación automática**: Verificación de datos de entrada\n",
    "    * **Documentación interactiva**: Swagger UI integrado\n",
    "    \n",
    "    ## Modelos Disponibles\n",
    "    \n",
    "    * **Regresión Logística**: Modelo interpretable y rápido\n",
    "    * **Random Forest**: Modelo ensemble con alta precisión\n",
    "    \"\"\",\n",
    "    version=\"1.0.0\",\n",
    "    contact={\n",
    "        \"name\": \"Equipo ML\",\n",
    "        \"email\": \"ml@tuempresa.com\",\n",
    "    },\n",
    "    license_info={\n",
    "        \"name\": \"Apache 2.0\",\n",
    "        \"url\": \"https://www.apache.org/licenses/LICENSE-2.0.html\",\n",
    "    },\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Configurar CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # En producción, especifica dominios específicos\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Dependencia para obtener modelo\n",
    "async def get_model(model_name: str = \"churn_logistic_regression_20241201\"):\n",
    "    if model_name not in ml_models:\n",
    "        available_models = list(ml_models.keys())\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Modelo '{model_name}' no encontrado. Modelos disponibles: {available_models}\"\n",
    "        )\n",
    "    return ml_models[model_name]\n",
    "\n",
    "# === ENDPOINTS ===\n",
    "\n",
    "@app.get(\"/\", tags=[\"info\"])\n",
    "async def root():\n",
    "    \"\"\"Información básica de la API\"\"\"\n",
    "    return {\n",
    "        \"message\": \"🎯 Churn Prediction API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"active\",\n",
    "        \"models_loaded\": len(ml_models),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\", tags=[\"monitoring\"])\n",
    "async def health_check():\n",
    "    \"\"\"Health check para monitoreo\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"models_count\": len(ml_models),\n",
    "        \"models_available\": list(ml_models.keys()),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/models\", tags=[\"models\"])\n",
    "async def list_models():\n",
    "    \"\"\"Listar modelos disponibles\"\"\"\n",
    "    model_info = {}\n",
    "    \n",
    "    for name, model in ml_models.items():\n",
    "        model_info[name] = {\n",
    "            \"type\": type(model).__name__,\n",
    "            \"steps\": [step[0] for step in model.steps] if hasattr(model, 'steps') else \"Pipeline\",\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"available_models\": model_info,\n",
    "        \"total_count\": len(ml_models)\n",
    "    }\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"predictions\"])\n",
    "async def predict_churn(\n",
    "    customer: CustomerInput,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    model_name: str = \"churn_logistic_regression_20241201\",\n",
    "    model = Depends(get_model)\n",
    "):\n",
    "    \"\"\"\n",
    "    🎯 Predecir probabilidad de churn para un cliente\n",
    "    \n",
    "    Utiliza el modelo especificado para calcular la probabilidad de que\n",
    "    el cliente cancele su servicio.\n",
    "    \n",
    "    - **customer**: Datos del cliente (ver esquema completo abajo)\n",
    "    - **model_name**: Nombre del modelo a utilizar\n",
    "    \n",
    "    Retorna predicción, probabilidades y metadatos del modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Convertir datos de entrada a formato de diccionario\n",
    "        customer_dict = customer.model_dump()\n",
    "        \n",
    "        # Hacer predicción\n",
    "        prediction = model.predict([customer_dict])[0]\n",
    "        probabilities = model.predict_proba([customer_dict])[0]\n",
    "        \n",
    "        # Calcular métricas\n",
    "        churn_probability = float(probabilities[1])\n",
    "        retention_probability = float(probabilities[0])\n",
    "        confidence = max(probabilities)\n",
    "        \n",
    "        # Determinar categoría de riesgo\n",
    "        if churn_probability >= 0.7:\n",
    "            risk_category = \"High\"\n",
    "        elif churn_probability >= 0.4:\n",
    "            risk_category = \"Medium\"  \n",
    "        else:\n",
    "            risk_category = \"Low\"\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        response = PredictionResponse(\n",
    "            prediction=int(prediction),\n",
    "            churn_probability=churn_probability,\n",
    "            retention_probability=retention_probability,\n",
    "            risk_category=risk_category,\n",
    "            confidence=float(confidence),\n",
    "            model_info={\n",
    "                \"name\": model_name,\n",
    "                \"type\": type(model).__name__,\n",
    "                \"version\": \"1.0.0\"\n",
    "            },\n",
    "            processing_time_ms=int(processing_time),\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        # Log en background (no bloquea la respuesta)\n",
    "        background_tasks.add_task(\n",
    "            log_prediction,\n",
    "            customer_dict,\n",
    "            response.model_dump(),\n",
    "            model_name\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en predicción: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Error procesando predicción: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Función de logging asíncrono\n",
    "async def log_prediction(customer_data: dict, prediction_result: dict, model_name: str):\n",
    "    \"\"\"Registrar predicción para monitoreo y análisis\"\"\"\n",
    "    logger.info(\n",
    "        f\"PREDICTION - Model: {model_name}, \"\n",
    "        f\"Churn_Prob: {prediction_result['churn_probability']:.3f}, \"\n",
    "        f\"Risk: {prediction_result['risk_category']}, \"\n",
    "        f\"Tenure: {customer_data.get('tenure', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True,\n",
    "        log_level=\"info\"\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa31081-9e77-4116-8167-0bc8856b21ed",
   "metadata": {},
   "source": [
    "## 5. Modelos de Validación con Pydantic\n",
    "\n",
    "### Esquemas de Entrada y Salida\n",
    "\n",
    "```python\n",
    "# src/schemas/predictions.py\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "class RiskCategory(str, Enum):\n",
    "    \"\"\"Categorías de riesgo de churn\"\"\"\n",
    "    LOW = \"Low\"\n",
    "    MEDIUM = \"Medium\" \n",
    "    HIGH = \"High\"\n",
    "\n",
    "class ContractType(str, Enum):\n",
    "    \"\"\"Tipos de contrato disponibles\"\"\"\n",
    "    MONTH_TO_MONTH = \"Month-to-month\"\n",
    "    ONE_YEAR = \"One year\"\n",
    "    TWO_YEAR = \"Two year\"\n",
    "\n",
    "class PaymentMethod(str, Enum):\n",
    "    \"\"\"Métodos de pago disponibles\"\"\"\n",
    "    ELECTRONIC_CHECK = \"Electronic check\"\n",
    "    MAILED_CHECK = \"Mailed check\"\n",
    "    BANK_TRANSFER = \"Bank transfer (automatic)\"\n",
    "    CREDIT_CARD = \"Credit card (automatic)\"\n",
    "\n",
    "class InternetService(str, Enum):\n",
    "    \"\"\"Tipos de servicio de internet\"\"\"\n",
    "    DSL = \"DSL\"\n",
    "    FIBER_OPTIC = \"Fiber optic\"\n",
    "    NO = \"No\"\n",
    "\n",
    "class CustomerInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo de entrada para datos del cliente.\n",
    "    \n",
    "    Todos los campos son validados automáticamente por Pydantic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Información demográfica\n",
    "    gender: str = Field(\n",
    "        ..., \n",
    "        description=\"Género del cliente\",\n",
    "        example=\"Male\"\n",
    "    )\n",
    "    \n",
    "    senior_citizen: int = Field(\n",
    "        ..., \n",
    "        ge=0, \n",
    "        le=1,\n",
    "        description=\"Es ciudadano senior (0=No, 1=Sí)\",\n",
    "        example=0\n",
    "    )\n",
    "    \n",
    "    partner: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene pareja\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    dependents: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene dependientes\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    # Información del servicio\n",
    "    tenure: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Meses como cliente\",\n",
    "        example=24\n",
    "    )\n",
    "    \n",
    "    phone_service: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene servicio telefónico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    internet_service: InternetService = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de servicio de internet\",\n",
    "        example=\"Fiber optic\"\n",
    "    )\n",
    "    \n",
    "    online_security: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene seguridad online\",\n",
    "        example=\"No\"\n",
    "    )\n",
    "    \n",
    "    tech_support: str = Field(\n",
    "        ...,\n",
    "        description=\"Tiene soporte técnico\",\n",
    "        example=\"Yes\"\n",
    "    )\n",
    "    \n",
    "    # Información contractual y financiera\n",
    "    contract: ContractType = Field(\n",
    "        ...,\n",
    "        description=\"Tipo de contrato\",\n",
    "        example=\"Month-to-month\"\n",
    "    )\n",
    "    \n",
    "    payment_method: PaymentMethod = Field(\n",
    "        ...,\n",
    "        description=\"Método de pago\",\n",
    "        example=\"Electronic check\"\n",
    "    )\n",
    "    \n",
    "    monthly_charges: float = Field(\n",
    "        ...,\n",
    "        gt=0,\n",
    "        lt=200,\n",
    "        description=\"Cargos mensuales en USD\",\n",
    "        example=85.50\n",
    "    )\n",
    "    \n",
    "    total_charges: float = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Total de cargos acumulados en USD\",\n",
    "        example=2052.00\n",
    "    )\n",
    "    \n",
    "    # Campo opcional para ID del cliente\n",
    "    customer_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"ID opcional del cliente\",\n",
    "        example=\"CUST001\"\n",
    "    )\n",
    "    \n",
    "    @validator('gender')\n",
    "    def validate_gender(cls, v):\n",
    "        allowed_genders = ['Male', 'Female']\n",
    "        if v not in allowed_genders:\n",
    "            raise ValueError(f'Gender debe ser uno de: {allowed_genders}')\n",
    "        return v\n",
    "    \n",
    "    @validator('partner', 'dependents', 'phone_service')\n",
    "    def validate_yes_no_fields(cls, v, field):\n",
    "        allowed_values = ['Yes', 'No']\n",
    "        if v not in allowed_values:\n",
    "            raise ValueError(f'{field.name} debe ser \"Yes\" o \"No\"')\n",
    "        return v\n",
    "\n",
    "    class Config:\n",
    "        # Configuración del modelo Pydantic\n",
    "        str_strip_whitespace = True  # Eliminar espacios en blanco\n",
    "        validate_assignment = True   # Validar en asignaciones\n",
    "        use_enum_values = True      # Usar valores de enum\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"gender\": \"Female\",\n",
    "                \"senior_citizen\": 0,\n",
    "                \"partner\": \"Yes\",\n",
    "                \"dependents\": \"No\", \n",
    "                \"tenure\": 24,\n",
    "                \"phone_service\": \"Yes\",\n",
    "                \"internet_service\": \"Fiber optic\",\n",
    "                \"online_security\": \"No\",\n",
    "                \"tech_support\": \"Yes\",\n",
    "                \"contract\": \"Month-to-month\",\n",
    "                \"payment_method\": \"Electronic check\",\n",
    "                \"monthly_charges\": 85.50,\n",
    "                \"total_charges\": 2052.00,\n",
    "                \"customer_id\": \"CUST001\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Respuesta de la predicción de churn\"\"\"\n",
    "    \n",
    "    prediction: int = Field(\n",
    "        ...,\n",
    "        description=\"Predicción de churn (0=No Churn, 1=Churn)\",\n",
    "        example=1\n",
    "    )\n",
    "    \n",
    "    churn_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de churn\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    retention_probability: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Probabilidad de retención\",\n",
    "        example=0.25\n",
    "    )\n",
    "    \n",
    "    risk_category: RiskCategory = Field(\n",
    "        ...,\n",
    "        description=\"Categoría de riesgo\",\n",
    "        example=\"High\"\n",
    "    )\n",
    "    \n",
    "    confidence: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Confianza del modelo\",\n",
    "        example=0.75\n",
    "    )\n",
    "    \n",
    "    model_info: Dict[str, Any] = Field(\n",
    "        ...,\n",
    "        description=\"Información del modelo utilizado\",\n",
    "        example={\n",
    "            \"name\": \"churn_logistic_regression\",\n",
    "            \"type\": \"Pipeline\",\n",
    "            \"version\": \"1.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time_ms: int = Field(\n",
    "        ...,\n",
    "        ge=0,\n",
    "        description=\"Tiempo de procesamiento en milisegundos\",\n",
    "        example=150\n",
    "    )\n",
    "    \n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Timestamp de la predicción\",\n",
    "        example=\"2024-12-01T10:30:00\"\n",
    "    )\n",
    "\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    \"\"\"Solicitud de predicción por lotes\"\"\"\n",
    "    \n",
    "    customers: List[CustomerInput] = Field(\n",
    "        ...,\n",
    "        min_items=1,\n",
    "        max_items=1000,  # Límite para evitar sobrecarga\n",
    "        description=\"Lista de clientes para predecir\"\n",
    "    )\n",
    "    \n",
    "    include_details: bool = Field(\n",
    "        True,\n",
    "        description=\"Incluir detalles completos en la respuesta\"\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cd044-6415-44bd-9968-f6b75acee71d",
   "metadata": {},
   "source": [
    "## 6. Contenedorización con Docker\n",
    "\n",
    "### Dockerfile Optimizado\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile multi-stage optimizado para FastAPI + ML con uv\n",
    "\n",
    "# Etapa 1: Builder - Instalar dependencias\n",
    "FROM python:3.12-slim as builder\n",
    "\n",
    "# Instalar uv (gestor de paquetes rápido)\n",
    "COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n",
    "\n",
    "# Variables de entorno para optimización\n",
    "ENV UV_COMPILE_BYTECODE=1\n",
    "ENV UV_LINK_MODE=copy\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar archivos de dependencias\n",
    "COPY pyproject.toml ./\n",
    "\n",
    "# Crear entorno virtual e instalar dependencias\n",
    "RUN uv venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "RUN uv pip install -r pyproject.toml\n",
    "\n",
    "# Etapa 2: Runtime - Aplicación final\n",
    "FROM python:3.12-slim as runtime\n",
    "\n",
    "# Instalar dependencias del sistema necesarias para ML\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libgomp1 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Variables de entorno\n",
    "ENV PYTHONPATH=/app\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Crear usuario no-root para seguridad\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# Directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar entorno virtual desde builder\n",
    "COPY --from=builder /opt/venv /opt/venv\n",
    "\n",
    "# Copiar código de la aplicación\n",
    "COPY src/ /app/src/\n",
    "COPY models/ /app/models/\n",
    "\n",
    "# Crear directorio para logs\n",
    "RUN mkdir -p /app/logs && chown -R appuser:appuser /app\n",
    "\n",
    "# Cambiar a usuario no-root\n",
    "USER appuser\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n",
    "    CMD python -c \"import requests; requests.get('http://localhost:8000/health')\"\n",
    "\n",
    "# Puerto de la aplicación\n",
    "EXPOSE 8000\n",
    "\n",
    "# Comando por defecto - usar FastAPI CLI\n",
    "CMD [\"fastapi\", \"run\", \"src/main.py\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### Docker Compose para Desarrollo\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # Servicio principal de la API\n",
    "  churn-api:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    container_name: churn-prediction-api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - ENVIRONMENT=development\n",
    "      - LOG_LEVEL=INFO\n",
    "      - MODELS_PATH=/app/models\n",
    "    volumes:\n",
    "      # Volumen para desarrollo - hot reload\n",
    "      - ./src:/app/src:ro\n",
    "      - ./models:/app/models:ro\n",
    "      - ./logs:/app/logs\n",
    "    restart: unless-stopped\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 30s\n",
    "    networks:\n",
    "      - ml-network\n",
    "\n",
    "  # Redis para caché (opcional)\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: churn-api-cache\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    networks:\n",
    "      - ml-network\n",
    "    restart: unless-stopped\n",
    "    command: redis-server --appendonly yes\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "\n",
    "networks:\n",
    "  ml-network:\n",
    "    driver: bridge\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909b1f-9de6-4921-bbdb-63af64a803d5",
   "metadata": {},
   "source": [
    "## 7. Despliegue en la Nube con Fly.io\n",
    "\n",
    "### Configuración de Fly.io\n",
    "\n",
    "```toml\n",
    "# fly.toml\n",
    "app = \"churn-prediction-api\"\n",
    "primary_region = \"mad\"  # Madrid - cambiar según tu preferencia\n",
    "\n",
    "# Build configuration\n",
    "[build]\n",
    "\n",
    "# Environment variables\n",
    "[env]\n",
    "  PORT = \"8000\"\n",
    "  ENVIRONMENT = \"production\"\n",
    "  LOG_LEVEL = \"INFO\"\n",
    "\n",
    "# HTTP service configuration\n",
    "[http_service]\n",
    "  internal_port = 8000\n",
    "  force_https = true\n",
    "  auto_stop_machines = true\n",
    "  auto_start_machines = true\n",
    "  min_machines_running = 0\n",
    "  processes = [\"app\"]\n",
    "\n",
    "  # Health checks\n",
    "  [[http_service.checks]]\n",
    "    grace_period = \"10s\"\n",
    "    interval = \"30s\"\n",
    "    method = \"GET\"\n",
    "    timeout = \"5s\"\n",
    "    path = \"/health\"\n",
    "    protocol = \"http\"\n",
    "\n",
    "# Machine configuration\n",
    "[[vm]]\n",
    "  memory = \"2gb\"      # Suficiente para modelos ML\n",
    "  cpu_kind = \"shared\"\n",
    "  cpus = 1\n",
    "  processes = [\"app\"]\n",
    "\n",
    "# Configuración de procesos\n",
    "[processes]\n",
    "  app = \"fastapi run src/main.py --host 0.0.0.0 --port 8000\"\n",
    "```\n",
    "\n",
    "### Script de Deployment\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# scripts/deploy-fly.sh\n",
    "\n",
    "# Script de deployment para Fly.io\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"🚀 Iniciando deployment a Fly.io\"\n",
    "\n",
    "# Variables\n",
    "FLY_APP_NAME=\"churn-prediction-api\"\n",
    "REGION=\"mad\"  # Madrid\n",
    "\n",
    "# Verificar que flyctl esté instalado\n",
    "check_flyctl() {\n",
    "    if ! command -v flyctl &> /dev/null; then\n",
    "        echo \"❌ flyctl no está instalado\"\n",
    "        echo \"Instala flyctl desde: https://fly.io/docs/hands-on/install-flyctl/\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"✅ flyctl instalado\"\n",
    "}\n",
    "\n",
    "# Verificar autenticación\n",
    "check_auth() {\n",
    "    if ! flyctl auth whoami &> /dev/null; then\n",
    "        echo \"⚠️ No estás autenticado en Fly.io\"\n",
    "        echo \"Ejecutando 'flyctl auth login'...\"\n",
    "        flyctl auth login\n",
    "    fi\n",
    "    echo \"✅ Autenticado en Fly.io\"\n",
    "}\n",
    "\n",
    "# Verificar que los modelos existen\n",
    "check_models() {\n",
    "    if [ ! -d \"models\" ] || [ -z \"$(ls -A models/*.joblib 2>/dev/null)\" ]; then\n",
    "        echo \"❌ No se encontraron modelos entrenados\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"✅ Modelos encontrados\"\n",
    "}\n",
    "\n",
    "# Crear aplicación si no existe\n",
    "create_or_update_app() {\n",
    "    if flyctl apps show $FLY_APP_NAME &> /dev/null; then\n",
    "        echo \"✅ Aplicación '$FLY_APP_NAME' ya existe\"\n",
    "    else\n",
    "        echo \"📱 Creando nueva aplicación...\"\n",
    "        flyctl apps create $FLY_APP_NAME --region $REGION\n",
    "        echo \"✅ Aplicación creada\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Deploy de la aplicación\n",
    "deploy_app() {\n",
    "    echo \"🚀 Iniciando deployment...\"\n",
    "    flyctl deploy --remote-only --strategy immediate\n",
    "    echo \"✅ Deployment completado\"\n",
    "}\n",
    "\n",
    "# Verificar que el deployment funcionó\n",
    "verify_deployment() {\n",
    "    local app_url=\"https://${FLY_APP_NAME}.fly.dev\"\n",
    "    \n",
    "    echo \"🔍 Verificando deployment...\"\n",
    "    sleep 10\n",
    "    \n",
    "    if curl -f \"${app_url}/health\" > /dev/null 2>&1; then\n",
    "        echo \"✅ ¡Deployment exitoso!\"\n",
    "        echo \"📖 Documentación API: ${app_url}/docs\"\n",
    "        echo \"🔍 Health check: ${app_url}/health\"\n",
    "        return 0\n",
    "    else\n",
    "        echo \"❌ Deployment falló\"\n",
    "        flyctl logs --app $FLY_APP_NAME\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Función principal\n",
    "main() {\n",
    "    echo \"════════════════════════════════════════\"\n",
    "    echo \"   🚀 DEPLOYMENT A FLY.IO\"\n",
    "    echo \"════════════════════════════════════════\"\n",
    "    \n",
    "    check_flyctl\n",
    "    check_auth\n",
    "    check_models\n",
    "    create_or_update_app\n",
    "    deploy_app\n",
    "    \n",
    "    if verify_deployment; then\n",
    "        echo \"🎉 ¡Deployment completado exitosamente!\"\n",
    "    else\n",
    "        echo \"💥 Deployment falló. Revisa los logs.\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Ejecutar función principal\n",
    "main \"$@\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e99e4-4c5d-471c-a5a7-a1a67ad45987",
   "metadata": {},
   "source": [
    "## 8. Testing de la API\n",
    "\n",
    "### Tests Automatizados con Pytest\n",
    "\n",
    "```python\n",
    "# tests/test_api.py\n",
    "import pytest\n",
    "import httpx\n",
    "from fastapi.testclient import TestClient\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configurar path para imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n",
    "\n",
    "from main import app\n",
    "\n",
    "# Cliente de testing\n",
    "client = TestClient(app)\n",
    "\n",
    "class TestHealthEndpoints:\n",
    "    \"\"\"Tests para endpoints de salud y monitoreo.\"\"\"\n",
    "    \n",
    "    def test_root_endpoint(self):\n",
    "        \"\"\"Test del endpoint raíz.\"\"\"\n",
    "        response = client.get(\"/\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"message\"] == \"🎯 Churn Prediction API\"\n",
    "        assert data[\"version\"] == \"1.0.0\"\n",
    "        assert \"status\" in data\n",
    "    \n",
    "    def test_health_check(self):\n",
    "        \"\"\"Test del health check básico.\"\"\"\n",
    "        response = client.get(\"/health\")\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        assert data[\"status\"] == \"healthy\"\n",
    "        assert \"models_available\" in data\n",
    "\n",
    "class TestPredictionEndpoints:\n",
    "    \"\"\"Tests para endpoints de predicción.\"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def valid_customer_data(self):\n",
    "        \"\"\"Datos válidos de cliente para testing.\"\"\"\n",
    "        return {\n",
    "            \"gender\": \"Female\",\n",
    "            \"senior_citizen\": 0,\n",
    "            \"partner\": \"Yes\",\n",
    "            \"dependents\": \"No\",\n",
    "            \"tenure\": 24,\n",
    "            \"phone_service\": \"Yes\",\n",
    "            \"internet_service\": \"Fiber optic\",\n",
    "            \"online_security\": \"No\",\n",
    "            \"tech_support\": \"Yes\",\n",
    "            \"contract\": \"Month-to-month\",\n",
    "            \"payment_method\": \"Electronic check\",\n",
    "            \"monthly_charges\": 85.50,\n",
    "            \"total_charges\": 2052.00,\n",
    "            \"customer_id\": \"TEST001\"\n",
    "        }\n",
    "    \n",
    "    def test_predict_valid_customer(self, valid_customer_data):\n",
    "        \"\"\"Test de predicción con datos válidos.\"\"\"\n",
    "        response = client.post(\"/predict\", json=valid_customer_data)\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Verificar estructura de la respuesta\n",
    "        required_fields = [\n",
    "            \"prediction\", \"churn_probability\", \"retention_probability\",\n",
    "            \"risk_category\", \"confidence\", \"model_info\", \n",
    "            \"processing_time_ms\", \"timestamp\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            assert field in data, f\"Campo {field} faltante en respuesta\"\n",
    "        \n",
    "        # Verificar tipos y rangos\n",
    "        assert isinstance(data[\"prediction\"], int)\n",
    "        assert data[\"prediction\"] in [0, 1]\n",
    "        \n",
    "        assert 0 <= data[\"churn_probability\"] <= 1\n",
    "        assert 0 <= data[\"retention_probability\"] <= 1\n",
    "        \n",
    "        assert data[\"risk_category\"] in [\"Low\", \"Medium\", \"High\"]\n",
    "        assert data[\"processing_time_ms\"] > 0\n",
    "    \n",
    "    def test_predict_invalid_data(self):\n",
    "        \"\"\"Test con datos inválidos.\"\"\"\n",
    "        invalid_data = {\n",
    "            \"gender\": \"Other\",  # No permitido\n",
    "            \"senior_citizen\": 2,  # Fuera de rango\n",
    "            \"tenure\": -5,  # Negativo\n",
    "            \"monthly_charges\": 0  # Debe ser > 0\n",
    "        }\n",
    "        \n",
    "        response = client.post(\"/predict\", json=invalid_data)\n",
    "        assert response.status_code == 422  # Unprocessable Entity\n",
    "\n",
    "# Script para ejecutar tests\n",
    "if __name__ == \"__main__\":\n",
    "    pytest.main([__file__])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2297c-47af-4aaa-8ad2-9bbae491128b",
   "metadata": {},
   "source": [
    "## 9. Mejores Prácticas y Tips\n",
    "\n",
    "### Checklist de Producción\n",
    "\n",
    "```\n",
    "# 📋 CHECKLIST DE PRODUCCIÓN PARA API DE ML\n",
    "\n",
    "## ✅ Código y Arquitectura\n",
    "- [ ] Código limpio y bien documentado\n",
    "- [ ] Separación clara entre entrenamiento e inferencia\n",
    "- [ ] Pipelines de scikit-learn para consistencia\n",
    "- [ ] Validación robusta con Pydantic\n",
    "- [ ] Manejo de errores comprehensivo\n",
    "- [ ] Logging estructurado configurado\n",
    "- [ ] Tests unitarios e integración (>80% cobertura)\n",
    "\n",
    "## ✅ Modelo y Datos\n",
    "- [ ] Modelo validado en datos de prueba\n",
    "- [ ] Métricas de rendimiento documentadas\n",
    "- [ ] Versionado de modelos implementado\n",
    "- [ ] Backup de modelos configurado\n",
    "\n",
    "## ✅ API y Rendimiento\n",
    "- [ ] Documentación API completa (Swagger)\n",
    "- [ ] Health checks funcionando\n",
    "- [ ] CORS configurado apropiadamente\n",
    "- [ ] Timeouts configurados\n",
    "\n",
    "## ✅ Seguridad\n",
    "- [ ] Variables sensibles en variables de entorno\n",
    "- [ ] Usuario no-root en contenedor Docker\n",
    "- [ ] HTTPS habilitado\n",
    "- [ ] Validación de entrada estricta\n",
    "\n",
    "## ✅ Infraestructura\n",
    "- [ ] Dockerfile optimizado (multi-stage)\n",
    "- [ ] Imagen Docker pequeña y eficiente\n",
    "- [ ] Monitoreo y alertas configurados\n",
    "- [ ] Backup y recuperación probados\n",
    "```\n",
    "\n",
    "### Optimizaciones de Rendimiento\n",
    "\n",
    "```python\n",
    "# Técnicas de optimización para APIs de ML\n",
    "\n",
    "# 1. Cache de modelos\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_model_cached(model_path: str):\n",
    "    \"\"\"Cargar modelo con cache para evitar recargas.\"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# 2. Procesamiento por lotes\n",
    "@app.post(\"/predict/batch\")\n",
    "async def batch_predict(requests: List[PredictionRequest]):\n",
    "    \"\"\"Procesar múltiples predicciones eficientemente.\"\"\"\n",
    "    # Preparar datos para predicción vectorizada\n",
    "    batch_data = [req.features.dict() for req in requests]\n",
    "    \n",
    "    # Predicción vectorizada (más eficiente)\n",
    "    predictions = model.predict(batch_data)\n",
    "    probabilities = model.predict_proba(batch_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 3. Async/Await para I/O\n",
    "async def log_prediction_async(prediction_data: dict):\n",
    "    \"\"\"Logging asíncrono para no bloquear requests.\"\"\"\n",
    "    async with aiofiles.open(\"predictions.log\", \"a\") as f:\n",
    "        await f.write(f\"{json.dumps(prediction_data)}\\n\")\n",
    "\n",
    "# 4. Configuración de Uvicorn para producción\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        workers=4,  # Número de workers basado en CPU\n",
    "        loop=\"uvloop\",  # Loop más rápido\n",
    "        http=\"httptools\",  # Parser HTTP más rápido\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ae230-1d51-4d19-b2f3-c99fd001e4da",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y Próximos Pasos\n",
    "\n",
    "### Resumen de lo Implementado\n",
    "\n",
    "🎓 **Has aprendido a implementar un sistema completo de ML en producción:**\n",
    "\n",
    "1. **Gestión moderna de proyectos** con UV y pyproject.toml\n",
    "2. **Machine Learning pipelines** con scikit-learn\n",
    "3. **API robusta** con FastAPI y validación Pydantic\n",
    "4. **Contenedorización** optimizada con Docker\n",
    "5. **Deployment** en la nube con Fly.io\n",
    "6. **Testing automatizado** con pytest\n",
    "7. **Monitoreo** y observabilidad\n",
    "\n",
    "### Valor Agregado vs. Enfoques Tradicionales\n",
    "\n",
    "| Aspecto | Tradicional (Flask + pip) | Moderno (FastAPI + uv) |\n",
    "|---------|---------------------------|------------------------|\n",
    "| **Velocidad API** | ~1000 req/s | ~3000+ req/s |\n",
    "| **Documentación** | Manual | Automática |\n",
    "| **Validación** | Manual | Automática |\n",
    "| **Install deps** | pip install (30s) | uv sync (3s) |\n",
    "| **Typing** | Opcional | Nativo |\n",
    "| **Async** | Complejo | Nativo |\n",
    "\n",
    "### Próximos Pasos Recomendados\n",
    "\n",
    "🛣️ **Extensiones avanzadas:**\n",
    "\n",
    "1. **MLOps**: Integrar MLflow para model registry\n",
    "2. **Monitoreo**: Añadir Prometheus + Grafana\n",
    "3. **Seguridad**: Implementar autenticación JWT\n",
    "4. **Escalabilidad**: Añadir Redis cache y load balancing\n",
    "5. **CI/CD**: GitHub Actions para deployment automático\n",
    "\n",
    "### Comandos Finales\n",
    "\n",
    "```bash\n",
    "# Configuración inicial\n",
    "uv sync                                 # Instalar dependencias\n",
    "python scripts/setup.py               # Configurar proyecto\n",
    "\n",
    "# Desarrollo local\n",
    "uv run uvicorn src.main:app --reload  # Servidor desarrollo\n",
    "\n",
    "# Testing\n",
    "pytest tests/ --cov=src               # Tests con cobertura\n",
    "\n",
    "# Deployment\n",
    "./scripts/deploy-fly.sh              # Deploy a producción\n",
    "```\n",
    "\n",
    "### Estructura Final del Proyecto\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "├── src/                    # Código fuente\n",
    "│   ├── main.py            # Aplicación FastAPI\n",
    "│   ├── schemas/           # Modelos Pydantic\n",
    "│   └── ml/                # Lógica ML\n",
    "├── models/                # Modelos entrenados (.joblib)\n",
    "├── tests/                 # Tests automatizados\n",
    "├── scripts/               # Scripts de utilidad\n",
    "├── Dockerfile             # Contenedorización\n",
    "├── fly.toml              # Config Fly.io\n",
    "└── pyproject.toml        # Dependencias UV\n",
    "```\n",
    "\n",
    "🎉 **¡Felicitaciones! Has implementado una API de ML moderna, escalable y lista para producción usando las mejores prácticas y herramientas de 2025.**\n",
    "\n",
    "Tu API ahora puede:\n",
    "- ✅ Servir predicciones de ML a miles de usuarios\n",
    "- ✅ Validar datos automáticamente\n",
    "- ✅ Documentarse a sí misma\n",
    "- ✅ Desplegarse globalmente en segundos\n",
    "- ✅ Monitorearse y alertar automáticamente\n",
    "- ✅ Escalarse según demanda\n",
    "\n",
    "**¡Es hora de llevarlo a producción y ver tu modelo en acción!** 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63710c-2172-4bda-8853-4d9e6110b7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
